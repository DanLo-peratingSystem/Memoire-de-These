
@article{bettati_end--end_1994,
	title = {End-to-end scheduling to meet deadlines in distributed systems},
	language = {en},
	author = {Bettati, Riccardo},
	year = {1994},
	pages = {164},
}

@techreport{becker_measuring_2018,
	title = {Measuring {Software} {Performance} on {Linux}},
	url = {http://arxiv.org/abs/1811.01412},
	abstract = {Measuring and analyzing the performance of software has reached a high complexity, caused by more advanced processor designs and the intricate interaction between user programs, the operating system, and the processor’s microarchitecture. In this report, we summarize our experience on how performance characteristics of software should be measured when running on a Linux operating system and a modern processor. In particular, (1) we provide a general overview about hardware and operating system features that may have a significant impact on timing and explain their interaction, (2) we identify sources of errors that need to be controlled in order to obtain unbiased measurement results, and (3) we propose a measurement setup for Linux to minimize errors. Although not the focus of this report, we describe the measurement process using hardware performance counters, which can faithfully point to performance bottlenecks on a given processor. Our experiments confirm that our measurement setup has a large impact on the results.},
	language = {en},
	urldate = {2020-12-14},
	author = {Becker, Martin and Chakraborty, Samarjit},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.01412},
	keywords = {Computer Science - Performance},
}

@article{loche_mixed_2019,
	title = {Mixed {Critical} {Automotive} {Embedded} {Applications} on {Multicores}: {A} {Safe} {Scheduling} {Approach} for {Dependability}},
	copyright = {All rights reserved},
	abstract = {Memory access durations on multicore architectures are highly variable, since concurrent accesses to memory by different cores induce time interferences. Consequently, critical software tasks may be delayed by non-critical ones, leading to deadline misses and possible catastrophic failures. We present an approach to tackle the implementation of mixed criticality workloads on multicore chips, focusing on task chains, i.e., sequences of tasks with end-to-end deadlines. Our main contribution is a Monitoring \& Control System able to stop non-critical software execution in order to prevent memory interference and guarantee that critical tasks deadlines are met. This paper describes our approach, and the associated experimental framework to conduct experiments to analyze attainable real-time guarantees on a multicore platform.},
	language = {en},
	journal = {EDCC - CARS Workshop},
	author = {Loche, Daniel and Lauer, Michael and Roy, Matthieu and Fabre, Jean-Charles},
	year = {2019},
}

@article{loche_safe_2020,
	title = {Safe {Scheduling} on {Multicores}: an approach leveraging multi-criticality and end-to-end deadlines},
	shorttitle = {Safe {Scheduling} on {Multicores}},
	url = {https://hal.laas.fr/hal-02465340},
	abstract = {Memory access duration on multicore architectures are highly variable, since concurrent accesses to resources by different cores induce time interferences. Consequently, critical software tasks may be delayed by non-critical ones, leading to deadline misses and possible catastrophic failures. We present an approach to tackle the implementation of mixed criticality work-loads on multicore chips, focusing on task chains, i.e., sequences of tasks with end-to-end deadlines. Our main contribution is a Monitoring \& Control Agent able to stop non-critical software execution in order to prevent memory interference and guarantee that critical tasks deadlines are met. This paper describes our approach, and the associated experimental framework to conduct experiments to analyze attainable real-time guarantees on a multicore platform.},
	language = {en},
	urldate = {2020-11-23},
	journal = {10th European Congress on Embedded Real Time Software and Systems (ERTS 2020)},
	author = {Loche, Daniel and Lauer, Michaël and Roy, Matthieu and Fabre, Jean-Charles},
	year = {2020},
}

@inproceedings{lu_robustness_2009,
	title = {Robustness of modular multi-layered software in the automotive domain: a wrapping-based approach},
	abstract = {New automotive modular multi-layered software organization particularly favors use and interoperability of Components-OffThe-Shelf. However, the integration of software components is error-prone, if their coordination is not rigorously controlled. The risk of failure is increased with the possibility to multiplex software components with heterogeneous levels of criticality, observability. Most of dependability mechanisms, today, address locally errors within each component or report them to further diagnosis services. Instead, we consider a global wrapping-based approach to deal with multilevel properties to be checked on the complete multilayered system at runtime. In this paper, we introduce a framework to design robust software, from analysis to implementation issues, and we illustrate the methodology on simple case study.},
	language = {en},
	publisher = {IEEE},
	author = {Lu, Caroline and Fabre, Jean-Charles and Killijian, Marc-Olivier},
	year = {2009},
	pages = {8},
}

@article{litayem_building_2011,
	title = {Building {XenoBuntu} {Linux} {Distribution} for {Teaching} and {Prototyping} {Real}-{Time} {Operating} {Systems}},
	volume = {2},
	issn = {2158107X, 21565570},
	url = {http://thesai.org/Publications/ViewPaper?Volume=2&Issue=2&Code=IJACSA&SerialNo=1},
	doi = {10.14569/IJACSA.2011.020201},
	abstract = {This paper describes the realization of a new Linux distribution based on Ubuntu Linux and Xenomai Real-Time framework. This realization is motivated by the eminent need of real-time systems in modern computer science courses. The majority of the technical choices are made after qualitative comparison. The main goal of this distribution is to offer standard Operating Systems (OS) that include Xenomai infrastructure and the essential tools to begin hard real-time application development inside a convivial desktop environment. The released live/installable DVD can be adopted to emulate several classic RTOS Application Program Interfaces (APIs), directly use and understand real-time Linux in convivial desktop environment and prototyping real-time embedded applications.},
	language = {en},
	number = {2},
	urldate = {2020-07-20},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Litayem, Nabil and Ben, Ahmed and Ben, Slim},
	year = {2011},
}

@article{bertolino_tour_2018,
	title = {A tour of secure software engineering solutions for connected vehicles},
	volume = {26},
	issn = {0963-9314, 1573-1367},
	url = {http://link.springer.com/10.1007/s11219-017-9393-3},
	doi = {10.1007/s11219-017-9393-3},
	language = {en},
	number = {4},
	urldate = {2020-07-16},
	journal = {Software Quality Journal},
	author = {Bertolino, Antonia and Calabro’, Antonello and Di Giandomenico, Felicita and Lami, Giuseppe and Lonetti, Francesca and Marchetti, Eda and Martinelli, Fabio and Matteucci, Ilaria and Mori, Paolo},
	month = dec,
	year = {2018},
	pages = {1223--1256},
}

@inproceedings{quillet_analysis_2020,
	address = {Paris France},
	title = {Analysis of {Polka} {Contention} {Manager} for use in {Multicore} {Hard} {Real}-{Time} {Systems}},
	isbn = {978-1-4503-7593-1},
	url = {https://dl.acm.org/doi/10.1145/3394810.3394825},
	doi = {10.1145/3394810.3394825},
	abstract = {Transactional memory (TM) draws the attention of both academic and development groups; indeed this concept offers an alternative to lock-based approaches, easing programmers’ work. Despite the large amount of investigations around this topic, the question of the correctness of most TM implementations remains open. More specifically, the lack of upper bounds on the execution time of transactions prevents the use of TM in real-time systems. To address this issue, we introduce new realistic assumptions relative to real-time systems, which allow to ensure wait-freedom guarantees progress (i.e. all transactions progress) when Polka contention manager is considered. In that context, through a thorough formalization of the system, we prove upper bounds both on the number of abortions and on the execution time of transactions.},
	language = {en},
	urldate = {2020-07-16},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Real}-{Time} {Networks} and {Systems}},
	publisher = {ACM},
	author = {Quillet, Adrien and Queudet, Audrey and Lime, Didier},
	month = jun,
	year = {2020},
	pages = {11--21},
}

@misc{lipari_programming_nodate,
	title = {Programming {RT} systems with pthreads},
	language = {en},
	author = {Lipari, Giuseppe},
}

@misc{lipari_real-time_nodate,
	title = {Real-{Time} {Linux} and the {Xenomai} system},
	language = {en},
	author = {Lipari, Giuseppe},
}

@phdthesis{gratia_approche_2017,
	type = {thesis},
	title = {Une approche efficace et polyvalente pour l'ordonnancement de systèmes à criticité mixte sur processeur multi-coeurs},
	url = {http://www.theses.fr/2017ENST0001},
	abstract = {Ce document présente nos contributions aux algorithmes d'ordonnancement à criticité mixte pour multi-processeurs. La correction de l'exécution des applications temps réel critiques est assurée par l'utilisation d'un ordonnancement vérifié à la conception. Dans ce contexte, le dimensionnement des plate-formes d'exécution vise à minimiser le nombre de processeurs nécessaires pour assurer un ordonnancement correct. Ce dimensionnement est affecté par les exigences de sûreté de fonctionnement. Ces exigences poussent à surestimer le temps nécessaire garantissant l'exécution correcte des applications. Il en découle un dimensionnement assez coûteux. Les méthodes d'ordonnancement des systèmes à criticité mixte proposent des compromis sur les garanties d'exécution des applications améliorant le dimensionnement.  Différents compromis ont été proposés mais tous reposent sur la notion de mode d'exécution. Les modes sont ordonnés, et les tâches voient leur temps d'exécution requis croître avec les modes. Cependant, afin de diminuer le dimensionnement du système, seul l'ordonnancement des tâches les plus critiques est garanti. Ce modèle est appelé "discarding". La majorité des algorithmes proposés se limitent à deux modes d'exécutions par simplicité. De plus, les algorithmes les plus efficaces pour multi-processeurs exhibent un nombre élevé de préemptions, ce qui constitue un frein à leur adoption. Finalement, ces algorithmes sont rarement généralisables. Pourtant, la prise en compte de plus de deux modes, ou de tâches aux périodes élastiques permettrait une adoption plus large par le milieu industriel.  L'approche proposée repose sur la séparation des préoccupations entre la prise en compte des modes de fonctionnement, et l'ordonnancement des tâches sur multi-processeurs. Cette méthode permet de concevoir une politique d'ordonnancement efficace et adaptable à différents modèles de systèmes à criticité mixte. Notre approche consiste à transformer un lot de tâches à criticité mixte en un lot de tâches qui n'est plus à criticité mixte.  Ceci nous permet d'utiliser un algorithme d'ordonnancement temps réel optimal engendrant peu de préemptions et de migrations, à savoir RUN.  Cette approche, appliquée en premier pour le modèle discarding avec deux modes d'exécution, rempli son objectif d'efficacité. Nous illustrons sa généricité en utilisant le même principe pour ordonnancer des systèmes discarding avec plus de deux modes d'exécution. Enfin, une démarche reposant sur la décomposition de tâche permet de généraliser l'approche au cas des tâches élastiques.},
	urldate = {2019-11-25},
	school = {Paris, ENST},
	author = {Gratia, Romain},
	month = jan,
	year = {2017},
	keywords = {Criticité mixte, Informatique et réseaux, Mixed–criticality, Multiprocesseur, Multiprocesseurs, Multiprocessor, Ordonnancement, Ordonnancement (informatique), Real–time systems, Scheduling, Système temps réel, Temps réel (informatique)},
}

@article{sangiovanni-vincentelli_embedded_nodate,
	title = {Embedded {System} {Design} for {Automotive} {Applications}},
	volume = {40},
	issn = {0018-9162},
	url = {https://www.academia.edu/2738584/Embedded_system_design_for_automotive_applications},
	abstract = {CHALLENGES Novel methods and tools for system-level analysis and modeling are needed not only for predictability and composability when partitioning end-to-end functions at design time (and later, at system integration time), but also for providing},
	language = {en},
	number = {10},
	urldate = {2019-11-12},
	journal = {Computer},
	author = {Sangiovanni-Vincentelli, Alberto and Natale, Marco Di},
	pages = {42--51},
}

@article{mishra_dynamic_2014,
	title = {Dynamic {Task} {Scheduling} on {Multicore} {Automotive} {ECUs}},
	volume = {5},
	issn = {09761527, 09761357},
	url = {http://www.aircconline.com/vlsics/V5N6/5614vlsi01.pdf},
	doi = {10.5121/vlsic.2014.5601},
	number = {6},
	urldate = {2019-11-08},
	journal = {International Journal of VLSI Design \& Communication Systems},
	author = {Mishra, Geetishree and K S, Gurumurthy},
	month = dec,
	year = {2014},
	pages = {01--08},
}

@article{yildirim_function_nodate,
	title = {Function modeling using the system state flow diagram},
	abstract = {This paper introduces a rigorous framework for function modeling of complex multidisciplinary systems based on the system state flow diagram (SSFD). The work addresses the need for a consistent methodology to support solution-neutral function-based system decomposition analysis, facilitating the design, modeling, and analysis of complex systems architectures. A rigorous basis for the SSFD is established by defining conventions for states and function definitions and a representation scheme, underpinned by a critical review of existing literature. A set of heuristics are introduced to support the function decomposition analysis and to facilitate the deployment of the methodology with strong practitioner guidelines. The SSFD heuristics extend the existing framework of Otto and Wood (2001) by introducing a conditional fork node heuristic, to facilitate analysis and aggregation of function models across multiple modes of operation of the system. The empirical validation of the SSFD function modeling framework is discussed in relation to its application to two case studies: a benchmark problem (glue gun) set for the engineering design community; and an industrial case study of an electric vehicle powertrain. Based on the evidence from the two case studies presented in the paper, a critical evaluation of the SSFD function modeling methodology is discussed based on the function benchmarking framework established by Summers et al. (2013), considering the representation, modeling, cognitive, and reasoning characteristics. The significance of this paper is that it establishes a rigorous reference framework for the SSFD function representation and a consistent methodology to guide the practitioner with its deployment, facilitating its impact to industrial practice.},
	language = {en},
	author = {Yildirim, Unal and Campean, Felician and Williams, Huw},
	pages = {23},
}

@article{cha_deriving_nodate,
	title = {Deriving {High}-{Performance} {Real}-{Time} {Multicore} {Systems} {Based} on {Simulink} {Applications}},
	abstract = {MATLAB/Simulink is commonly used for designing model-based dynamic embedded systems. Throughout Real-Time Workshop toolkits, it can generate C or C++ programs for various target platforms, which is useful to develop embedded systems. However, the current toolkits generate only single programs, so that it does not leverage multicore technology for performance improvement. In this paper, we provide a new automatic code generation scheme for multicore real-time systems by inserting user-deﬁned S-Functions for Simulink applications. The proposed scheme uses mailboxes for synchronization among threads in order to reduce the overhead. Users can easily develop multiple subtasks of a Simulink application on multicore systems. We develop the automatic code generation for RTAI real-time systems and evaluate the performance throughout experiments.},
	language = {en},
	author = {Cha, Minji and Kim, Kyong Hoon and Lee, Chung Jae and Ha, Dojun and Kim, Byoung Soo},
	pages = {8},
}

@article{wang_spatial_2008,
	title = {Spatial and {Temporal} {Cost} {Analysis} on {OSEK} {Implementations} of {Synchronous} {Reactive} {Semantics} {Preserving} {Communication} {Protocols}},
	url = {https://www.academia.edu/2735932/Spatial_and_Temporal_Cost_Analysis_on_OSEK_Implementations_of_Synchronous_Reactive_Semantics_Preserving_Communication_Protocols},
	abstract = {Synchronous Reactive semantics preserving communication buffer sizing mechanisms and buffer indexing protocols are presented. Because these protocols define buffer indices for writers and readers at task activation time, generally they},
	language = {en},
	urldate = {2019-11-05},
	author = {Wang, Guogiang and Di Natale, Marco and Sangiovanni-Vincentelli, Alberto},
	year = {2008},
}

@article{di_natale_osek/vdx_2007,
	title = {An {OSEK}/{VDX} implementation of synchronous reactive semantics preserving communication protocols},
	url = {https://www.academia.edu/2735276/An_OSEK_VDX_implementation_of_synchronous_reactive_semantics_preserving_communication_protocols},
	abstract = {Synchronous Reactive semantics preserving communication buffer sizing mechanisms and buffer indexing protocols are presented for both single-port and multiport tasks. Because these protocols define buffer indices for writers and readers at},
	language = {en},
	urldate = {2019-11-05},
	journal = {Workshop on Operating Systems Platforms for Embedded Real-Time applications},
	author = {Di Natale, Marco and Wang, Guogiang and Sangiovanni-Vincentelli, Alberto},
	year = {2007},
}

@article{trinquet_overview_2008,
	title = {Overview of microkernel standards for real-time in-vehicle embedded systems},
	url = {https://www.academia.edu/18392155/Overview_of_microkernel_standards_for_real-time_in-vehicle_embedded_systems},
	abstract = {Overview of microkernel standards for real-time in-vehicle embedded systems},
	language = {en},
	urldate = {2019-11-05},
	journal = {TFIT},
	author = {Trinquet, Y. and Hladik, Pierre-emmanuel and Faucou, Sébastien},
	year = {2008},
}

@article{devika_autosar_nodate,
	title = {{AUTOSAR} {Multicore} {Operating} {System} {Implementation} for {MPC5668G}},
	url = {https://www.academia.edu/5718377/AUTOSAR_Multicore_Operating_System_Implementation_for_MPC5668G_},
	abstract = {This paper discusses the design and implementation details of multicore operating system for dual core processor MPC5668G.},
	language = {en},
	urldate = {2019-11-05},
	journal = {International Journal of Engineering Sciences \&amp; Research Technology},
	author = {Devika, K and Syama, R and Anurag, R},
}

@misc{fisher_certifying_2013,
	title = {Certifying {Applications} in a {Multi}-{Core} {Environment}: {The} {World}’s {First} {Multi}-{Core} {Certification} to {SIL} 4.},
	language = {en},
	author = {Fisher, Stuart and SYSGO AG},
	year = {2013},
}

@inproceedings{blin_maximizing_2016,
	address = {Toulouse},
	title = {Maximizing {Parallelism} without {Exploding} {Deadlines} in a {Mixed} {Criticality} {Embedded} {System}},
	isbn = {978-1-5090-2811-5},
	url = {http://ieeexplore.ieee.org/document/7557873/},
	doi = {10.1109/ECRTS.2016.18},
	abstract = {Complex embedded systems today commonly involve a mix of real-time and best-effort applications. The recent emergence of low-cost multicore processors raises the possibility of running both kinds of applications on a single machine, with virtualization ensuring isolation. Nevertheless, memory contention can introduce other sources of delay, that can lead to missed deadlines. In this paper, we present a combined ofﬂine/online memory bandwidth monitoring approach. Our approach estimates and limits the impact of the memory contention incurred by the best-effort applications on the execution time of the real-time application. We show that our approach is compatible with the hardware counters provided by current small commodity multicore processors. Using our approach, the system designer can limit the overhead on the real-time application to under 5\% of its expected execution time, while still enabling progress of the best-effort applications.},
	urldate = {2019-10-13},
	booktitle = {2016 28th {Euromicro} {Conference} on {Real}-{Time} {Systems} ({ECRTS})},
	publisher = {IEEE},
	author = {Blin, Antoine and Courtaud, Cedric and Sopena, Julien and Lawall, Julia and Muller, Gilles},
	month = jul,
	year = {2016},
	pages = {109--119},
}

@phdthesis{fersman_generic_2003,
	address = {Uppsala},
	title = {A generic approach to schedulability analysis of real-time systems},
	language = {en},
	school = {Univ. Uppsala, Sweden},
	author = {Fersman, Elena},
	year = {2003},
	note = {OCLC: 249094759},
}

@inproceedings{altmeyer_generic_2015,
	title = {A generic and compositional framework for multicore response time analysis},
	isbn = {978-1-4503-3591-1},
	url = {http://dl.acm.org/citation.cfm?id=2834848.2834862},
	doi = {10.1145/2834848.2834862},
	urldate = {2019-10-13},
	publisher = {ACM},
	author = {Altmeyer, Sebastian and Davis, Robert I. and Indrusiak, Leandro and Maiza, Claire and Nelis, Vincent and Reineke, Jan},
	month = nov,
	year = {2015},
	pages = {129--138},
}

@inproceedings{huang_deadline_2013,
	title = {Deadline {Analysis} of {AUTOSAR} {OS} {Periodic} {Tasks} in the {Presence} of {Interrupts}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-41202-8_12},
	doi = {10.1007/978-3-642-41202-8_12},
	abstract = {AUTOSAR, the open and emerging global standard for automotive embedded systems, offers a timing protection mechanism to protect tasks from missing their deadlines. However, in practice, it is...},
	language = {en},
	urldate = {2019-10-13},
	booktitle = {Formal {Methods} and {Software} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Huang, Yanhong and Ferreira, João F. and He, Guanhua and Qin, Shengchao and He, Jifeng},
	month = oct,
	year = {2013},
	pages = {165--181},
}

@inproceedings{solet_hw-based_2018,
	address = {Edinburgh},
	title = {{HW}-based {Architecture} for {Runtime} {Verification} of {Embedded} {Software} on {SoPC} systems},
	isbn = {978-1-5386-7753-7},
	url = {https://ieeexplore.ieee.org/document/8541459/},
	doi = {10.1109/AHS.2018.8541459},
	urldate = {2019-10-13},
	booktitle = {2018 {NASA}/{ESA} {Conference} on {Adaptive} {Hardware} and {Systems} ({AHS})},
	publisher = {IEEE},
	author = {Solet, Dimitry and Pillement, Sebastien and Bechennec, Jean-Luc and Briday, Mikael and Faucou, Sebastien},
	month = aug,
	year = {2018},
	pages = {249--256},
}

@unpublished{helder_introduction_2014,
	type = {{STR} {Guide}},
	title = {Introduction   to   real   time   applications   development   with {Xenomai} 2.5.x},
	url = {http://intranet.deei.fct.ualg.pt/STR/temp/01-xenomai-2.5.x-eng.pdf},
	language = {en},
	urldate = {2019-02-05},
	author = {Helder, Daniel},
	year = {2014},
}

@misc{noauthor_real-time_2017,
	title = {Real-time {Linux} explained, and contrasted with {Xenomai} and {RTAI}},
	url = {http://linuxgizmos.com/real-time-linux-explained/},
	abstract = {At ELC Europe, Real-time Linux developer Jan Altenberg described the progress of RTL, compared it to Xenomai and RTAI, and unveiled new benchmarks.},
	urldate = {2018-10-10},
	journal = {LinuxGizmos.com},
	month = feb,
	year = {2017},
}

@unpublished{intel_corporation_hard_2009,
	type = {White {Paper}},
	title = {Hard {Real} time {Linux} {Using} {Xenomai} on {Intel} {Multi}-{Core} {Processors}},
	language = {en},
	author = {Intel Corporation},
	year = {2009},
}

@article{bach_functional_2017,
	title = {From {Functional} {Chains} to {Functional} {Networks}},
	abstract = {Systems Engineering, System Architecture, Advanced Driving Assistance Systems, Automated Driving.},
	language = {en},
	author = {Bach, Johannes and Otten, Stefan and Sax, Eric},
	year = {2017},
	keywords = {ADAS, Architecture, Automated Driving, Functional chains, System Architecture, Systems Engineering},
	pages = {12},
}

@inproceedings{allende_towards_2019,
	title = {Towards {Linux} for the {Development} of {Mixed}-{Criticality} {Embedded} {Systems} {Based} on {Multi}-{Core} {Devices}},
	isbn = {978-1-72813-929-6},
	doi = {10.1109/EDCC.2019.00020},
	abstract = {As the complexity of several safety-critical systems continues to increase (e.g. autonomous driving), the need for a safety operating system to run complex algorithms and software has arisen. Although GNU/Linux is a widely used operating system, including high-performance systems, it was not designed for safety critical systems. This paper presents a novel isolation concept in order to support a deﬁned independence level in mixed-criticality systems. This novel isolation concept is integrated with the architecture proposed by SIL2LinuxMP. Finally, a simple case study is used to guide the deﬁnition of safety techniques and the identiﬁcation of challenges to be addressed.},
	language = {en},
	publisher = {IEEE},
	author = {Allende, Imanol and Centre, Ikerlan Technology Research and Guire, Nicholas Mc and GmbH, OpenTech EDV Research and Perez, Jon and Centre, Ikerlan Technology Research and Monsalve, Lisandro Gabriel and Centre, Ikerlan Technology Research and Uriarte, Nerea and Centre, Ikerlan Technology Research and Obermaisser, Roman},
	year = {2019},
	pages = {8},
}

@article{hladik_adequacy_nodate,
	title = {Adequacy between {AUTOSAR} {OS} speciﬁcation and real-time scheduling theory},
	abstract = {AUTOSAR (AUTOmotive Open System ARchitecture) consortium is a development partnership between the main actors of the automotive manufacturing industry. It aims at deﬁning an open standardized software architecture, in order to face the future challenges in automotive development. One of the important challenge concerns the development of timecritical systems, e.g. brake-by-wire or steer-by-wire. In order to master the development of such systems, one must be able to understand and analyze their real-time behavior. Responses to this problem can be found in the real-time scheduling theory, especially schedulability analysis techniques. In this paper, we propose a review of a subset of the AUTOSAR Operating System speciﬁcation from a schedulability analysis point-of-view.},
	language = {en},
	author = {Hladik, Pierre-Emmanuel and Deplanche, Anne-Marie and Faucou, Sebastien and Trinquet, Yvon},
	pages = {9},
}

@article{bertrand_analysis_nodate,
	title = {An analysis of the {AUTOSAR} {OS} timing protection mechanism},
	abstract = {The in-vehicle embedded system market is evolving toward a large improvement of the industrialization of the embedded software. One of the technical consequences of this evolution is the mandatory integration of protection mechanisms in the embedded operating system kernels to support the design of multi-suppliers multi-critical component-based embedded software. In this paper, we evaluate such a mechanism: the timing protection mechanism proposed in the AUTOSAR OS standard. This evaluation shows that the present version of the mechanism is not fully adapted to multi-critical systems because it does not handle soft/non real-time applications.},
	language = {en},
	author = {Bertrand, Dominique and Faucou, Sébastien and Trinquet, Yvon},
	pages = {8},
}

@misc{ishkov_complete_2015,
	title = {A complete guide to {Linux} process scheduling},
	abstract = {The subject of this thesis is process scheduling in wide purpose operating systems. For many years kernel hackers all over the world tried to accomplish the seemingly infeasible task of achieving good interaction on desktop systems and low latencies on heavily loaded server machines. Some progress has been made in this area since the rise of free software, but, in opinion of many, it is still far from perfect. Lots of beginner operating system enthusiasts find the existing solutions too complex to understand and, in light of almost complete lack of documentation along with common hostility of active kernel developers towards rookies, impossible to get hands on. Anyone who has the courage to wade into the dragon infested layer that is the scheduler, should be aware of the ideas behind current implementations before making any contributions. That is what this thesis is about – showing how things work under the hood and how they developed to be like this. Every decision behind each concept in a kernel of an OS has its history and meaning. Here I will guide you through process scheduling mechanisms in currently stable Linux kernel as an object lesson on the matter. The work starts with an overview of the essentials of process abstraction in Linux, and continues with detailed code-level description of scheduling techniques involved in past and present kernels.},
	language = {en},
	publisher = {University of Tampere},
	author = {Ishkov, Nikita},
	year = {2015},
}

@article{garre_performance_2014,
	title = {Performance {Comparison} of {Real}-{Time} and {General}- {Purpose} {Operating} {Systems} in {Parallel} {Physical} {Simulation} with {High} {Computational} {Cost}},
	doi = {10.4271/2014-01-0200},
	abstract = {Real-time simulation is a valuable tool in the design and test of vehicles and vehicle parts, mainly when interfacing with hardware modules working at a given rate, as in hardware-in-the-loop testing. Real-time operating-systems (RTOS) are designed for minimizing the latency of critical operations},
	language = {en},
	author = {Garre, Carlos and Mundo, Domenico and Gubitosa, Marco and Toso, Alessandro},
	year = {2014},
	pages = {11},
}

@misc{balandin_method_2014,
	title = {Method and {Apparatus} for {Using} {Layer} 4 {Information} in a {Layer} 2 {Switch} in {Order} to {Support}},
	abstract = {Apparatus configured to receive a first end-to-end flow control representation for at least one logical connection from a first further apparatus to a second further apparatus, update at least one end-to-end credit value for the at least one logical connection from the first further apparatus to the second further apparatus dependent on the first end-to-end flow control representation, select at least one logical connection to the second further apparatus dependent on the end-to-end credit value, generate a second end-to-end flow control representation for the at least one logical connection to the second further apparatus, and transmit the second end-to-end flow control representation addressed to the second further apparatus.},
	language = {en},
	author = {Balandin, Sergey and Gillet, Michel},
	month = apr,
	year = {2014},
	pages = {17},
}

@misc{zink_system_2014,
	title = {System and {Method} for {Capacity} {Planning} for {Systems} with {Multithreaded} {Multicore} {Multiprocessor} {Resources}},
	abstract = {A method for expressing a hierarchy of scalabilities in complex systems, including a discrete event simulation and an analytic model, for analysis and prediction of the performance of multi-chip, multi-core, multi-threaded computer processors is provided. Further provided is a capacity planning tool for migrating data center systems from a source configuration which may include source systems with multithreaded, multicore, multichip central processing units to a destination configuration which may include destination systems with multithreaded, multicore and multichip central processing units, wherein the destination systems may be different than the source systems. Apparatus and methods are taught for the assembling of and utilization of linear and exponential scalability factors in the capacity planning tool when a plurality of active processor threads populate processors with multiple chips, multiple cores per chip and multiple threads per core.},
	language = {en},
	author = {Zink, Kenneth C and Neuse, Douglas M and Walton, Christopher B},
	year = {2014},
	pages = {31},
}

@misc{ramarao_method_2016,
	title = {Method and {System} for {Providing} {Usage} {Metrics} to {Manage} {Utilzation} of {Cloud} {Computing} {Resources}},
	abstract = {A management console application provides a dashboard which centralizes data from and access to one or more other applications. In a specific implementation, the dashboard displays resource utilization and tracking data generated by a first application, an application execution map generated by a second application that identifies the resources on which a third application is executing, or both.},
	language = {en},
	author = {Ramarao, Shreenidhi and Ilan, Ginzburg and Feng, Guo},
	month = nov,
	year = {2016},
	pages = {40},
}

@misc{cotard_procede_2015,
	title = {Procede {Hors} {Ligne} d'{Allocation} d'un {Logiciel} {Embarque} temps reel sur une architecture multi-controleur multicoeur, et son utilisation pour des applications embarquées dans un véhicule automobile},
	language = {Fr},
	author = {Cotard, Sylvain and Wang, Wenhao and Miramond, Benoit and Camut, Fabrice},
	month = dec,
	year = {2015},
}

@misc{liu_procede_2018,
	title = {Procédé, {Dispositif} et {Système} pour une communication interprocess d'un processeur multicoeur},
	author = {Liu, Tanyi and Yan, Youliang},
	month = mar,
	year = {2018},
}

@misc{lei_procede_2017,
	title = {Procédé et {Système} pour {Prend} en {Charge} une {Isolation} de {Ressources} dans une architecture {Multicoeur}},
	author = {Lei, Xiaosong},
	month = sep,
	year = {2017},
}

@misc{lippett_gestion_2018,
	title = {Gestion de {Ressources} dans une {Architecture} {Multicoeur}},
	language = {En},
	author = {Lippett, Mark David},
	month = dec,
	year = {2018},
}

@misc{picart_systeme_2001,
	title = {Système de {Traitement} d'informations pour effectuer des tâches ayant des priorités diverss et modem comportant un tel système},
	language = {Fr},
	author = {Picart, Catherine},
	month = sep,
	year = {2001},
}

@misc{won-bo_methoed_2018,
	title = {Methoed and {Apparatus} for {Data} {Processing} {Based} on {Multicore}},
	language = {En},
	author = {Won-Bo, Lee and Young-Ki, Hong and Young-Wook, Kim and Jung-Hwan, Suwon-si},
	month = nov,
	year = {2018},
}

@misc{noauthor_cn107526631_a.pdf_nodate,
	title = {{CN107526631}\_A.pdf},
}

@misc{noauthor_cn105653365_a.pdf_nodate,
	title = {{CN105653365}\_A.pdf},
}

@article{ren_mixed-criticality_nodate,
	title = {Mixed-{Criticality} {Scheduling} on {Multiprocessors} {Using} {Task} {Grouping}},
	abstract = {Real-time systems are increasingly running a mix of tasks with different criticality levels: for instance, unmanned aerial vehicle has multiple software functions with different safety criticality levels, but runs them on a single, shared computational platform. In addition, these systems are increasingly deployed on multiprocessor platforms because this can help to reduce their cost, space, weight, and power consumption. To assure the safety of such systems, several mixed-criticality scheduling algorithms have been developed that can provide mixed-criticality timing guarantees. However, most existing algorithms have two important limitations: they do not guarantee strong isolation among the high-criticality tasks, and they offer poor real-time performance for the low-criticality tasks.},
	language = {en},
	author = {Ren, Jiankang and Phan, Linh Thi Xuan},
	pages = {10},
}

@article{mohalik_model_nodate,
	title = {Model {Checking} based {Analysis} of {End}-to-end {Latency} in {Embedded}, {Real}-time {Systems} with {Clock} {Drifts}},
	abstract = {End-to-end latency of messages is an important design parameter that needs to be within speciﬁed bounds for the correct functioning of distributed real-time control systems. In this paper we give a formal deﬁnition of end-to-end latency, and use this as the basis for checking whether a stipulated deadline is violated within a bounded time. For unbounded veriﬁcation, we model the system as a set of communicating Timed Automata, and perform reachability analysis. The proposed method takes into account the drift of clocks which is shown to aﬀect the latency appreciably. The method has been tested on a medium sized automotive example.},
	language = {en},
	author = {Mohalik, Swarup and Rajeev, A C and Dixit, Manoj G and Ramesh, S and Suman, P Vijay and Pandya, Paritosh K and Jiang, Shengbing},
	pages = {4},
}

@article{kedad-sidhoum_scheduling_nodate,
	title = {Scheduling {Tasks} with {Precedence} {Constraints} on {Hybrid} {Multi}-core {Machines}},
	abstract = {In this work, we are interested in scheduling dependent tasks for hybrid parallel multi-core machines, composed of CPUs with additional accelerators (GPUs). The objective is to minimize the makespan, which is a crucial problem for reaching the potential of new platforms in High Performance Computing. We provide an approximation algorithm with a performance guarantee of 6 to solve this problem. The algorithm is a two-phase solving method: a ﬁrst phase based on rounding the solution provided by solving a linear programming formulation for the assignment of the tasks to the resources. A second phase uses a classical list algorithm to schedule the tasks according to the assignment phase. The proposed approach is the ﬁrst generic algorithm with a performance guarantee for scheduling tasks with precedence constraints on hybrid platforms with CPUs and GPUs resources.},
	language = {en},
	author = {Kedad-Sidhoum, Saﬁa and Monna, Florence and Trystram, Denis and Grenoble-Alpes, Univ},
	pages = {7},
}

@inproceedings{lin_maximizing_2006,
	address = {San Jose, USA},
	title = {Maximizing {Guaranteed} {QoS} within (m, k)-firm {Real}- time {Constraints}},
	abstract = {(m,k)-firm constraints have been used to schedule tasks in firm real-time systems under overloaded conditions. In general, they are provided by application designers to guarantee the minimum levels of quality of service (QoS). Many problems focusing on task schedulability under these constraints were investigated in the last ten years. However, little work has been done in combining the optimization of the QoS and tasks schedulability subject to these (m,k)-firm constraints. In this paper, we consider the problem of maximizing the guaranteed performance while maintaining a schedulable task set in periodic firm real-time systems. To quantify the performance, we propose a granularity-related metric called Granularity of Quality of Service - Reward (GQoS- reward). We then show that maximizing the total GQoS-reward is an NP-Hard problem. We conclude the paper by laying out a preliminary framework for solving this problem.},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Lin, Jian (Denny) and M. K. Cheng, Albert},
	month = apr,
	year = {2006},
}

@article{hammadeh_bounding_nodate,
	title = {Bounding {Deadline} {Misses} in {Weakly}-{Hard} {Real}-{Time} {Systems} with {Task} {Dependencies}},
	abstract = {Real-time systems with functional dependencies between tasks often require end-to-end (as opposed to task-level) guarantees. For many of these systems, it is even possible to accept the possibility of longer end-to-end delays if one can bound their frequency. Such systems are called weakly-hard.},
	language = {en},
	author = {Hammadeh, Zain A H and Ernst, Rolf and Quinton, Sophie and Henia, Rafik and Rioux, Laurent},
	pages = {7},
}

@book{ieee_computer_society_42nd_2012,
	address = {Boston, Massachusetts, USA},
	title = {42nd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks}},
	isbn = {978-1-4673-1624-8},
	shorttitle = {{DSN} 2012},
	publisher = {IEEE},
	editor = {IEEE Computer Society and IFIP Working Group 10.4 on Dependable Computing {and} Fault Tolerance},
	year = {2012},
	keywords = {Computers, Congresses, Fault-tolerant computing, Reliability},
}

@article{baker_comparison_nodate,
	title = {A {Comparison} of {Global} and {Partitioned} {EDF} {Schedulability} {Tests} for {Multiprocessors}},
	abstract = {This paper compares the performance of several variations on EDF-based global and partitioned multiprocessor scheduling algorithms, together with their associated feasibility tests, on a variety of pseudo-randomly chosen sets of sporadic tasks. A new hybrid EDF-based scheme is shown to perform better than previously studied priority-based global scheduling schemes, though not as well as EDF-based ﬁrst-ﬁt partitioned scheduling.},
	language = {en},
	author = {Baker, Theodore P},
	pages = {14},
}

@misc{jan_ordonnancement_2017,
	address = {Telecom ParisTech},
	title = {Ordonnancement temps réel multiprocesseurs : théorie et pratique},
	url = {https://etr2017.sciencesconf.org/data/program/ETR_2017_ordo_multi.pdf},
	urldate = {2019-04-23},
	author = {Jan, Mathieu},
	year = {2017},
}

@inproceedings{ieee_technical_committee_on_real-time_systems_real-time_2006,
	address = {San Jose, USA},
	title = {Real-{Time} and {Embedded} {Technology} and {Applications} {Symposium}},
	url = {https://www.researchgate.net/profile/Richard_Schantz/publication/237707809_A_Hierarchical_Control_System_for_Dynamic_Resource_Management/links/00b4952e6dc88cb590000000/A-Hierarchical-Control-System-for-Dynamic-Resource-Management.pdf#page=59},
	language = {en},
	urldate = {2018-09-14},
	author = {IEEE Technical Committee on Real-Time Systems},
	month = apr,
	year = {2006},
	pages = {75},
}

@article{gujarati_multiprocessor_nodate,
	title = {Multiprocessor {Real}-{Time} {Scheduling} with {Arbitrary} {Processor} {Afﬁnities}: {From} {Practice} to {Theory}},
	abstract = {Contemporary multiprocessor real-time operating systems, such as VxWorks, LynxOS, QNX, and real-time variants of Linux, allow a process to have an arbitrary processor afﬁnity, that is, a process may be pinned to an arbitrary subset of the processors in the system. Placing such a hard constraint on process migrations can help to improve cache performance of speciﬁc multi-threaded applications, achieve isolation among applications, and aid in loadbalancing. However, to date, the lack of schedulability analysis for such systems prevents the use of arbitrary processor afﬁnities in predictable hard real-time systems. This paper presents the ﬁrst analysis of multiprocessor scheduling with arbitrary processor afﬁnities from a real-time perspective. It is shown that job-level ﬁxed-priority scheduling with arbitrary processor afﬁnities is strictly more general than global, clustered, and partitioned job-level ﬁxed-priority scheduling combined. Concerning the more general case of joblevel dynamic priorities, it is shown that global and clustered scheduling are equivalent to multiprocessor real-time scheduling with arbitrary processor afﬁnities. The Linux push and pull scheduler is studied as a reference implementation and two approaches for the schedulability analysis of hard real-time tasks with arbitrary processor afﬁnity masks are presented. In the ﬁrst approach, the scheduling problem is reduced to “global-like” sub-problems to which existing global schedulability tests can be applied. The second approach is speciﬁcally based on response-time analysis and models the response-time computation as a linear optimization problem. The latter linear-programming-based approach has better runtime complexity than the former reduction-based approach. Schedulability experiments show the proposed techniques to be effective.},
	language = {en},
	author = {Gujarati, Arpan and Cerqueira, Felipe and Brandenburg, Bjorn B},
	pages = {40},
}

@inproceedings{giannopoulou_scheduling_2013,
	title = {Scheduling of mixed-criticality applications on resource-sharing multicore systems},
	booktitle = {{ACM} {International} {Conference} on {Embedded} {Software}},
	author = {Giannopoulou, Georgia and Stoimenov, Nikolay and Huang, Pengcheng and Thiele, Lothar},
	year = {2013},
	pages = {17},
}

@article{lelli_efficient_2011,
	title = {An efficient and scalable implementation of global {EDF} in {Linux}},
	language = {en},
	journal = {7th International Workshop on Operating Systems Platforms for Embedded Real-Time Applications (OSPERT’11)},
	author = {Lelli, Juri and Lipari, Giuseppe and Faggioli, Dario and Cucinotta, Tommaso},
	year = {2011},
}

@article{wong_towards_2008,
	title = {Towards {Achieving} {Fairness} in the {Linux} {Scheduler}},
	volume = {42},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/1400097.1400102},
	doi = {10.1145/1400097.1400102},
	abstract = {The Operating System scheduler is designed to allocate the CPU resources appropriately to all processes. The Linux Completely Fair Scheduler (CFS) design ensures fairness among tasks using the thread fair scheduling algorithm. This algorithm ensures allocation of resources based on the number of threads in the system and not within executing programs. This can lead to fairness issue in a multi-threaded environment as the Linux scheduler tends to favor programs with higher number of threads. We illustrate the issue of fairness through experimental evaluation thus exposing the weakness of the current allocation scheme where software developers could take advantage by spawning many additional threads in order to obtain more CPU resources. A novel algorithm is proposed as a solution towards achieving better fairness in the Linux scheduler. The algorithm is based on weight readjustment of the threads created in the same process to significantly reduce the unfair allocation of CPU resources in multi-threaded environments. The algorithm was implemented and evaluated. It demonstrated promising results towards solving the raised fairness issue. We conclude this paper highlighting the limitations of the proposed approach and the future work in the stated direction.},
	number = {5},
	urldate = {2019-01-21},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Wong, Chee Siang and Tan, Ian and Kumari, Rosalind Deena and Wey, Fun},
	year = {2008},
	keywords = {Linux, completely fair scheduler, fairness, process scheduling},
	pages = {34--43},
}

@inproceedings{ward_making_2013,
	title = {Making {Shared} {Caches} {More} {Predictable} on {Multicore} {Platforms}},
	isbn = {978-0-7695-5054-1},
	shorttitle = {Outstanding {Paper} {Award}},
	url = {http://ieeexplore.ieee.org/document/6602097/},
	doi = {10.1109/ECRTS.2013.26},
	abstract = {In safety-critical cyber-physical systems, the usage of multicore platforms has been hampered by problems due to interactions across cores through shared hardware. The inability to precisely characterize such interactions can lead to worst-case execution time pessimism that is so great, the extra processing capacity of additional cores is entirely negated. In this paper, several techniques are proposed and analyzed for dealing with such interactions in the context of shared caches. These techniques are applied in a mixedcriticality scheduling framework motivated by the needs of next-generation unmanned air vehicles.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Ward, Bryan C. and Herman, Jonathan L. and Kenna, Christopher J. and Anderson, James H.},
	month = jul,
	year = {2013},
	pages = {157--167},
}

@article{sysgo_ag_arinc_2019,
	title = {{ARINC} 653 {RTOS} for multi core certification},
	language = {en},
	author = {SYSGO AG},
	year = {2019},
	pages = {15},
}

@article{ozer_safety_2017,
	title = {Safety certification for unsafe {COTS} platforms},
	language = {en},
	author = {Özer, Mehmet and SYSGO AG, Sysgo},
	year = {2017},
	pages = {10},
}

@misc{puaut_state---art_2007,
	type = {State of the {Art}},
	title = {State-of-the-art of {WCET} ({Worst}- {Case} {Execution} {Time}) {Estimation} methods},
	language = {en},
	author = {PUAUT, Isabelle},
	year = {2007},
	keywords = {WCET},
}

@inproceedings{guthaus_mibench:_2001,
	address = {Austin, TX, USA},
	title = {{MiBench}: {A} free, commercially representative embedded benchmark suite},
	doi = {10.1109/WWC.2001.990739},
	abstract = {This paper examines a set of commercially representative embedded programs and compares them to an existing benchmark suite, SPEC2000. A new version of SimpleScalar that has been adapted to the ARM instruction set is used to characterize the performance of the benchmarks using configurations similar to current and next generation embedded processors. Several characteristics distinguish the representative embedded programs from the existing SPEC benchmarks including instruction distribution, memory behavior, and available parallelism. The embedded benchmarks, called MiBench, are freely available to all researchers.},
	language = {en},
	publisher = {IEEE},
	author = {Guthaus, Matthew R and Ringenberg, Jeffrey S and Ernst, Dan and Austin, Todd M and Mudge, Trevor and Brown, Richard B},
	month = dec,
	year = {2001},
	pages = {12},
}

@techreport{guan_improving_2013,
	type = {Technical {Repport}},
	title = {Improving the {Scheduling} of {Certiﬁable} {Mixed}-{Criticality} {Sporadic} {Task} {Systems}},
	abstract = {An increasing trend in embedded system design is to integrate components with different levels of criticality into a shared hardware platform for better cost and power efﬁciency. Such mixed-criticality systems are subject to certiﬁcations at different levels of rigorousness, for validating the correctness of different subsystems on various conﬁdence levels. The realtime scheduling of certiﬁable mixed-criticality systems has been recognized to be a challenging problem, where using traditional scheduling techniques may result in unacceptable resource waste. In this paper we present an algorithm called PLRS to schedule certiﬁable mixed-criticality sporadic tasks systems. PLRS uses ﬁxed-job-priority scheduling, and assigns job priorities by exploring and balancing the asymmetric effects between the workload on different criticality levels. Comparing with the state-of-the-art algorithm by Li and Baruah for such systems, which we refer to as LB, PLRS is both more effective and more efﬁcient: (i) The schedulability test of PLRS not only theoretically dominates, but also on average signiﬁcantly outperforms LB’s. (ii) The run-time complexity of PLRS is polynomial (quadratic in the number of tasks), which is much more efﬁcient than the pseudo-polynomial run-time complexity of LB.},
	language = {en},
	author = {Guan, Nan and Ekberg, Pontus and Stigge, Martin and Yi, Wang},
	year = {2013},
	pages = {12},
}

@inproceedings{burns_towards_2013,
	title = {Towards {A} {More} {Practical} {Model} for {Mixed} {Criticality} {Systems}},
	abstract = {Mixed Criticality Systems (MCSs) have been the focus of considerable study over the last six years. This work has lead to the deﬁnition of a standard model that allows processors to be shared efﬁciently between tasks of different criticality levels. Key aspects of this model are that a system is deemed to execute in one of a small number of criticality modes; initially the system is in the lowest criticality mode, but if any task executes for more than its predeﬁned budget for this criticality level then a mode change is made to a higher criticality mode and all tasks of the lowest criticality level are abandoned (aborted). The initial criticality level is never revisited. This model has been useful in deﬁning key properties of MCSs, but it does not form a useful basis for an actual implementation of a MCS. In this paper we consider the tradeoffs stemming from a consideration of what systems engineers require at run-time and the actual properties of the model that scheduling analysis guarantees. Alternative models are deﬁned that allow low criticality tasks to continue to execute after a criticality mode change. The paper also addresses robust priority assignment.},
	language = {en},
	author = {Burns, A and Baruah, S K},
	year = {2013},
	pages = {6},
}

@techreport{gerum_xenomai_2004,
	title = {Xenomai - {Implementing} a {RTOS} emulation framework on {GNU}/{Linux}},
	abstract = {Generally speaking, the Xenomai technology first aims at helping application designers relying on traditional RTOS to move as smoothly as possible to a GNU/ Linux-based execution environment, without having to rewrite their application entirely.},
	language = {en},
	institution = {Xenomai},
	author = {Gerum, Philippe},
	year = {2004},
	pages = {12},
}

@inproceedings{rohou_pitfalls_2010,
	address = {Saint Malo, France},
	title = {The {Pitfalls} of {Benchmarking} with {Applications}},
	abstract = {Application benchmarking is a widely trusted method of performance evaluation. Compiler developers rely on them to assess the correctness and performance of their optimizations; computer vendors use them to compare their respective machines; processor architects run them to tune innovative features, and — to a lesser extent — to validate their correctness. Benchmarks must reﬂect actual workloads of interest, and return a synthetic measure of “performance”. Often, benchmarks are simply a collection of real-world applications run as black boxes. We identify a number of pitfalls that derive from using applications as benchmarks, and we illustrate them with a popular, freely available, benchmark suite. In particular, we advocate the fact that correctness should be deﬁned by an expert of the application domain, and the test should be integrated in the benchmark.},
	language = {en},
	author = {Rohou, Erven and Lafage, Thierry},
	year = {2010},
	pages = {11},
}

@techreport{brown_how_2010,
	title = {How fast is fast enough? {Choosing} between {Xenomai} and {Linux} for real-time applications},
	abstract = {We needed data to help ourselves and our clients to decide when to expend the extra eﬀort to use a real-time extension such as Xenomai; when it is suﬃcient to use mainline Linux with the PREEMPT RT patches applied; and when unpatched mainline Linux is suﬃcient.},
	language = {en},
	author = {Brown, Dr Jeremy H and Martin, Brad},
	year = {2010},
	pages = {17},
}

@inproceedings{blin_understanding_2016,
	address = {Marakech, Morocco},
	title = {Understanding the {Memory} {Consumption} of the {MiBench} {Embedded} {Benchmark}},
	abstract = {Complex embedded systems today commonly involve a mix of real-time and best-eﬀort applications. The recent emergence of small low-cost commodity multi-core processors raises the possibility of running both kinds of applications on a single machine, with virtualization ensuring that the best-eﬀort applications cannot steal CPU cycles from the real-time applications. Nevertheless, memory contention can introduce other sources of delay, that can lead to missed deadlines. In this paper, we analyze the sources of memory consumption for the real-time applications found in the MiBench embedded benchmark suite.},
	language = {en},
	publisher = {Netys},
	author = {Blin, Antoine and Courtaud, Cédric and Sopena, Julien and Lawall, Julia and Muller, Gilles},
	year = {2016},
	pages = {16},
}

@inproceedings{baruah_scheduling_2012,
	title = {Scheduling real-time mixed-criticality jobs},
	volume = {61},
	abstract = {Many safety-critical embedded systems are subject to certiﬁcation requirements; some systems may be required to meet multiple sets of certiﬁcation requirements, from diﬀerent certiﬁcation authorities. Certiﬁcation requirements in such “mixed-criticality” systems give rise to interesting scheduling problems, that cannot be satisfactorily addressed using techniques from conventional scheduling theory. In this paper, we study a formal model for representing such mixed-criticality workloads. We demonstrate ﬁrst the intractability of determining whether a system speciﬁed in this model can be scheduled to meet all its certiﬁcation requirements, even for systems subject to two sets of certiﬁcation requirements. Then we quantify, via the metric of processor speedup factor, the eﬀectiveness of two techniques, reservation-based scheduling and priority-based scheduling, that are widely used in scheduling such mixedcriticality systems, showing that the latter of the two is superior to the former. We also show that the speedup factors are tight for these two techniques.},
	language = {en},
	publisher = {IEEE},
	author = {Baruah, Sanjoy and Bonifaci, Vincenzo and D’Angelo, Gianlorenzo and Li, Haohan and Marchetti-Spaccamela, Alberto and Megow, Nicole and Stougie, Leen},
	year = {2012},
	pages = {1140--1152},
}

@misc{baruah_why_nodate,
	title = {Why real-time scheduling theory still matters},
	language = {en},
	author = {Baruah, Sanjoy},
}

@article{baruah_mixed_2009,
	title = {Mixed criticality schedulability analysis is highly intractable},
	url = {http://www.cs.unc.edu/baruah/Pubs.shtml},
	language = {en},
	author = {Baruah, Sanjoy},
	year = {2009},
	pages = {7},
}

@techreport{burns_mixed_2018,
	title = {Mixed {Criticality} {Systems} - {A} {Review}∗},
	abstract = {This review covers research on the topic of mixed criticality systems that has been published since Vestal’s 2007 paper. It covers the period up to and including December 2017. The review is organised into the following topics: introduction and motivation, models, single processor analysis (including job-based, hard and soft tasks, ﬁxed priority and EDF scheduling, shared resources and static and synchronous scheduling), multiprocessor analysis, related topics, realistic models, formal treatments, systems issues and industrial practice.},
	language = {en},
	author = {Burns, Alan and Davis, Robert I},
	month = jan,
	year = {2018},
	pages = {72},
}

@inproceedings{li_global_2012,
	title = {Global mixed-criticality scheduling on multiprocessors},
	abstract = {The scheduling of mixed-criticality implicit-deadline sporadic task systems on identical multiprocessor platforms is considered, when inter-processor migration is permitted. A scheduling algorithm is derived and proved correct, and its properties investigated. Theoretical analysis (in the form of both a speedup factor and sufﬁcient schedulability conditions) as well as extensive simulation experiments serve to demonstrate its effectiveness.},
	language = {en},
	publisher = {IEEE},
	author = {Li, Haohan and Baruah, Sanjoy},
	year = {2012},
	pages = {166--175},
}

@inproceedings{kritikakou_multiplexing_2016,
	address = {Göteborg, Sweden},
	title = {Multiplexing {Adaptive} with {Classic} {AUTOSAR}? {Adaptive} {Software} {Control} to {Increase} {Resource} {Utilization} in {Mixed}-{Critical} {Systems}},
	abstract = {Automotive embedded systems need to cope with antagonist requirements: on the one hand, the users and market pressure push car manufacturers to integrate more and more services that go far beyond the control of the car itself. On the other hand, recent standardization efforts in the safety domain has led to the development of the ISO 26262 norm that deﬁnes means and requirements to ensure the safe operation of automotive embedded systems. In particular, it led to the deﬁnition of ASIL (Automotive Safety and Integrity Levels), i.e., it formally deﬁnes several criticality levels. Handling the increased complexity of new services makes new architectures, such as multi or many-cores, appealing choices for the car industry. Yet, these architectures provide a very low level of timing predictability due to shared resources, which goes in contradiction with timing guarantees required by ISO 26262.},
	language = {en},
	author = {Kritikakou, Angeliki and Marty, Thibaut and Pagetti, Claire and Rochange, Christine and Lauer, Michaël and Roy, Matthieu},
	year = {2016},
	pages = {6},
}

@inproceedings{augier_real-time_2006,
	title = {Real-{Time} {Scheduling} in a {Virtualized} {Environment}},
	abstract = {In a virtualized real-time environment, a RTOS can run in parallel with a commodity OS with negligible overhead. Real-time properties of the RTOS are guaranteed by giving it and its tasks the highest priority over CPU utilization. The isolation between the OSes and the highest priority given to the RTOS can lead, however, to a misuse of the CPU resource and high-latency of the other OS tasks. These issues come from the lack of a global vision of the system scheduling needs as each OS schedules its own tasks. We propose to move task scheduling into the virtual machine monitor. There, the Scheduler Virtual Device is in charge of scheduling all the tasks independantly of their hosting OS.},
	language = {en},
	publisher = {University of York},
	author = {Augier, Christophe and Armand, Francois and Muller, Gilles},
	year = {2006},
	pages = {4},
}

@inproceedings{anderson_multicore_2009,
	title = {Multicore {Operating}-{System} {Support} for {Mixed} {Criticality}},
	volume = {4},
	abstract = {Ongoing research is discussed on the development of operating-system support for enabling mixed-criticality workloads to be supported on multicore platforms. This work is motivated by avionics systems in which such workloads occur. In the mixed-criticality workload model that is considered, task execution costs may be determined using more-stringent methods at high criticality levels, and lessstringent methods at low criticality levels. The main focus of this research effort is devising mechanisms for providing “temporal isolation” across criticality levels: lower levels should not adversely “interfere” with higher levels.},
	language = {en},
	publisher = {Citeseer},
	author = {Anderson, James H and Baruah, Sanjoy K and Brandenburg, Bjorn B},
	year = {2009},
	pages = {11},
}

@inproceedings{cerqueira_comparison_2013,
	title = {A {Comparison} of {Scheduling} {Latency} in {Linux}, {PREEMPT} {RT}, and {LITMUSRT}},
	abstract = {Scheduling latency under Linux and its principal real-time variant, the PREEMPT RT patch, are typically measured using cyclictest, a tracing tool that treats the kernel as a black box and directly reports scheduling latency. LITMUSRT, a real-time extension of Linux focused on algorithmic improvements, is typically evaluated using Feather-Trace, a ﬁnedgrained tracing mechanism that produces a comprehensive overhead proﬁle suitable for overhead-aware schedulability analysis. This difference in tracing tools and output has to date prevented a direct comparison. This paper reports on a port of cyclictest to LITMUSRT and a case study comparing scheduling latency on a 16-core Intel platform. The main conclusions are: (i) LITMUSRT introduces only minor overhead itself, but (ii) it also inherits mainline Linux’s severe limitations in the presence of I/O-bound background tasks.},
	language = {en},
	publisher = {SYSGO AG},
	author = {Cerqueira, Felipe and Brandenburg, Bjorn B},
	year = {2013},
	pages = {19--29},
}

@article{lozi_linux_2016,
	series = {{EuroSys}'16},
	title = {The {Linux} {Scheduler}: a {Decade} of {Wasted} {Cores}},
	doi = {http://dx.doi.org/10.1145/2901318.2901326},
	abstract = {As a central part of resource management, the OS thread scheduler must maintain the following, simple, invariant: make sure that ready threads are scheduled on available cores. As simple as it may seem, we found that this invariant is often broken in Linux. Cores may stay idle for seconds while ready threads are waiting in runqueues. In our experiments, these performance bugs caused many-fold performance degradation for synchronization-heavy scientiﬁc applications, 13\% higher latency for kernel make, and a 1423\% decrease in TPC-H throughput for a widely used commercial database. The main contribution of this work is the discovery and analysis of these bugs and providing the ﬁxes. Conventional testing techniques and debugging tools are ineffective at conﬁrming or understanding this kind of bugs, because their symptoms are often evasive. To drive our investigation, we built new tools that check for violation of the invariant online and visualize scheduling activity. They are simple, easily portable across kernel versions, and run with a negligible overhead. We believe that making these tools part of the kernel developers’ tool belt can help keep this type of bug at bay.},
	language = {en},
	author = {Lozi, Jean-Pierre and Gaud, Fabien and Lepers, Baptiste and Quema, Vivien and Funston, Justin and Fedorova, Alexandra},
	year = {2016},
	pages = {16},
}

@article{kritikakou_dynascore:_2017,
	title = {{DYNASCORE}: {DYNAmic} {Software} {COntroller} to {Increase} {REsource} {Utilization} in {Mixed}-{Critical} {Systems}},
	volume = {23},
	issn = {10844309},
	shorttitle = {{DYNASCORE}},
	url = {http://dl.acm.org/citation.cfm?doid=3149546.3110222},
	doi = {10.1145/3110222},
	language = {en},
	number = {2},
	urldate = {2018-07-05},
	journal = {ACM Transactions on Design Automation of Electronic Systems},
	author = {Kritikakou, Angeliki and Marty, Thibaut and Roy, Matthieu},
	year = {2017},
	pages = {1--26},
}

@article{daghsen_applying_2012,
	title = {Applying {Holistic} {Distributed} {Scheduling} to {AUTOSAR} {Methodology}},
	abstract = {AUTOSAR initiative continues to envoy success in the automotive software domain by providing a common framework for efficient software development and by the integration and reuse of software components. However, additional work is needed to consider non-functional properties in the development cycle. Recent release of AUTOSAR has defined a common language to define timingrelated information for the automotive embedded system across all development layers.},
	language = {en},
	author = {Daghsen, Ahmed and Chaaban, Khaled and Saudrais, Sébastien and Leserf, Patrick},
	year = {2012},
	pages = {9},
}

@misc{noauthor_xenomai_nodate,
	title = {Xenomai - {Generals}},
	url = {http://www.cs.ru.nl/lab/xenomai/doc.html},
	urldate = {2019-02-22},
}

@article{goos_midatasets:_2007,
	series = {Springer},
	title = {{MiDataSets}: {Creating} the {Conditions} for a {MoreRealistic} {Evaluation} of {Iterative} optimization},
	volume = {2},
	issn = {0302-9743},
	language = {en},
	journal = {International Conference, HiPEAC Proceedings},
	author = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Rangan, C Pandu and Steffen, Bernhard},
	month = jan,
	year = {2007},
	pages = {245--260},
}

@inproceedings{kaldewey_firm_2006,
	address = {San Jose, USA},
	title = {Firm {Real}-{Time} {Processing} in an {Integrated} {Real}-{Time} {System}},
	volume = {12},
	abstract = {We explore the integration of firm real-time processing— where processing completed after its deadline has no value but some jobs may be terminated or skipped— into an integrated real-time system managing hard, soft, and non-real-time processes. We show that it is feasible to add firm real-time processing to an integrated environment and that concurrently executing soft real-time processes can benefit from the slack made available from dropped firm real-time jobs. We examine how dropping jobs of firm real-time tasks using different static and dynamic drop patterns reduces deadline misses of soft real-time tasks. Our results show that even a simple static drop pattern results in noticeable performance gain for other soft real-time processes and we argue that our dynamic approach, once implemented, will produce even better results.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Kaldewey, Tim and Lin, Caixue and Brandt, Scott},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{wu_schedulability_2006,
	address = {San Jose, USA},
	title = {On {Schedulability} {Bounds} of {Weighted} {Round} {Robin} {Schedulers}},
	abstract = {We derive a closed-formed schedulability bound for weighted round robin schedulers. The schedulability bound is parameterized for protocol overhead ratio D which measures the portion of time consumed in protocol operations per round, normalized token rotation frequency J which measures the number of token rotations per Dmin (the shortest relative deadline of the tasks) time interval, the normalized deadline k , which measures the tightness of deadline assignment, the tasks set workload smoothness P which measures the burstness of the workload. Individual schedulability bounds can be easily obtained by simply plugging in these parameters.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Wu, Jianjia and Liu, Jyh-Charn and Zhao, Wei},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{scheler_synthesising_2006,
	address = {San Jose, USA},
	title = {Synthesising {Real}-{Time} {Systems} from {Atomic} {Basic} {Blocks}},
	abstract = {Whether a real-time system is implemented as timetriggered or event-triggered system is constituted quite early in the development process of real-time systems. Unfortunately, different task models are associated inseparably with these real-time architectures. This makes it very hard to migrate from time-triggered to event-triggered systems and vice versa, also the reuse of individual eventhandlers of a real-time system is prohibited by this fact. In this paper we point out that there is no need to prefer a certain real-time architecture in many cases. Therefore, we sketch an architecture-independent representation of realtime systems based on so called atomic basic blocks (ABB). These ABBs allow to describe reusable event-handlers that are composed into the ﬁnal real-time system by an automated synthesis.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Scheler, Fabian and Schröder-Preikschat, Wolfgang},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{rohloff_hierarchical_2006,
	address = {San Jose, USA},
	title = {A {Hierarchical} {Control} {System} for {Dynamic} {Resource} {Management}},
	abstract = {We present a hierarchical control system for the dynamic resource management of a distributed real-time embedded (DRE) system. This DRE is inspired by the DARPA Adaptive and Reﬂective Middleware Systems (ARMS) program. The goal of the control system is to simultaneously manage multiple resources and QoS concerns. The control system is scalable and uses a utility-driven approach for decisionmaking and performance evaluation. The control system is designed to be easily adaptable to other multi-tiered DRE systems.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Rohloff, Kurt and Ye, Jianming and Loyall, Joseph and Schantz, Richard and St, Moulton},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{povzner_supporting_2006,
	address = {San Jose, USA},
	title = {Supporting {Rate}-{Based} {Processes} in an {Integrated} {System}},
	abstract = {As real-time applications are becoming common in general-purpose computing systems, scheduling solutions have been developed to support processes with a variety of different timeliness constraints in an integrated way. In this paper, we identify a separate category of soft realtime processes, called rate-based processes, and investigate the ways to add the support of this class of processes into an integrated system. We consider rate-based processes as a separate class of soft real-time processes because they do not have timing constraints in the form of deadlines. Instead, they have continuous processing requirements in terms of the constant rate. The goal of the efﬁcient scheduling mechanism for rate-based processes as part of an integrated system is to provide good overall system performance (good performance of all classes of processes in the system) while maintaining the required throughput of rate-based processes.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Povzner, Anna and Lin, Caixue and Brandt, Scott A},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{lin_multi-round_2006,
	address = {San Jose, USA},
	title = {Multi-{Round} {Real}-{Time} {Divisible} {Load} {Scheduling} for {Clusters}},
	abstract = {Cluster Computing has emerged as a new paradigm for solving large-scale problems. To enhance QoS and provide performance guarantees in cluster computing environments, various workload models and real-time scheduling algorithms have been investigated. The divisible load model, propagated by divisible load theory, models computations that can be arbitrarily divided into independent pieces and provides a good approximation of many real-world applications. However, the problem of providing performance guarantees to divisible load applications has not been thoroughly investigated. Therefore, this paper presents our ongoing work to extend multi-round divisible load theory to provide deterministic QoS to arbitrarily divisible applications executing in a cluster.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Lin, Xuan and Lu, Ying and Deogun, Jitender and Goddard, Steve},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{lam_timed_2006,
	address = {San Jose, USA},
	title = {On {Timed} {Zero} {Knowledge} {Proof} ({ZKP}) {Protocols} ({Preliminary} {Results})},
	abstract = {A major application of zero knowledge proof (ZKP) protocols is for authetnication of anonymous users. Many ZKP protocols also control anonymity quota so that any excessive use of authorized tokens issued to the user (prover) will allow the authenticator (veriﬁer) to decipher the user identity unambiguously. ZKP has great potentials to be used for creating spoof-free trust chains among hostile peer computing systems. Given the critical nature of trust chains, the temporal behaviors and the operational overheads of ZKP need to be adequately addressed. In this work-in-progress article, we report preliminary results on how to guarantee the security properties of timed ZKP (TZKP) protocols locked into the logical clocks for session based resource access. Preliminary ﬁndings suggest that security vulnerability can be prevented with reduced overheads after proper reﬁnements to the disposable authentication protocols.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Lam, T C and Liu, Jyh-Charn},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{kim_policy_2006,
	address = {San Jose, USA},
	title = {Policy {Construction} and {Validation} for {Energy} {Minimization} in {Cross} {Layered} {Systems}: {A} {Formal} {Method} {Approach}},
	abstract = {The highly dynamic nature and stringent timing constraints of distributed, real-time, and embedded (DRE) systems lead to complex cross-layer interactions and valid designs must satisfy a multitude of constraints. In this paper, we focus our attention on design validation considering multidimensional interoperability in the context of cross-layer approaches for power optimization under timing constraints in distributed mobile systems. Specifically, we (i) formally specify each layer of abstraction in consort with timing and energy properties, and (ii) evaluate an optimized policy for design validation as well as provide a time-energy critical path for further optimization that will cost-effectively address the Quality of Service (QoS)/performance tradeoffs. By providing a design flow that includes both timing verification and cross layer optimization, we can achieve (i) timing guarantees for design verification, (ii) better optimizations for resource management, and (iii) adaptive parameter settings for resource sharing and energy minimization. We present preliminary results on an MPEG application.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Kim, Minyoung and Dutt, Nikil and Venkatasubramanian, Nalini},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{hu_optimal_2006,
	address = {San Jose, USA},
	title = {Optimal {Elastic} {Scheduling}},
	abstract = {This paper introduces an optimization framework for the elastic scheduling of periodic tasks. The paper rederives the original elastic scheduling algorithm in [6] as the solution to an optimization problem that seeks to minimize the squared deviation of a task’s utilization from initial desired utilization. We apply this approach to develop a closedform formula for determining task periods to minimize the average difference of task period from a desired minimum period.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Hu, Xiaobo Sharon and Chantem, Thidapat and Lemmon, M D},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{colmenares_component_2006,
	address = {San Jose, USA},
	title = {A {Component} {Framework} for {Real}-time {Java}},
	abstract = {The Real-time Speciﬁcation for Java (RTSJ) offers predictable memory management and scheduling required for real-time applications. However, the usage of its memory model is difﬁcult for standard Java developers, who are accustomed to automatic memory management. Components offer the opportunity to hide the complexities of the RTSJ’s memory model, in addition to beneﬁts such as reusability and modularity. To this end, we propose a component framework that brings together the ease of programming in Java and the predictability of RTSJ.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Colmenares, Juan A and Gorappa, Shruti and Panahi, Mark and Klefstad, Raymond},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{chen_providing_2006,
	address = {San Jose, USA},
	title = {Providing {Fault}-{Tolerance} through a {Distributed} {Coordination} {Model} for {Open} {Distributed} {Embedded} {Systems}},
	abstract = {Open distributed and embedded (ODE) systems by nature have rigid Quality of Service (QoS) requirements, such as real-time constraints, reliability, and fault-tolerance requirements. An Actor, Role, Coordinator (ARC) model is proposed [8] to model such software systems as compositions of concurrent computation and coerced coordination. In this paper, we present a framework based on the ARC model, called ARC-AA. The framework is an extension of the Actor Architecture framework [6]. It supports groupwised and decentralized coordination among distributed actors, and the QoS requirements inherent in an ODE system are achieved through the coerced coordination. We focus on fault-tolerance features of the model. In particular, two types of failures, i.e., actor, role, and coordinator crash failures, and timing failures are handled in the ARCAA framework.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Chen, Nianen and Poirot, Pierre-Etienne and Ren, Shangping},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{brogioli_design_2006,
	address = {San Jose, USA},
	title = {Design and {Analysis} of {Heterogeneous} {DSP}/{FPGA} {Based} {Architectures} for {3GPP} {Wireless} {Systems}},
	abstract = {This paper shows how iterative hardware/software partitioning in heterogeneous DSP/FPGA based embedded systems can be utilized to achieve real-time deadlines of modern 3GPP wireless equalization workloads. By utilizing a well deﬁned set of application partitioning criteria in tandem with SOC simulation tools, we are able to show a greater than six fold improvement in application performance and ultimately meet, and even exceed real-time data processing deadlines.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Brogioli, Michael C and Gadhiok, Manik and Cavallaro, Joseph R},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{bonakdarpour_automated_2006,
	address = {San Jose, USA},
	title = {Automated {Revision} of {Legacy} {Real}-{Time} {Programs}: {Work} in {Progress}},
	abstract = {In this paper, we focus on the problem of automatic revision of legacy real-time programs. We consider this problem in two contexts. First, we investigate the problem of automated addition of properties expressed in Metric Temporal Logic (MTL) formulas to existing real-time programs modeled in Alur and Dill timed automata. Then, we consider transformation problems, where we design synthesis methods to add fault-tolerance to existing fault-intolerant realtime programs. While both problems have been addressed in the literature for untimed programs in theory and practice, there is much to be done for real-time programs. To this end, we concentrate on ﬁlling the gap between theory and practice of automated methods for synthesizing realtime programs by characterizing the class of real-time programs and properties, where program synthesis is practically feasible.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Bonakdarpour, Borzoo and Kulkarni, Sandeep S},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{bimbard_feasibility_2006,
	address = {San Jose, USA},
	title = {Feasibility {Conditions} with {Kernel} {Overheads} for {Mixed} {Preemptive} and {Non}-{Preemptive} {Periodic} {Tasks} with {FP}/{FIFO} {Scheduling} on an {Event} {Driven} {OSEK} {System}},
	abstract = {In this paper, we propose extended real-time feasibility conditions, taking into account kernel overheads for mixed preemptive and nonpreemptive periodic tasks scheduled with Fixed Priority FP/FIFO scheduling, where FIFO is used to arbitrate tasks having the same ﬁxed priority. The kernel considered in this paper is the event driven OSEK kernel. Our OSEK operating system is based on the OSEK-OS-speciﬁcation version 2.2 and is provided by Vector Corp. We identify the sources of overheads and show how to take them into account in the feasibility conditions. We compare the theoretical worst case response time obtained with kernel overheads to the response time obtained on a real event driven OSEK implementation. We show that the kernel overheads cannot be neglected and that the theoretical results are valid and can be used for a real-time dimensioning of an OSEK system.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Bimbard, Franck and George, Laurent},
	month = apr,
	year = {2006},
	pages = {4},
}

@inproceedings{arslan_modeling_2006,
	address = {San Jose, USA},
	title = {Modeling {Embedded} {Real}-{Time} {Applications} with {Objects} and {Events}},
	volume = {12},
	abstract = {The ability to model periodic, sporadic and aperiodic tasks in a way that ensures their timing constraints such as worst-case execution time, deadline and periodicity is a major concern in embedded real-time programming. We propose the use of a concurrent event library to achieve the predictability of embedded real-time programs while retaining the advantages of modular development and reasoning of object-oriented languages and the benefit of event-driven programming.},
	language = {en},
	publisher = {IEEE Technical Committee on Real-Time Systems},
	author = {Arslan, Volkan and Eugster, Patrick and Nienaltowski, Piotr},
	month = apr,
	year = {2006},
	pages = {4},
}

@misc{hoarau_beta_2017,
	title = {({Beta}) {Xenomai} 3.0.5 on {Ubuntu} 14.04/16.04},
	url = {https://rtt-lwr.readthedocs.io/en/latest/rtpc/xenomai3.html},
	abstract = {These instructions demonstrates how to build a Cobalt Core for Xenomai 3.0.5.

- Recommended Hardware
 -- Get the linux kernel
 -- Get Xenomai
 -- Apply Xenomai Patch
 -- Configure the kernel
 -- Build the RT Kernel
 -- Compile faster (distcc)

- Allow non-root users

- Configure GRUB and reboot
 -- Install Xenomai User space libraries

- Update your bashrc

- Test your installation
 -- Fix negative latency issues},
	language = {en},
	urldate = {2018-12-07},
	journal = {RT LWR},
	author = {Hoarau, Antoine},
	year = {2017},
}

@article{manolache_schedulability_nodate,
	title = {Schedulability analysis of {Multiprocessor} {Real}-{Time} {Applications} with {Stochastic} {Task} {Execution} {Times}},
	abstract = {This paper presents an approach to the analysis of task sets implemented on multiprocessor systems, when the task execution times are speciﬁed as generalized probability distributions. Because of the extreme complexity of the problem, an exact solution is practically impossible to be obtained even for toy examples. Therefore, our methodology is based on approximating the generalized probability distributions of execution times by Coxian distributions of exponentials. Thus, we transform the generalized semi-Markov process, corresponding to the initial problem, into a continuous Markov chain (CTMC) which, however, is extremely large and, hence, most often is impossible to be stored in memory. We have elaborated a solution which allows to generate and analyze the CTMC in an efﬁcient way, such that only a small part has to be stored at a given time. Several experiments investigate the impact of various parameters on complexity, in terms of time and memory, as well as the trade-offs regarding the accuracy of generated results.},
	language = {en},
	author = {Manolache, Sorin and Eles, Petru and Peng, Zebo},
	pages = {8},
}

@incollection{son_schedulability_2007,
	title = {Schedulability analysis of {Multiprocessor} {Sporadic} {Task} {Systems}},
	volume = {20073969},
	isbn = {978-1-58488-678-5 978-1-4200-1174-6},
	url = {http://www.crcnetbase.com/doi/abs/10.1201/9781420011746.ch3},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {Handbook of {Real}-{Time} and {Embedded} {Systems}},
	publisher = {Chapman and Hall/CRC},
	author = {Baruah, Sanjoy and Baker, Theodore},
	editor = {Son, Sang and Lee, Insup and Y-T. Leung, Joseph},
	month = jul,
	year = {2007},
	doi = {10.1201/9781420011746.ch3},
	pages = {3--1--3--17},
}

@inproceedings{baruah_schedulability_2008,
	title = {Schedulability analysis of {Sporadic} {Tasks} with {Multiple} {Criticality} {Specifications}},
	isbn = {978-0-7695-3298-1},
	url = {http://ieeexplore.ieee.org/document/4573111/},
	doi = {10.1109/ECRTS.2008.26},
	abstract = {In a paper that was presented at the recently-concluded RealTime Systems Symposium, Vestal proposed a new real-time task model that is able to represent the fact that the worst-case execution time (WCET) of a single task may be determined to different levels of accuracy with different degrees of conﬁdence. In systems with multiple criticality requirements — different tasks need to be assured of meeting their deadlines with different levels of conﬁdence — such multiple speciﬁcations of WCET may be exploited to obtain better processor utilization.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, Sanjoy and Vestal, Steve},
	month = jul,
	year = {2008},
	pages = {147--155},
}

@inproceedings{kritikakou_monitoring_2013,
	title = {Monitoring {On}-line {Timing} {Information} to {Support} {Mixed}-{Critical} {Workloads}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {http://oatao.univ-toulouse.fr/12756/},
	abstract = {Many/multi-cores architectures provide tremendous increase in computation power, increasing the possibility of executing additional tasks on the system. In critical embedded systems, e.g. aeronautical systems, the uncertainty of the non-uniform and concurrent memory access scheme prohibits the full utilization of the system potentials. Classical Worst Case Execution Time (WCET) estimation techniques upper bound the memory accesses -considering a fully congested memory bus - resulting in safe, but pessimistic, bounds. The proposed approach explores the increase in the system utilization by less critical tasks, while guaranteeing the safety of the critical task.},
	language = {en},
	urldate = {2019-01-30},
	publisher = {University of Waterloo},
	author = {Kritikakou, Angeliki and Baldellon, Olivier and Pagetti, Claire and Rochange, Christine and Roy, Matthieu and Vargas, Fabian},
	year = {2013},
	pages = {1--2},
}

@misc{noauthor_kaby_nodate,
	title = {Kaby {Lake} - {Microarchitectures} - {Intel} - {WikiChip}},
	url = {https://en.wikichip.org/wiki/intel/microarchitectures/kaby_lake#Individual_Core},
	language = {en},
	urldate = {2019-01-21},
}

@phdthesis{bethmangalkar_schedulability_1999,
	title = {Schedulability {Analysis} in {Static} {Real}-time {Systems} : priority mapping and daspcp for real-time  {CORBA}},
	language = {en},
	author = {Bethmangalkar, Ramachandra},
	year = {1999},
}

@misc{noauthor_sched_nodate,
	title = {sched - overview of scheduling {APIs} - {Linux} {Man} {Pages} (7)},
	url = {//www.systutorials.com/docs/linux/man/docs/linux/man/7-sched/},
	abstract = {\&nbsp; API summary The Linux scheduling APIs are as follows: sched\_setscheduler(2) Set the scheduling policy and parameters of a specified thread. sched\_getscheduler(2)},
	urldate = {2019-01-21},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {Style} {Repository}},
	url = {https://www.zotero.org/styles?q=ieee%20Transactions%20on%20Dep},
	urldate = {2019-01-21},
}

@inproceedings{faggioli_edf_2009,
	title = {An {EDF} scheduling class for the {Linux} kernel},
	abstract = {The Linux kernel is mainly used is general-purpose operating system, i.e., in server and/or desktop environments. During the last years, however, academic institutions and companies showed an increasing interest in using it for real-time and control applications as well.},
	language = {en},
	author = {Faggioli, Dario and Checconi, Fabio and Trimarchi, Michael and Scordino, Claudio},
	year = {2009},
	pages = {8},
}

@article{pabla_completely_2009,
	title = {Completely {Fair} {Scheduler}},
	volume = {2009},
	issn = {1075-3583},
	url = {http://dl.acm.org/citation.cfm?id=1594371.1594375},
	abstract = {Linux's latest scheduler makeover.},
	number = {184},
	urldate = {2019-01-18},
	journal = {Linux J.},
	author = {Pabla, Chandandeep Singh},
	month = aug,
	year = {2009},
}

@inproceedings{bril_worst-case_2007,
	title = {Worst-{Case} {Response} {Time} {Analysis} of {Real}-{Time} {Tasks} under {Fixed}-{Priority} {Scheduling} with {Deferred} {Preemption} {Revisited}},
	isbn = {978-0-7695-2914-1},
	url = {http://ieeexplore.ieee.org/document/4271700/},
	doi = {10.1109/ECRTS.2007.38},
	abstract = {Fixed-priority scheduling with deferred preemption (FPDS) has been proposed in the literature as a viable alternative to ﬁxed-priority preemptive scheduling (FPPS), that both reduces the cost of arbitrary preemptions and removes the need for non-trivial resource access protocols.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Bril, Reinder J. and Lukkien, Johan J. and Verhaegh, Wim F.J.},
	month = jul,
	year = {2007},
	keywords = {WCET},
	pages = {269--279},
}

@article{wilhelm_worst-case_2008,
	title = {The worst-case execution-time problem—overview of methods and survey of tools},
	volume = {7},
	issn = {15399087},
	url = {http://portal.acm.org/citation.cfm?doid=1347375.1347389},
	doi = {10.1145/1347375.1347389},
	language = {en},
	number = {3},
	urldate = {2018-07-05},
	journal = {ACM Transactions on Embedded Computing Systems},
	author = {Wilhelm, Reinhard and Mitra, Tulika and Mueller, Frank and Puaut, Isabelle and Puschner, Peter and Staschulat, Jan and Stenström, Per and Engblom, Jakob and Ermedahl, Andreas and Holsti, Niklas and Thesing, Stephan and Whalley, David and Bernat, Guillem and Ferdinand, Christian and Heckmann, Reinhold},
	month = apr,
	year = {2008},
	keywords = {WCET},
	pages = {1--53},
}

@article{autosar_methodology_2016,
	title = {Methodology},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {520},
}

@article{autosar_overview_2016,
	title = {Overview of {Functional} {Safety} {Measures} in {AUTOSAR}},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {96},
}

@article{autosar_guide_2014,
	title = {Guide to {Multi}-{Core} {Systems}},
	language = {en},
	journal = {Release 4.1 Rev 3},
	author = {AUTOSAR},
	year = {2014},
	pages = {28},
}

@article{autosar_guide_2016,
	title = {Guide to {BSW} {Distribution}},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {46},
}

@article{autosar_timing_2016,
	title = {Timing {Analysis}},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {118},
}

@article{autosar_software_2016,
	title = {Software {Component} {Template}},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {1052},
}

@article{autosar_specification_2016,
	title = {Specification of {BSW} {Module} {Description} {Template}},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {341},
}

@article{autosar_specification_2017,
	title = {Specification of {Timing} {Extensions}},
	language = {en},
	journal = {Standard Release 4.3.1},
	author = {AUTOSAR},
	year = {2017},
	pages = {219},
}

@article{autosar_technical_2016,
	title = {Technical {Safety} {Concept} {Status} {Report}},
	issn = {AUTOSAR\_TR\_SafetyConceptStatusReport},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {59},
}

@article{autosar_specification_2016-1,
	title = {Specification of {RTE}},
	issn = {AUTOSAR\_SWS\_RTE},
	language = {en},
	journal = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {1116},
}

@techreport{autosar_virtual_2016,
	title = {Virtual {Functional} {Bus}},
	language = {en},
	number = {Standard Release 4.3.0},
	author = {AUTOSAR},
	year = {2016},
	pages = {104},
}

@incollection{hutchison_otawa:_2010,
	address = {Berlin, Heidelberg},
	title = {{OTAWA}: {An} {Open} {Toolbox} for {Adaptive} {WCET} {Analysis}},
	volume = {6399},
	isbn = {978-3-642-16255-8 978-3-642-16256-5},
	shorttitle = {{OTAWA}},
	url = {http://link.springer.com/10.1007/978-3-642-16256-5_6},
	abstract = {The analysis of worst-case execution times has become mandatory in the design of hard real-time systems: it is absolutely necessary to know an upper bound of the execution time of each task to determine a task schedule that insures that deadlines will all be met. The OTAWA toolbox presented in this paper has been designed to host algorithms resulting from research in the domain of WCET analysis so that they can be combined to compute tight WCET estimates. It features an abstraction layer that decouples the analyses from the target hardware and from the instruction set architecture, as well as a set of functionalities that facilitate the implementation of new approaches.},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {Software {Technologies} for {Embedded} and {Ubiquitous} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ballabriga, Clément and Cassé, Hugues and Rochange, Christine and Sainrat, Pascal},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Min, Sang Lyul and Pettit, Robert and Puschner, Peter and Ungerer, Theo},
	year = {2010},
	doi = {10.1007/978-3-642-16256-5_6},
	keywords = {WCET},
	pages = {35--46},
}

@phdthesis{bertogna_real-time_2007,
	address = {Italie},
	title = {Real-{Time} {Scheduling} {Analysis} for {Multiprocessor} {Platforms}},
	language = {en},
	school = {Scuola Superiore Sant’Anna, Pisa},
	author = {Bertogna, Marko},
	year = {2007},
}

@inproceedings{mckinney_impact_2001,
	title = {Impact of commercial off-the-shelf ({COTS}) software on the interface between systems and software engineering},
	isbn = {978-1-58113-074-4},
	url = {http://portal.acm.org/citation.cfm?doid=302405.302721},
	doi = {10.1145/302405.302721},
	language = {en},
	urldate = {2018-07-05},
	publisher = {ACM Press},
	author = {McKinney, Dorothy},
	year = {2001},
	pages = {627--628},
}

@phdthesis{cotard_contribution_2013,
	address = {Nantes Angers Le Mans - France},
	title = {Contribution à la robustesse des systèmes temps reel embarques multicœur automobile},
	language = {fr},
	school = {Université de Nantes Angers Le Mans},
	author = {Cotard, Sylvain},
	year = {2013},
}

@article{gustavo_concierge:_nodate,
	title = {Concierge: {A} {Service} {Platform} for {Resource}-{Constrained} {Devices}},
	abstract = {As mobile and embedded devices become widespread, the management and conﬁguration of the software in the devices is increasingly turning into a critical issue. OSGi is a business standard for the life cycle management of Java software components. It is based on a service oriented architecture where functional units are decoupled and components can be managed independently of each other. However, the focus continuously shifts from the originally intended area of small and embedded devices towards large-scaled enterprise systems. As a result, implementations of the OSGi framework are increasingly becoming more heavyweight and less suitable for smaller computing devices. In this paper, we describe the experience gathered during the design of Concierge, an implementation of the OSGi speciﬁcation tailored to resource-constrained devices. Comprehensive benchmarks show that Concierge performs better than existing implementations and consumes less resources.},
	language = {en},
	author = {Gustavo, Alonzo and Rellermeyer, Jan S.},
	pages = {14},
}

@misc{intel_improving_2015,
	title = {Improving {Real}-{Time} {Performance} by {Utilizing} {Cache} {Allocation} {Technology}},
	language = {en},
	publisher = {Intel},
	author = {Intel},
	year = {2015},
}

@misc{noauthor_process_nodate,
	title = {Process 'niceness' vs. 'priority'},
	url = {https://askubuntu.com/questions/656771/process-niceness-vs-priority},
	urldate = {2019-01-16},
	journal = {Ask Ubuntu},
}

@article{schwaderer_dr._2014,
	title = {Dr. {Udo} {Brockmeyer}, {CEO}, {BTC} {Embedded} {Systems} {AG}},
	language = {en},
	author = {Schwaderer, Curt},
	year = {2014},
	pages = {38},
}

@misc{noauthor_erts_2018_proceedings_20180105.pdf_2018,
	title = {{ERTS}\_2018\_Proceedings\_20180105.pdf},
	year = {2018},
}

@phdthesis{li_scheduling_2013,
	title = {Scheduling {Mixed}-criticality {Real}-time systems},
	abstract = {This dissertation addresses the following question to the design of scheduling policies and resource allocation mechanisms in contemporary embedded systems that are implemented on integrated computing platforms:  in a multitasking system where it is hard to estimate a task’s worst-case execution time, how do we assign task priorities so that 1) the safety-critical tasks are asserted to be completed within a specified length of time, and 2) the non-critical tasks are also guaranteed to be completed within a predictable length of time if no task is actually consuming time at the worst case? This  dissertation  tries  to  answer  this  question  based  on  the  mixed-criticality  real-time system model, which defines multiple worst-case execution scenarios, and demands a scheduling policy to provide provable timing guarantees to each level of critical tasks with respect to each type of scenario.  Two scheduling algorithms are proposed to serve this model.  The OCBP algorithm is aimed at discrete one-shot tasks with an arbitrary number of criticality levels.  The EDF-VD algorithm is aimed at recurrent tasks with two criticality levels (safety-critical and non-critical).  Both algorithms are proved to optimally minimize the percentage of computational resource waste within two criticality levels.  More in-depth investigations to the relationship among the computational resource requirement of different criticality levels are also provided for both algorithms.},
	language = {en},
	school = {University of North Carolina at Chapel Hill},
	author = {Li, Haohan},
	year = {2013},
}

@inproceedings{palencia_schedulability_1998,
	title = {Schedulability analysis for tasks with static and dynamic offsets},
	abstract = {In this paper we present an extension to current schedulability analysis techniques for periodic tasks with offsets, scheduled under a preemtive fixed priority scheduler. Previous techniques allowed only static offstets restricted to being smaller than the task periods. With the extension presentid in this paper, we eliminate this restriction and we alow both static and dynamic offsets. The most significant application of this extension is in the analysis of multiprocessor and distributed systems. We show that we  can achieve a significant increase of the maximum schedulable utilization by using the new technique, as opposed to using previously known worst-case analysis techniques for distributed systems.},
	booktitle = {Real-{Time} {Systems} {Symposium}, 1998. {Proceedings}. {The} 19th {IEEE}},
	publisher = {IEEE},
	author = {Palencia, José Carlos and Harbour, M. González},
	year = {1998},
	pages = {26--37},
}

@article{autosar_flexible_nodate,
	title = {Flexible post-build configuration of {AUTOSAR} gateways},
	abstract = {The post-build process provides flexibility when changes are made in the communication description. Configuration is even possible in late development phases during ECU integration or in the field. This approach is especially useful for gateway ECUs, since it is possible to adapt them to modified network conditions without having to change the complete application code. However, the increased resource requirements must be taken into account. In any event, a gateway ECU is an interesting candidate for the post-build process, at least during the development phase.},
	language = {en},
	author = {AUTOSAR},
	pages = {5},
}

@misc{object_management_group_corba_2006,
	title = {{CORBA} {Component} {Model} {Specifications}},
	abstract = {This specification defines:
• The syntax and semantics of a component model (Chapter 6, “Component Model”), based on CORBA IDL, and a
corresponding meta-model (Chapter 11, “Interface Repository Metamodel”).
• A language to describe the structure and state of component implementations (Chapter 7, “OMG CIDL Syntax and
Semantics”), and a corresponding meta-model (Chapter 12, “CIF Metamodel”).
• A programming model for constructing component implementations (Chapter 8, “CCM Implementation
Framework”).
• A runtime environment for component implementations (Chapter 9, “The Container Programming Model”).
• Interaction between components and Enterprise Java Beans (Chapter 10, “Integrating with Enterprise JavaBeans”).
• Meta-data for describing component-based applications, and interfaces for their deployment (Chapter 14,
“Deployment PSM for CCM”).
• A lightweight subset of the component model, programming model and runtime environment (Chapter 13,
“Lightweight CCM Profile”).},
	author = {Object Management Group},
	year = {2006},
}

@article{jafari_scheduling_nodate,
	title = {Scheduling of {Systems} with {Mixed}-{Criticality} {Requirements}},
	language = {en},
	author = {Jafari, Zahra and Jervan, Dr Gert},
	pages = {66},
}

@article{ostberg_run_nodate,
	title = {Run time safety analysis for automotive systems in an open and adaptive environment},
	abstract = {Cooperative vehicles are no longer fiction. A key factor is the ability for vehicles to exchange information with their environment. The shared information can be used to realize new functionalities, from virtual traffic lights to emergency braking, thus with potential to increase safety and efficiency of vehicle systems. However, external information has inherent uncertainties and this poses a threat to safety. In this paper we will discuss how to handle these uncertainties by use of dynamic safety contracts. We propose an extension to AUTomotive Open System Architecture (AUTOSAR) which consists of a safety manager which actively enforces the safety rules described in such safety contract. We also propose to integrate the architecture of an Intelligent Transport System (ITS) station tightly to AUTOSAR. It is our hypothesis that such architecture provides a viable platform for run time safety assessment. Future research work is to evaluate what kind of safety assessments our system can be able to handle.},
	language = {en},
	author = {Östberg, Kenneth and Bengtsson, Magnus},
	pages = {13},
}

@phdthesis{manolache_sorin_schedulability_2002,
	title = {Schedulability {Analysis} of {Real}-{Time} {Systems} with {Stochastic} {Task} {Execution} {Times}},
	abstract = {Systems controlled by embedded computers become indispensable in our lives and can be found in avionics, automotive industry, home appliances, medicine, telecommunication industry, mecatronics, space industry, etc.
Fast, accurate and flexible performance estimation tools giving feedback to the designer in every design phase are a vital part of a design process capable to produce high quality designs of such embedded systems.
In the past decade, the limitations of models considering fixed (worst case) task execution times have been acknowledged for large application classes within soft real-time systems. A more realistic model considers the tasks having varying execution times with given probability distributions. No restriction has been imposed in this thesis on the particular type of these functions. Considering such a model, with specified task execution time probability distribution functions, an important performance indicator of the system is the expected deadline miss ratio of tasks or task graphs.
This thesis proposes two approaches for obtaining this indicator in an analytic way. The first is an exact one while the second approach provides an approximate solution trading accuracy for analysis speed. While the first approach can efficiently be applied to mono-processor systems, it can handle only very small multi-processor applications because of complexity reasons. The second approach, however, can successfully handle realistic multi-processor applications. Experiments show the efficiency of the proposed techniques.},
	school = {Department of Computer and Information Science, IDA, Linköping University},
	author = {Manolache, Sorin},
	year = {2002},
}

@misc{maegaard_development_1998,
	title = {Development of a {Safety} {Critical} {Hard} {Real}-{Time} {System} in a {World} of {Changes}},
	abstract = {This paper presents the experiences gained from the development, design and implementation approach used for the on-board application sofware for the European Robotic Arm. Rhe project has undergone dramatic changes during the implementation phase. These changes tange from change of processor and compilation system to radical functional and real-time changes. It is argued that the chosen development model using Ada tasking, priority basedpreemptive scheduling, and rate monotonic scheduling theory  has been crucial in maintaining a predictable system meeting all present requirements. The main features obtained are a coherent and loosely couple design, high maintainability, high portability, and statically analysable predictability.},
	publisher = {DASIA 98 - Data Systems in Aerospace, Proceedings of the conference held 25-28 May, 1998 in Athens, Greece. Edited by B. Kaldeich-Schü.rmann. ESA SP-422. Paris: European Space Agency., p.347},
	author = {Maegaard, C. and Beerthuizen, P.},
	year = {1998},
}

@phdthesis{lakshmanan_scheduling_2011,
	type = {phdthesis},
	title = {Scheduling and {Synchronization} for {Multi}-core {Real}-time {Systems}},
	abstract = {Multi-core processors are already prevalent in general-purpose computing systems with manufacturers currently offering up to a dozen cores per processor. Real-time and embedded systems adopting such processors gain increased computational capacity, improved parallelism, and higher performance per watt. However, using multi-core processors in real-time applications also introduces new challenges and opportunities for efficient scheduling and task synchronization. In this dissertation, we study this problem, characterize the design space, and develop an analytical and systems framework for multi-core real-time scheduling. Exploiting the co-located nature of processor cores, the general principle adopted in this thesis is to statically partition tasks among processor cores, co-allocate synchronizing tasks when possible, and introduce limited inter-core task migration and synchronization for improving system utilization as necessary. We model the multi-core real-time scheduling problem as a bin-packing problem and develop an object splitting algorithm for scheduling tasks on multi-core processors. We develop Highest-Priority Task Splitting (HPTS) to schedule independent sequential tasks on multi-core processors. We then analyze the overheads of inter-core task synchro- nization and provide mechanisms to efficiently allocate synchronizing sequential tasks on multi- cores by co-locating such tasks. We then generalize this approach to provide early solutions for scheduling parallel real-time tasks using the fork-join model. Next, we develop mechanisms to use such techniques in mixed-criticality systems. Finally, we describe the distributed resource kernel framework, where we demonstrate the practical feasibility of our approach. The results of this dissertation contribute to a system that can efficiently utilize multi-core processors to predictably execute periodic tasks with well-defined deadlines and analytically guarantee such deadlines. We provide a utilization bound of 65\% for independent sequential tasks, demonstrate up to 50\% reduction in the required number of cores using synchronization-aware allocation, and prove a 3.42 resource augmentation bound for parallel real-time task scheduling.},
	language = {en},
	school = {Carnegie Mellon University Pittsburgh, PA},
	author = {Lakshmanan, Karthik},
	year = {2011},
}

@misc{noauthor_exercises_nodate,
	title = {Exercises {Xenomai} 3},
	url = {http://www.cs.ru.nl/J.Hooman/DES/XenomaiExercises/},
	urldate = {2018-10-17},
}

@inproceedings{amnell_times:_2003,
	title = {{TIMES}: a tool for schedulability analysis and code generation of real-time systems},
	shorttitle = {{TIMES}},
	booktitle = {International {Conference} on {Formal} {Modeling} and {Analysis} of {Timed} {Systems}},
	publisher = {Springer},
	author = {Amnell, Tobias and Fersman, Elena and Mokrushin, Leonid and Pettersson, Paul and Yi, Wang},
	year = {2003},
	pages = {60--72},
}

@article{lawall_bossa:_nodate,
	title = {Bossa: {A} {Framework} for {Kernel} {Process} {Scheduler} {Development}},
	language = {en},
	author = {Lawall, Julia L and Muller, Gilles},
	pages = {5},
}

@inproceedings{prisaznuk_arinc_2008,
	title = {{ARINC} 653 role in {Integrated} {Modular} {Avionics} ({IMA})},
	doi = {10.1109/DASC.2008.4702770},
	abstract = {The air transport industry has developed ARINC Specification 653 as a standardized Real-Time Operating System (RTOS) interface definition. The document specifies the interface boundary between avionics software applications and the core executive software. The standardization effort was sponsored by the airline user community and involved many interested parties, including airframe manufacturers, avionics suppliers, RTOS suppliers, government and academia. ARINC 653 is a key enabler in the development of Integrated Modular Avionics (IMA). In many ways it represents a paradigm shift for avionics development; in particular it recognizes the RTOS as key component of an IMA system. The commitment shown by industry to IMA could not be more evident than that shown by the Airbus A380 and the Boeing 787 avionics suites. This paper will provide top-level overview of IMA software architecture, the key elements of the ARINC 653 standard and its current development status.},
	booktitle = {2008 {IEEE}/{AIAA} 27th {Digital} {Avionics} {Systems} {Conference}},
	author = {Prisaznuk, P. J.},
	month = oct,
	year = {2008},
	keywords = {ARINC Specification 653, Aerospace electronics, Airbus A380, Application software, Boeing 787, Government, Manufacturing industries, Operating systems, RTOS, Real time systems, Software standards, Standard, aerospace computing, air transport industry, avionics, core executive software, integrated modular avionics, software architecture},
	pages = {1.E.5--1--1.E.5--10},
}

@book{moliere_osgi:_2012,
	address = {Paris},
	title = {{OSGi}: conception d'applications modulaires en {Java}},
	isbn = {978-2-212-13328-8},
	shorttitle = {{OSGi}},
	language = {fr},
	publisher = {Eyrolles},
	author = {Molière, Jérôme},
	year = {2012},
	note = {OCLC: 779142898},
}

@article{friese_estimating_2018,
	title = {Estimating {Latencies} of {Task} {Sequences} in {Multi}-{Core} {Automotive} {ECUs}},
	abstract = {The computation of a cyber-physical system’s reaction to a stimulus typically involves the execution of several tasks. The delay between stimulus and reaction thus depends on the interaction of these tasks and is subject to timing constraints. Such constraints exist for a number of reasons and range from possible impacts on customer experiences to safety requirements. We present a technique to determine end-to-end latencies of such task sequences. The technique is demonstrated on the example of electronic control units (ECUs) in automotive embedded realtime systems. Our approach is able to deal with multi-core architectures and supports four different activation patterns, including interrupts. It is the ﬁrst formal analysis approach making use of load assumptions in order to exclude infeasible data propagation paths without the knowledge of worst-case execution times or worst-case response times. We employ a constraint programming solver to compute bounds on end-toend latencies.},
	language = {en},
	author = {Friese, Max J and Ehlers, Thorsten and Nowotka, Dirk},
	year = {2018},
	pages = {10},
}

@article{bini_schedulability_2004,
	title = {Schedulability analysis of periodic fixed priority systems},
	volume = {53},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/1336766/},
	doi = {10.1109/TC.2004.103},
	language = {en},
	number = {11},
	urldate = {2018-07-05},
	journal = {IEEE Transactions on Computers},
	author = {Bini, E. and Buttazzo, G.C.},
	month = nov,
	year = {2004},
	pages = {1462--1473},
}

@article{bertogna_schedulability_2008,
	title = {Schedulability analysis of global scheduling algorithms on multiprocessor platforms},
	abstract = {This paper addresses the schedulability problem of periodic and sporadic real-time task sets with constrained deadlines preemptively scheduled on a multiprocessor platform composed by identical processors. We assume that a global work-conserving scheduler is used and migration from one processor to another is allowed during task lifetime. First, a general method to derive schedulability conditions for multiprocessor real-time systems will be presented. The analysis will be applied to two typical scheduling algorithms: Earliest Deadline First (EDF) and Fixed Priority (FP). Then, the derived schedulability conditions will be tightened, reﬁning the analysis with a simple and effective technique that signiﬁcantly improves the percentage of accepted task sets. The effectiveness of the proposed test is shown through an extensive set of synthetic experiments.},
	language = {en},
	journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
	author = {Bertogna, Marko and Cirinei, Michele and Lipari, Giuseppe},
	year = {2008},
	pages = {14},
}

@article{baruah_improved_2010,
	title = {Improved multiprocessor global schedulability analysis},
	volume = {46},
	issn = {0922-6443, 1573-1383},
	url = {http://link.springer.com/10.1007/s11241-010-9096-3},
	doi = {10.1007/s11241-010-9096-3},
	abstract = {A new technique was recently introduced by Bonifaci et al. for the analysis of real-time systems scheduled on multiprocessor platforms by the global Earliest Deadline First (EDF) scheduling algorithm. In this paper, this technique is generalized so that it is applicable to the schedulability analysis of realtime systems scheduled on multiprocessor platforms by any work-conserving algorithm. The resulting analysis technique is applied to obtain a new sufﬁcient global Deadline Monotonic (DM) schedulability test. It is shown that this new test is quantitatively superior to pre-existing DM schedulability analysis tests; in addition, the degree of its deviation from any hypothetical optimal scheduler (that may be clairvoyant) is quantitatively bounded. A new global EDF schedulability test is also proposed here that builds on the results of Bonifaci et al. This new test is shown to be less pessimistic and more widely applicable than the earlier result was, while retaining the strong theoretical properties of the earlier result.},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {Real-Time Systems},
	author = {Baruah, Sanjoy and Bonifaci, Vincenzo and Marchetti-Spaccamela, Alberto and Stiller, Sebastian},
	month = sep,
	year = {2010},
	pages = {3--24},
}

@inproceedings{baruah_techniques_2007,
	title = {Techniques for {Multiprocessor} {Global} {Schedulability} {Analysis}},
	isbn = {978-0-7695-3062-8},
	url = {http://ieeexplore.ieee.org/document/4408297/},
	doi = {10.1109/RTSS.2007.35},
	abstract = {The scheduling of sporadic task systems upon multiprocessor platforms is considered, when inter-processor migration is permitted. It is known that current schedulability tests for such systems perform quite poorly when compared to schedulability tests for partitioned scheduling. Limitations of current tests are identiﬁed, which may be responsible for the unsatisfactory performance of these tests. A new test that overcomes some of these limitations is proposed and proved correct.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, Sanjoy},
	month = dec,
	year = {2007},
	pages = {119--128},
}

@inproceedings{bate_framework_1999,
	title = {A framework for scheduling in safety-critical embedded control systems},
	isbn = {978-0-7695-0306-6},
	url = {http://ieeexplore.ieee.org/document/811192/},
	doi = {10.1109/RTCSA.1999.811192},
	abstract = {This paper describes an approach that has been developed over a number of years for the task of scheduling systems and providing evidence that the timing requirements are met. The approach has been targeted at the safetycritical systems domain, and more speciﬁcally the development of jet engine control systems. The work has resulted in a computational model that supports the reuse of legacy systems whilst providing a powerful computational model. In addition, timing analysis has been developed that features low pessimism, low computational complexity and that is robust to change. The aim of this paper is to summarise and bring together all the facets of the work. This is, in part, achieved through a case study that is used as a threaded example through the course of the paper.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Bate, I. and Burns, A.},
	year = {1999},
	pages = {46--53},
}

@inproceedings{chakraborty_approximate_2002,
	title = {Approximate schedulability analysis},
	isbn = {978-0-7695-1851-0},
	url = {http://ieeexplore.ieee.org/document/1181571/},
	doi = {10.1109/REAL.2002.1181571},
	abstract = {The schedulability analysis problem for many realistic task models is intractable. Therefore known algorithms either have exponential complexity or at best can be solved in pseudo-polynomial time, thereby restricting the application of the concerned models to a large extent. We introduce the notion of “approximate schedulability analysis” and show that if a small amount of “error” (which is speciﬁed as an input to the algorithm) can be tolerated in the decisions made by the algorithm, then this problem can be solved in polynomial time. Our algorithms are analogous to fully polynomial time approximation schemes in the context of optimization problems. We show that this concept of approximate schedulability analysis is fairly general and can be applied to any task model which satisﬁes certain “taskindependence” assumptions. Lastly, we substantiate our theoretical results with experimental evidence and clearly show the tradeoffs between the running time of the schedulability analysis and the error incurred for various values of the input error parameter.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Chakraborty, S. and Kunzli, S. and Thiele, L.},
	year = {2002},
	pages = {159--168},
}

@inproceedings{craveiro_schedulability_2010,
	title = {Schedulability analysis in partitioned systems for aerospace avionics},
	isbn = {978-1-4244-6848-5},
	url = {http://ieeexplore.ieee.org/document/5641243/},
	doi = {10.1109/ETFA.2010.5641243},
	abstract = {Aerospace mission systems’ size, weight and power consumption requirements call for the integration of multiple functions on a single embedded computing platform. A current trend to guard against potential timeliness and safety issues in integrating applications of different natures and providers is the employment of temporal and spatial partitioning. The AIR architecture, deﬁned within initiatives sponsored by the European Space Agency to meet these goals, supports multiple partition operating systems, and advanced timeliness control and adaptation mechanisms. In this paper we propose how to take advantage of composability properties inherent to the build and integration process of AIR-based systems, towards toolassisted scheduling analysis and conﬁguration support.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Craveiro, J and Rufino, J},
	month = sep,
	year = {2010},
	pages = {1--4},
}

@article{dorin_schedulability_nodate,
	title = {Schedulability analysis of multiple criticality real-time tasks},
	language = {en},
	author = {DORIN, François and GOOSSENS, Joël and RICHARD, Pascal and RICHARD, Michaël},
	pages = {4},
}

@article{fersman_schedulability_2006,
	title = {Schedulability analysis of fixed-priority systems using timed automata},
	volume = {354},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397505008686},
	doi = {10.1016/j.tcs.2005.11.019},
	abstract = {In classic scheduling theory, real-time tasks are usually assumed to be periodic, i.e. tasks are released and computed with ﬁxed rates periodically. To relax the stringent constraints on task arrival times, we propose to use timed automata to describe task arrival patterns. In a previous work, it is shown that the general schedulability checking problem for such models is a reachability problem for a decidable class of timed automata extended with subtraction. Unfortunately, the number of clocks needed in the analysis is proportional to the maximal number of schedulable task instances associated with a model, which is in many cases huge. In this paper, we show that for ﬁxed-priority scheduling strategy, the schedulability checking problem can be solved using standard timed automata with two extra clocks in addition to the clocks used in the original model to describe task arrival times. The analysis can be done in a similar manner to response time analysis in classic Rate-Monotonic Analysis (RMA). The result is further extended to systems with data-dependent control, in which the release time of a task may depend on the time-point at which other tasks ﬁnish their execution. For the case when the execution times of tasks are constants, we show that the schedulability problem can be solved using n + 1 extra clocks, where n is the number of tasks. The presented analysis techniques have been implemented in the Times tool. For systems with only periodic tasks, the performance of the tool is comparable with tools implementing the classic RMA technique based on equation-solving, without suffering from the exponential explosion in the number of tasks.},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {Theoretical Computer Science},
	author = {Fersman, Elena and Mokrushin, Leonid and Pettersson, Paul and Yi, Wang},
	month = mar,
	year = {2006},
	pages = {301--317},
}

@article{furfaro_modelling_nodate,
	title = {Modelling and {Schedulability} {Analysis} of {Real}-time {Sequence} {Patterns} using {Time} {Petri} {Nets} and {Uppaal}},
	abstract = {This paper proposes an original approach to the schedulability analysis of real-time systems speciﬁed by Time Petri Nets (TPNs). The focus is on sequence patterns of transition ﬁrings (execution tasks). A TPN model is ﬁrst translated in the Timed Automata terms of the popular Uppaal tool. Then schedulability properties of tasks are veriﬁed through reachability analysis. The approach is eﬃcient and scalable. The paper demonstrates the concrete application of the approach through examples. Finally, conclusions are drawn together with an indication of on-going and future work.},
	language = {en},
	author = {Furfaro, Angelo and Nigro, Libero},
	pages = {15},
}

@inproceedings{hawkins_towards_2005,
	title = {Towards {Feasible} {Region} {Calculus}: {An} {End}-to-{End} {Schedulability} {Analysis} of {Real}-{Time} {Multistage} {Execution}},
	isbn = {978-0-7695-2490-0},
	shorttitle = {Towards {Feasible} {Region} {Calculus}},
	url = {http://ieeexplore.ieee.org/document/1563097/},
	doi = {10.1109/RTSS.2005.42},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Hawkins, W. and Abdelzaher, T.},
	year = {2005},
	pages = {75--86},
}

@inproceedings{ju_schedulability_2008,
	title = {Schedulability {Analysis} of {MSC}-based {System} {Models}},
	isbn = {978-0-7695-3146-5},
	url = {http://ieeexplore.ieee.org/document/4550794/},
	doi = {10.1109/RTAS.2008.9},
	abstract = {Message Sequence Charts (MSCs) are widely used for describing interaction scenarios between the components of a distributed system. Consequently, worst-case response time estimation and schedulability analysis of MSC-based speciﬁcations form natural building blocks for designing distributed real-time systems. However, currently there exists a large gap between the timing and quantitative performance analysis techniques that exist in the real-time systems literature, and the modeling/speciﬁcation techniques that are advocated by the formal methods community. As a result, although a number of schedulability analysis techniques are known for a variety of task graph-based models, it is not clear if they can be used to effectively analyze standard speciﬁcation formalisms such as MSCs. In this paper we make an attempt to bridge this gap by proposing a schedulability analysis technique for MSC-based system speciﬁcations. We show that compared to existing timing analysis techniques for distributed real-time systems, our proposed analysis gives tighter results, which immediately translate to better system design and improved resource dimensioning. We illustrate the details of our analysis using a setup from the automotive electronics domain, which consist of two real-life application programs (that are naturally modeled using MSCs) running on a platform consisting of multiple electronic control units (ECUs) connected via a FlexRay bus.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Ju, Lei and Roychoudhury, Abhik and Chakraborty, Samarjit},
	month = apr,
	year = {2008},
	pages = {215--224},
}

@inproceedings{kermia_schedulability_2008,
	title = {Schedulability {Analysis} for {Non}-{Preemptive} {Tasks} under {Strict} {Periodicity} {Constraints}},
	isbn = {978-0-7695-3349-0},
	url = {http://ieeexplore.ieee.org/document/4617270/},
	doi = {10.1109/RTCSA.2008.44},
	abstract = {Real-time systems are often designed using preemptive scheduling to guarantee the execution of high priority tasks. For multiple reasons there is a great interest in exploring non-preemptive scheduling in the case of hard real-time systems where missing deadline leads to catastrophic situations. This paper presents a necessary and sufﬁcient schedulability condition for determining whether a task will satisfy its period and precedences constraints when some tasks have already been scheduled. Tasks we are dealing with are non-preemptive and the periods considered here are strict.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Kermia, Omar and Sorel, Yves},
	month = aug,
	year = {2008},
	pages = {25--32},
}

@article{g_scheduling_2013,
	title = {Scheduling {Challenges} in {Mixed} {Critical} {Real}-{Time} {Heterogeneous} {Computing} {Platforms}},
	volume = {18},
	issn = {18770509},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050913005012},
	doi = {10.1016/j.procs.2013.05.358},
	abstract = {In Dynamic Data-Driven Application Systems (DDDAS), applications must dynamically adapt their behavior in response to objectives and conditions that change while deployed. Often these applications may be safety critical or tightly resource constrained, with a need for graceful degradation when introduced to unexpected conditions. This paper begins by motivating and providing a vision for a dynamically adaptable mixed critical computing platform to support DDDAS applications. We then speciﬁcally focus on the need for advancements in task models and scheduling algorithms to manage the resources of such a platform. We discuss the short comings of existing task models for capturing important attributes of our envisioned computing platform, and identify challenges that must be addressed when developing scheduling algorithms that act upon our proposed extended task model.},
	language = {en},
	urldate = {2018-07-09},
	journal = {Procedia Computer Science},
	author = {G, Chetan Kumar N and Vyas, Sudhanshu and Cytron, Ron K. and Gill, Christopher D. and Zambreno, Joseph and Jones, Phillip H.},
	year = {2013},
	pages = {1891--1898},
}

@article{lee_edzl_2013,
	title = {{EDZL} {Schedulability} {Analysis} in {Real}-{Time} {Multicore} {Scheduling}},
	volume = {39},
	issn = {0098-5589, 1939-3520},
	url = {http://ieeexplore.ieee.org/document/6374195/},
	doi = {10.1109/TSE.2012.75},
	abstract = {In real-time systems, correctness depends not only on functionality but also on timeliness. A great number of scheduling theories have been developed for verification of the temporal correctness of jobs (software) in such systems. Among them, the Earliest Deadline first until Zero-Laxity (EDZL) scheduling algorithm has received growing attention thanks to its effectiveness in multicore realtime scheduling. However, the true potential of EDZL has not yet been fully exploited in its schedulability analysis as the state-of-the-art EDZL analysis techniques involve considerable pessimism. In this paper, we propose a new EDZL multicore schedulability test. We first introduce an interesting observation that suggests an insight toward pessimism reduction in the schedulability analysis of EDZL. We then incorporate it into a well-known existing Earliest Deadline First (EDF) schedulability test, resulting in a new EDZL schedulability test. We demonstrate that the proposed EDZL test not only has lower time complexity than existing EDZL schedulability tests, but also significantly improves the schedulability of EDZL by up to 36.6 percent compared to the best existing EDZL schedulability tests.},
	language = {en},
	number = {7},
	urldate = {2018-07-09},
	journal = {IEEE Transactions on Software Engineering},
	author = {Lee, Jinkyu and Shin, Insik},
	month = jul,
	year = {2013},
	pages = {910--916},
}

@inproceedings{li_applicability_2012,
	title = {Applicability of real-time schedulability analysis on a software radio protocol},
	isbn = {978-1-4503-1505-0},
	url = {http://dl.acm.org/citation.cfm?doid=2402676.2402703},
	doi = {10.1145/2402676.2402703},
	abstract = {In this paper, we present our experience on integrating timing constraint veriﬁcation and analysis, by using the realtime scheduling theory, in an industrial context. The veriﬁcation process has been integrated into a design ﬂow at THALES Communications \& Security. We focus our work on Software Radio Protocols (SRP). We have used ModelDriven Engineering technologies and the Cheddar schedulability analysis tool for our experiment. We show how we have modeled a complete SRP in UML MARTE, a proﬁle for real-time embedded systems, before using model transformation to extract information for schedulability analysis with Cheddar.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Li, Shuai and Singhoff, Frank and Rubini, Stéphane and Michel, Bourdellès},
	year = {2012},
	pages = {81},
}

@article{marouf_schedulability_2012,
	title = {Schedulability analysis for a combination of preemptive strict periodic tasks and sporadic tasks},
	language = {en},
	author = {Marouf, Mohamed and George, Laurent and Sorel, Yves},
	year = {2012},
	pages = {3},
}

@article{ndoye_safety_nodate,
	title = {Safety {Critical} {Multiprocessor} {Real}-{Time} {Scheduling} with {Exact} {Preemption} {Cost}},
	abstract = {In this paper, we address for safety critical applications the problem of multiprocessor real-time scheduling while taking into account the exact preemption cost. In the framework of multiprocessor real-time partitioned scheduling, we propose a greedy heuristic which balances the load of the tasks on all the processors and minimizes the response time of the applications. That heuristic uses a schedulability condition which is based on the ⊕ operation. That operation performs a schedulability analysis while taking into account the exact preemption cost. A performance analysis is achieved which compares the proposed heuristic to the branch and bound exact algorithm and to the worst-ﬁt and best-ﬁt heuristics.},
	language = {en},
	author = {Ndoye, Falou and Sorel, Yves},
	pages = {10},
}

@inproceedings{pathan_schedulability_2012,
	title = {Schedulability {Analysis} of {Mixed}-{Criticality} {Systems} on {Multiprocessors}},
	isbn = {978-1-4673-2032-0},
	url = {http://ieeexplore.ieee.org/document/6257582/},
	doi = {10.1109/ECRTS.2012.29},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Pathan, Risat Mahmud},
	month = jul,
	year = {2012},
	pages = {309--320},
}

@inproceedings{pathan_parameterized_2010,
	title = {Parameterized {Schedulability} {Analysis} on {Uniform} {Multiprocessors}},
	isbn = {978-1-4244-7913-9},
	url = {http://ieeexplore.ieee.org/document/5599177/},
	doi = {10.1109/ICPP.2010.40},
	abstract = {This paper addresses global rate-monotonic scheduling of implicit-deadline periodic real-time tasks on uniform multiprocessor platforms. In particular, we propose new schedulability conditions that include a set of easily computable task-set parameters for achieving better system utilization while meeting the deadlines of all the tasks. First, an individual sufﬁcient schedulability condition is derived for each task. Then, the collection of schedulability conditions for the tasks are condensed to provide two different simple sufﬁcient schedulability conditions for the entire task system — one for uniform multiprocessors, and one for unit-capacity multiprocessors, respectively. Finally, we show that our proposed simple rate-monotonic schedulability conditions for uniform and unit-capacity multiprocessors have higher worst-case system utilization than all other state-of-the-art simple schedulability conditions for global rate-monotonic scheduling of implicit-deadline tasks.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Pathan, Risat Mahmud and Jonsson, Jan},
	month = sep,
	year = {2010},
	pages = {323--332},
}

@article{tindell_holistic_1994,
	title = {Holistic schedulability analysis for distributed hard real-time systems},
	volume = {40},
	issn = {01656074},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0165607494900809},
	doi = {10.1016/0165-6074(94)90080-9},
	abstract = {This paper extends the current analysis associated with static priority pre-emptive based scheduling to address the wider problem of analysing schedulability of a distributed hard real-time system; in particular it derives analysis for a distributed system where tasks with arbitrary deadlines communicate by message passing and shared data areas. A simple TDMA protocol is assumed, and analysis developed to bound not only the communications delays, but also the delays and overheads incurred when messages are processed by the protocol stack at the destination processor. The paper illustrates how a window-based analysis technique can be used to find the worst-case response times of a distributed task set. An extended example illustrating the application of the analysis is presented.},
	language = {en},
	number = {2-3},
	urldate = {2018-07-09},
	journal = {Microprocessing and Microprogramming},
	author = {Tindell, Ken and Clark, John},
	month = apr,
	year = {1994},
	pages = {117--134},
}

@phdthesis{lu_robustesse_2009,
	type = {phdthesis},
	title = {Robustesse du logiciel embarqué multicouche par une approche réflexive: application à l'automobile},
	language = {fr},
	school = {Université de Toulouse, Université Toulouse III-Paul Sabatier},
	author = {Lu, Caroline},
	month = dec,
	year = {2009},
}

@phdthesis{fayollas_architecture_2015,
	type = {{PhD} {Thesis}},
	title = {Architecture logicielle générique et approche à base de modèles pour la sûreté de fonctionnement des systèmes interactifs critiques},
	school = {Université de Toulouse, Université Toulouse III-Paul Sabatier},
	author = {Fayollas, Camille},
	year = {2015},
}

@phdthesis{blin_vers_2017,
	address = {Paris},
	type = {phdthesis},
	title = {Vers une utilisation efficace des processeurs multi-coeurs dans des systèmes embarqués à criticités multiples},
	url = {https://tel.archives-ouvertes.fr/tel-01624259},
	abstract = {Les systèmes embarqués dans les véhicules comportent un mélange d’applications temps réel et « best effort » déployées, pour des raisons d’isolation, sur des calculateurs séparés. L’ajout de nouvelles fonctionnalités dans les véhicules se traduit par un accroissement du nombre de calculateurs et ainsi par une augmentation des coûts, de la consommation électrique et de la dissipation thermique.L’émergence de nouvelles plate-formes multi-cœurs à bas coûts permet d’envisager le déploiement d’une nouvelle architecture dite « virtualisée » pour exécuter en parallèle sur un même calculateur les deux types d’applications. Néanmoins, la hiérarchie mémoire de tels calculateurs, reste partagée. Une application temps réel exécutée sur un cœur peut donc voir ses temps d’accès à la mémoire ralentis par les accès effectués par les applications « best effort » exécutées en parallèle entraînant ainsi la violation des échéances de la tâche temps réel.Dans cette thèse, nous proposons une nouvelle approche de gestion de la contention mémoire. Dans une première étape, hors ligne, nous générons un oracle capable d’estimer les ralentissements d’une tâche temps réel en fonction du trafic mémoire mesuré. Dans une deuxième étape, en ligne, les tâches temps réel sont exécutées en parallèle des applications « best effort ». Un mécanisme de régulation va surveiller la consommation mémoire et utiliser l’oracle généré précédemment pour estimer le ralentissement des tâches temps réel. Lorsque le ralentissement estimé est supérieur à celui fixé par le concepteur du système les applications « best effort » sont suspendues jusqu’à ce que l’application temps réel termine son activation.},
	language = {fr},
	school = {Université Pierre et Marie Curie - Paris VI},
	author = {Blin, Antoine},
	month = jan,
	year = {2017},
}

@inproceedings{tamas-selicean_design_2011,
	title = {Design {Optimization} of {Mixed}-{Criticality} {Real}-{Time} {Applications} on {Cost}-{Constrained} {Partitioned} {Architectures}},
	isbn = {978-1-4577-2000-0},
	url = {http://ieeexplore.ieee.org/document/6121423/},
	doi = {10.1109/RTSS.2011.11},
	abstract = {In this paper we are interested to implement mixed-criticality hard real-time applications on a given heterogeneous distributed architecture. Applications have different criticality levels, captured by their Safety-Integrity Level (SIL), and are scheduled using static-cyclic scheduling. Mixed-criticality tasks can be integrated onto the same architecture only if there is enough spatial and temporal separation among them. We consider that the separation is provided by partitioning, such that applications run in separate partitions, and each partition is allocated several time slots on a processor. Tasks of different SILs can share a partition only if they are all elevated to the highest SIL among them. Such elevation leads to increased development costs. We are interested to determine (i) the mapping of tasks to processors, (ii) the assignment of tasks to partitions, (iii) the sequence and size of the time slots on each processor and (iv) the schedule tables, such that all the applications are schedulable and the development costs are minimized. We have proposed a Tabu Search-based approach to solve this optimization problem. The proposed algorithm has been evaluated using several synthetic and real-life benchmarks.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Tamas-Selicean, Domitian and Pop, Paul},
	month = nov,
	year = {2011},
	pages = {24--33},
}

@phdthesis{monot_verification_2012,
	title = {Vérification des contraintes temporelles de bout-en-bout dans le contexte {AutoSar}},
	abstract = {The complexity of electronic embedded systems in cars is continuously growing. Hence, mastering the temporal behavior of such systems is paramount in order to ensure the safety and comfort of the passengers. As a consequence, the verification of end-to-end real-time constraints is a major challenge during the design phase of a car. The AUTOSAR software architecture drives us to address the verification of end-to-end real-time constraints as two independent scheduling problems respectively for electronic control units and communication buses. First, we introduce an approach, which optimizes the utilization of controllers scheduling numerous software components that is compatible with the upcoming multicore architectures. We describe fast and efficient algorithms in order to balance the periodic load over time on multicore controllers by adapting and improving an existing approach used for the CAN networks. We provide theoretical result on the efficiency of the algorithms in some specific cases. Moreover, we describe how to use these algorithms in conjunction with other tasks scheduled on the controller. The remaining part of this research work addresses the problem of obtaining the response time distributions of the messages sent on a CAN network. First, we present a simulation approach based on the modelisation of clock drifts on the communicating nodes connected on the CAN network. We show that we obtain similar results with a single simulation using our approach in comparison with the legacy approach consisting in numerous short simulation runs without clock drifts. Then, we present an analytical approach in order to compute the response time distributions of the CAN frames. We introduce several approximation parameters to cope with the very high computational complexity of this approach while limiting the loss of accuracy. Finally, we compare experimentally the simulation and analytical approaches in order to discuss the relative advantages of each of the two approaches.},
	language = {fr},
	school = {Université de Lorraine},
	author = {Monot, Aurélien},
	month = nov,
	year = {2012},
}

@inproceedings{abeni_integrating_1998,
	title = {Integrating multimedia applications in hard real-time systems},
	isbn = {978-0-8186-9212-3},
	url = {http://ieeexplore.ieee.org/document/739726/},
	doi = {10.1109/REAL.1998.739726},
	abstract = {This paper focuses on the problem of providing efﬁcient run-time support to multimedia applications in a real-time system, where two types of tasks can coexist simultaneously: multimedia soft real-time tasks and hard real-time tasks. Hard tasks are guaranteed based on worst case execution times and minimum interarrival times, whereas multimedia and soft tasks are served based on mean parameters. The paper describes a server-based mechanism for scheduling soft and multimedia tasks without jeopardizing the a priori guarantee of hard real-time activities. The performance of the proposed method is compared with that of similar service mechanisms through extensive simulation experiments and several multimedia applications have been implemented on the HARTIK kernel.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Abeni, L. and Buttazzo, G.},
	year = {1998},
	pages = {4--13},
}

@inproceedings{caccamo_capacity_2000,
	title = {Capacity sharing for overrun control},
	isbn = {978-0-7695-0900-6},
	url = {http://ieeexplore.ieee.org/document/896018/},
	doi = {10.1109/REAL.2000.896018},
	abstract = {In this paper, we present a general scheduling methodology for managing overruns in a real-time environment, where tasks may have different criticality and flexible timing constraints. The proposed method achieves isolation among tasks through a resource reservation mechanism which bounds the effects of task interference, but also performs eficient rcclaiming of the unused computation times to relax the utilization constraints imposed by isolation. The enhancements achieved b y the proposed approach resulted to be very effective with respect to classical reservation schemes. The performance has been evaluated b y implementing the algorithm on a real-time kernel. The runtime overhead introduced by the scheduling mechanism has also been investigated with specific experiments, in order to be taken into account in the schedulability analysis. However, it resulted to be negligible in most practical cases.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Caccamo, M. and Buttazzo, G. and {Lui Sha}},
	year = {2000},
	pages = {295--304},
}

@inproceedings{motruk_idamc:_2012,
	title = {{IDAMC}: {A} {Many}-{Core} {Platform} with {Run}-{Time} {Monitoring} for {Mixed}-{Criticality}},
	isbn = {978-1-4673-4742-6 978-0-7695-4912-5},
	shorttitle = {{IDAMC}},
	url = {http://ieeexplore.ieee.org/document/6375633/},
	doi = {10.1109/HASE.2012.19},
	abstract = {On a multi- or many-core platform that runs applications of different safety criticality (mixed-criticality), all applications have to be certiﬁed to the highest level of criticality, unless they are sufﬁciently isolated. Isolation enables individual certiﬁcation of applications and cost-efﬁcient re-certiﬁcation of single applications after an update. We introduce a parameterizable and synthesizable many-core platform with a fast and scalable monitoring and control mechanism that supports safe sharing of resources. Our contribution is a step towards exploiting the beneﬁts of multi- and many-core platforms for mixed-critical applications.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Motruk, Boris and Diemer, Jonas and Buchty, Rainer and Ernst, Rolf and Berekovic, Mladen},
	month = oct,
	year = {2012},
	pages = {24--31},
}

@inproceedings{saez_soft_1999,
	title = {Soft aperiodic task scheduling on hard real-time multiprocessor systems},
	isbn = {978-0-7695-0306-6},
	url = {http://ieeexplore.ieee.org/document/811293/},
	doi = {10.1109/RTCSA.1999.811293},
	abstract = {The problem ofjointly scheduling both hard deadlineperiodic tasks and softaperiodic tasks has been the subject of considerable research in real-time systems. The main goal of such a system is to minimize the response time of soft aperiodic tasks, without jeopardizing the hard deadlines of periodic tasks. Although, several approaches have been developed to schedule critical workloads on multiprocessors and to manage aperiodic tasks on monoprocessors, the proposed problem has not beenfully solvedfor multiprocessors and integrated solutions are still required.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Saez, S. and Vila, J. and Crespo, A.},
	year = {1999},
	pages = {424--427},
}

@article{baker_comparison_2005,
	title = {Comparison of {Empirical} {Success} {Rates} of {Global} vs. {Partitioned} {Fixed}-{Priority} and {EDF} {Scheduling} for {Hard} {Real} {Time} {TR}-05060},
	abstract = {Improvements in schedulability tests for global ﬁxed-priority and EDF scheduling in a homogeneous multiprocessor (symmetric multiprocessing) environment have shown that the worst-case guaranteed achievable utilization levels for global EDF scheduling equals what can be achieved with partitioned scheduling, and both ways of applying EDF scheduling out-perform ﬁxed-priority scheduling, for sets of independent periodic or sporadic hard-deadline tasks with deadline equal to period. However, less is known about the comparative performance of the partitioned vs. global and EDF vs. ﬁxed-priority approaches in the average and without the restriction that deadline equal period, and particular which of the known combinations of a scheduling algorithm and a suﬃcient a priori test of schedulability is more likely to succeed in veriﬁably scheduling a set of tasks to meet all deadlines. This paper compares the performance of several such combinations on a variety of pseudo-randomly chosen sets of sporadic tasks.},
	language = {en},
	author = {Baker, Theodore P},
	year = {2005},
	pages = {14},
}

@inproceedings{baker_sustainable_2009,
	title = {Sustainable {Multiprocessor} {Scheduling} of {Sporadic} {Task} {Systems}},
	isbn = {978-0-7695-3724-5},
	url = {http://ieeexplore.ieee.org/document/5161510/},
	doi = {10.1109/ECRTS.2009.25},
	abstract = {A scheduling policy or a schedulability test is deﬁned to be sustainable with respect to a particular workload model if any task system represented in that model that is determined to be schedulable remains so if it behaves better than mandated by its speciﬁcations. We investigate the sustainability properties of global scheduling algorithms when applied to systems represented using the sporadic task model. We show that Fixed-Priority (FP) scheduling of sporadic task sets is sustainable under a variety of scheduling parameter relaxations, including decreased execution requirements, later arrivals, and deadline relaxations. It follows that all sufﬁcient tests of global FP schedulability are sustainable for sporadic task systems. We show that the Earliest Deadline First (EDF) and Earliest-Deadline with Zero Laxity scheduling policies are sustainable with respect to decreased execution requirements and later arrivals. We also introduce a notion of self-sustainability, and show that many widely-used EDF schedulability tests are not selfsustainable but one is.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baker, Theodore P. and Baruah, Sanjoy K.},
	month = jul,
	year = {2009},
	pages = {141--150},
}

@inproceedings{baruah_towards_2010,
	title = {Towards the {Design} of {Certifiable} {Mixed}-criticality {Systems}},
	isbn = {978-1-4244-6690-0},
	url = {http://ieeexplore.ieee.org/document/5465960/},
	doi = {10.1109/RTAS.2010.10},
	abstract = {Many safety-critical embedded systems are subject to certiﬁcation requirements; some systems may be required to meet multiple sets of certiﬁcation requirements, from different certiﬁcation authorities. Certiﬁcation requirements in such “mixed-criticality” systems give rise to some interesting scheduling problems, that cannot be satisfactorily addressed using techniques from conventional scheduling theory. In this paper, we propose a formal model for representing such mixed-criticality workloads. We demonstrate the intractability of determining whether a system speciﬁed in this model can be scheduled to meet all its certiﬁcation requirements. For dualcriticality systems – systems subject to two sets of certiﬁcation requirements – we quantify, via the metric of processor speedup factor, the effectiveness of 2 techniques (reservation-based scheduling and priority-based scheduling) that are widely used in scheduling such mixedcriticality systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, Sanjoy and Li, Haohan and Stougie, Leen},
	month = apr,
	year = {2010},
	pages = {13--22},
}

@inproceedings{behera_schedulability_2012,
	title = {Schedulability analysis of task scheduling in multiprocessor real-time systems using {EDF} algorithm},
	isbn = {978-1-4577-1583-9 978-1-4577-1580-8 978-1-4577-1582-2},
	url = {http://ieeexplore.ieee.org/document/6158912/},
	doi = {10.1109/ICCCI.2012.6158912},
	abstract = {Task scheduling in real-time systems is a concept by which we can schedule the tasks according to their priorities. In hard real-time systems, the task scheduling is more important due to the chance of system failure. We discuss EDF task scheduling which is an optimal technique for the uniprocessor systems. The existing result of the QPA algorithm was applied on the uniprocessor system to check the schedulability of the tasks in uniprocessor system. We have extended the QPA algorithm to check the schedulability of the task sets in multiprocessor systems. Our algorithm is based on QPA algorithm and the utilization balanced algorithm. The proposed algorithm checks the absolute deadlines much faster than the existing QPA algorithm for uniprocessor real-time systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Behera, Lalatendu and Mohapatra, Durga Prasad},
	month = jan,
	year = {2012},
	pages = {1--9},
}

@inproceedings{bertogna_evaluation_2009,
	title = {Evaluation of {Existing} {Schedulability} {Tests} for {Global} {EDF}},
	isbn = {978-1-4244-4923-1},
	url = {http://ieeexplore.ieee.org/document/5366907/},
	doi = {10.1109/ICPPW.2009.12},
	abstract = {The increasing attention on global scheduling algorithms for identical multiprocessor platforms produced different, independently developed, schedulability tests. However, the existing relations among such tests have not been sufﬁciently clariﬁed, so that it is difﬁcult to understand which strategy provides the best performances in a particular scenario.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Bertogna, Marko},
	month = sep,
	year = {2009},
	pages = {11--18},
}

@inproceedings{brandenburg_integrating_2007,
	title = {Integrating {Hard}/{Soft} {Real}-{Time} {Tasks} and {Best}-{Effort} {Jobs} on {Multiprocessors}},
	isbn = {978-0-7695-2914-1},
	url = {http://ieeexplore.ieee.org/document/4271681/},
	doi = {10.1109/ECRTS.2007.17},
	abstract = {We present a multiprocessor scheduling framework for integrating hard and soft real-time tasks and best-effort jobs. This framework allows for full system utilization, and ensures that hard real-time deadlines are met and that deadline tardiness is bounded for soft real-time tasks. Dynamic slack reclamation is employed to reduce tardiness and to improve the response time of best-effort jobs. The approach is validated using an implementation within the Linux kernel.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Brandenburg, Bjorn B. and Anderson, James H.},
	month = jul,
	year = {2007},
	pages = {61--70},
}

@inproceedings{brandenburg_scalability_2008,
	title = {On the {Scalability} of {Real}-{Time} {Scheduling} {Algorithms} on {Multicore} {Platforms}: {A} {Case} {Study}},
	isbn = {978-0-7695-3477-0},
	shorttitle = {On the {Scalability} of {Real}-{Time} {Scheduling} {Algorithms} on {Multicore} {Platforms}},
	url = {http://ieeexplore.ieee.org/document/4700432/},
	doi = {10.1109/RTSS.2008.23},
	abstract = {Multicore platforms are predicted to become signiﬁcantly larger in the coming years. Given that real-time workloads will inevitably be deployed on such platforms, the scalability of the scheduling algorithms used to support such workloads warrants investigation. In this paper, this issue is considered and an empirical evaluation of several global and partitioned scheduling algorithms is presented. This evaluation was conducted using a Sun Niagara multicore platform with 32 logical CPUs (eight cores, four hardware threads per core). In this study, each tested algorithm proved to be a viable choice for some subset of the workload categories considered.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Brandenburg, Björn B. and Calandrino, John M. and Anderson, James H.},
	month = nov,
	year = {2008},
	pages = {157--169},
}

@incollection{jin_generalized_2007,
	address = {Berlin, Heidelberg},
	title = {A {Generalized} {Critical} {Task} {Anticipation} {Technique} for {DAG} {Scheduling}},
	volume = {4494},
	isbn = {978-3-540-72904-4 978-3-540-72905-1},
	url = {http://link.springer.com/10.1007/978-3-540-72905-1_44},
	abstract = {The problem of scheduling a weighted directed acyclic graph (DAG) representing an application to a set of heterogeneous processors to minimize the completion time has been recently studied. The NP-completeness of the problem has instigated researchers to propose different heuristic algorithms. In this paper, we present a Generalized Critical-task Anticipation (GCA) algorithm for DAG scheduling in heterogeneous computing environment. The GCA scheduling algorithm employs task prioritizing technique based on CA algorithm and introduces a new processor selection scheme by considering heterogeneous communication costs among processors for adapting grid and scalable computing. To evaluate the performance of the proposed technique, we have developed a simulator that contains a parametric graph generator for generating weighted directed acyclic graphs with various characteristics. We have implemented the GCA algorithm along with the CA and HEFT scheduling algorithms on the simulator. The GCA algorithm is shown to be effective in terms of speedup and low scheduling costs.},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {Algorithms and {Architectures} for {Parallel} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hsu, Ching-Hsien and Hsieh, Chih-Wei and Yang, Chao-Tung},
	editor = {Jin, Hai and Rana, Omer F. and Pan, Yi and Prasanna, Viktor K.},
	year = {2007},
	doi = {10.1007/978-3-540-72905-1_44},
	pages = {493--505},
}

@article{dorin_schedulability_2010,
	title = {Schedulability and sensitivity analysis of multiple criticality tasks with fixed-priorities},
	volume = {46},
	issn = {0922-6443, 1573-1383},
	url = {http://link.springer.com/10.1007/s11241-010-9107-4},
	doi = {10.1007/s11241-010-9107-4},
	abstract = {Safety-critical real-time standards deﬁne several criticality levels for the tasks. In this paper we consider the real-time systems designed under the DO-178B safety assessment process (i.e., Software Considerations in Airborne Systems and Equipment Certiﬁcation). Vestal introduced a new multiple criticality task model to efﬁciently take into account criticality levels in the schedulability analysis of such systems. Such a task model represents a potentially very signiﬁcant advance in the modeling of safety-critical real-time softwares. Baruah and Vestal continue this investigation, with a new scheduling algorithm combining ﬁxed and dynamic priority policies. Another major design issue is to allow a system developer to determine how sensitive is the schedulability analysis to changes in execution time of various software components.},
	language = {en},
	number = {3},
	urldate = {2018-07-09},
	journal = {Real-Time Systems},
	author = {Dorin, François and Richard, Pascal and Richard, Michaël and Goossens, Joël},
	month = dec,
	year = {2010},
	pages = {305--331},
}

@inproceedings{ekberg_outstanding_2012,
	title = {Outstanding {Paper} {Award}: {Bounding} and {Shaping} the {Demand} of {Mixed}-{Criticality} {Sporadic} {Tasks}},
	isbn = {978-1-4673-2032-0},
	shorttitle = {Outstanding {Paper} {Award}},
	url = {http://ieeexplore.ieee.org/document/6257566/},
	doi = {10.1109/ECRTS.2012.24},
	abstract = {We derive demand-bound functions for mixedcriticality sporadic tasks, and use these to determine EDFschedulability. Tasks have different demand-bound functions for each criticality mode. We show how to shift execution demand from high- to low-criticality mode by tuning the relative deadlines. This allows us to shape the demand characteristics of each task. We propose an efﬁcient algorithm for tuning all relative deadlines of a task set in order to shape the total demand to the available supply of the computing platform. Experiments indicate that this approach is signiﬁcantly more powerful than previous approaches to mixed-criticality scheduling. This new approach has the added beneﬁt of supporting hierarchical scheduling frameworks.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Ekberg, Pontus and Yi, Wang},
	month = jul,
	year = {2012},
	pages = {135--144},
}

@inproceedings{ernst_mixed_2012,
	title = {Mixed critical system design and analysis},
	isbn = {978-1-4503-1425-1},
	url = {http://dl.acm.org/citation.cfm?doid=2380356.2380401},
	doi = {10.1145/2380356.2380401},
	abstract = {With increasing use of embedded systems in safety critical systems, architectures and design processes for safety have become a primary objective in systems design. Most such systems are also time critical leading to safety and time critical systems. Safety standards impose strong requirements on such systems challenging system performance and cost. Very often, however, only part of the functions is safety and time critical calling for a design approach that both meets the safety requirements and provides efficiency and flexibility for less critical functions. These conflicting requirements have given rise to the new research area of mixed critical system design with enormous practical relevance.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Ernst, Rolf and Burns, Alan and Thiele, Lothar and Le Rhun, Jimmy},
	year = {2012},
	pages = {247},
}

@inproceedings{goswami_time-triggered_2012,
	title = {Time-triggered implementations of mixed-criticality automotive software},
	isbn = {978-1-4577-2145-8 978-3-9810801-8-6},
	url = {http://ieeexplore.ieee.org/document/6176680/},
	doi = {10.1109/DATE.2012.6176680},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Goswami, D. and Lukasiewycz, M. and Schneider, R. and Chakraborty, S.},
	month = mar,
	year = {2012},
	pages = {1227--1232},
}

@inproceedings{guan_effective_2011,
	title = {Effective and {Efficient} {Scheduling} of {Certifiable} {Mixed}-{Criticality} {Sporadic} {Task} {Systems}},
	isbn = {978-1-4577-2000-0},
	url = {http://ieeexplore.ieee.org/document/6121422/},
	doi = {10.1109/RTSS.2011.10},
	abstract = {An increasing trend in embedded system design is to integrate components with different levels of criticality into a shared hardware platform for better cost and power efﬁciency. Such mixed-criticality systems are subject to certiﬁcations at different levels of rigorousness, for validating the correctness of different subsystems on various conﬁdence levels. The realtime scheduling of certiﬁable mixed-criticality systems has been recognized to be a challenging problem, where using traditional scheduling techniques may result in unacceptable resource waste. In this paper we present an algorithm called PLRS to schedule certiﬁable mixed-criticality sporadic tasks systems. PLRS uses ﬁxed-job-priority scheduling, and assigns job priorities by exploring and balancing the asymmetric effects between the workload on different criticality levels. Comparing with the state-of-the-art algorithm by Li and Baruah for such systems, which we refer to as LB, PLRS is both more effective and more efﬁcient: (i) The schedulability test of PLRS not only theoretically dominates, but also on average signiﬁcantly outperforms LB’s. (ii) The run-time complexity of PLRS is polynomial (quadratic in the number of tasks), which is much more efﬁcient than the pseudo-polynomial run-time complexity of LB.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Guan, Nan and Ekberg, Pontus and Stigge, Martin and Yi, Wang},
	month = nov,
	year = {2011},
	pages = {13--23},
}

@inproceedings{herman_rtos_2012,
	title = {{RTOS} {Support} for {Multicore} {Mixed}-{Criticality} {Systems}},
	isbn = {978-1-4673-0883-0},
	url = {http://ieeexplore.ieee.org/document/6200051/},
	doi = {10.1109/RTAS.2012.24},
	abstract = {Mixed-criticality scheduling algorithms, which attempt to reclaim system capacity lost to worst-case execution time pessimism, seem to hold great promise for multicore real-time systems, where such loss is particularly severe. However, the unique nature of these algorithms gives rise to a number of major challenges for the would-be implementer. This paper describes the ﬁrst implementation of a mixed-criticality scheduling framework on a multicore system. We experimentally evaluate design tradeoffs that arise when seeking to isolate tasks of different criticalities and to maintain overheads commensurate with a standard RTOS. We also evaluate a key property needed for such a system to be practical: that the system be robust to breaches of the optimistic execution-time assumptions used in mixed-criticality analysis.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Herman, Jonathan L. and Kenna, Christopher J. and Mollison, Malcolm S. and Anderson, James H. and Johnson, Daniel M.},
	month = apr,
	year = {2012},
	pages = {197--208},
}

@inproceedings{hill_non-interference_2000,
	title = {Non-interference analysis for mixed criticality code in avionics systems},
	isbn = {978-0-7695-0710-1},
	url = {http://ieeexplore.ieee.org/document/873672/},
	doi = {10.1109/ASE.2000.873672},
	abstract = {Future aircraft system procurements are expected to utilise a new f o r m of modular architecture. However, the architectures being put forward only provide for hardware partitioning, and there is little protection for safety-critical processes from interference by rogue processes. This paper puts forward a mixed static/ dynamic analysis approach for assuring software partitioning of processes within a single hardware partition. Such an approach is a necessity in cost effective modular architectures if all processes are not to be classified and developed as safety-critical.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Hill, M.G. and Lake, T.W.},
	year = {2000},
	pages = {257--260},
}

@inproceedings{huang_new_2013,
	title = {A new scheduling approach for mix-criticality real-time system},
	isbn = {978-1-4673-6249-8 978-1-4673-6248-1 978-1-4673-6247-4},
	url = {http://ieeexplore.ieee.org/document/6568037/},
	doi = {10.1109/ICICIP.2013.6568037},
	abstract = {Many safety-critical embedded systems are subject to meet multiple sets of certification requirements from different certification authorities. The techniques from the traditional scheduling theory cannot be satisfactorily addressed the scheduling problems in such “mixed-criticality” systems. So some scheduling algorithms such as OCBP(Own Criticality Based Priority) and CM(criticality monotonically) were presented. But they all only adapted to some cases. In this paper, we propose a new scheduling algorithm----BTW(Based Time Windows) for solving such mixed-criticality workloads. Our simulations show that BTW algorithm are most likely to be able to schedule a randomly selected task set than OCBP and CM. And it also can owns the better system utilization and the lower miss deadline ratio.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Huang, Shujuan and Zhu, Yi'an and Duan, Junhua},
	month = jun,
	year = {2013},
	pages = {43--46},
}

@inproceedings{huber_resource_2008,
	title = {A resource management framework for mixed-criticality embedded systems},
	isbn = {978-1-4244-1767-4},
	url = {http://ieeexplore.ieee.org/document/4758337/},
	doi = {10.1109/IECON.2008.4758337},
	abstract = {Dynamic resource management enables a system to dynamically react to changing resource demands or resource availability. It enables better resource utilization, improved dependability, and the enabling of power-aware system behavior. This paper examines the application of dynamic resource management for an integrated time-triggered system architecture for embedded systems, which is designed to support mixedcriticality systems, i.e., systems integrating distributed application subsystems (DASs) with different dependability requirements on the same hardware platform. For such systems a vital characteristic is to achieve encapsulation of the hosted DASs and to provide mechanisms for fault-isolation. The key challenge addressed in this paper is to preserve these system characteristics despite the presence of dynamic resource allocation. To this end, a resource management framework is presented that provides static resource guarantees for DASs having higher dependability requirements, while facilitating efﬁcient resource utilization for less critical DASs.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Huber, B. and El Salloum, C. and Obermaisser, R.},
	month = nov,
	year = {2008},
	pages = {2425--2431},
}

@inproceedings{huang_implementation_2012,
	title = {Implementation and {Evaluation} of {Mixed}-{Criticality} {Scheduling} {Approaches} for {Periodic} {Tasks}},
	isbn = {978-1-4673-0883-0},
	url = {http://ieeexplore.ieee.org/document/6200075/},
	doi = {10.1109/RTAS.2012.16},
	abstract = {Traditional ﬁxed-priority scheduling analysis for periodic task sets is based on the assumption that all tasks are equally critical to the correct operation of the system. Therefore, every task has to be schedulable under the scheduling policy, and estimates of tasks’ worst case execution times must be conservative in case a task runs longer than is usual. To address the signiﬁcant under-utilization of a system’s resources under normal operating conditions that can arise from these assumptions, three main approaches have been proposed: priority assignment, period transformation, and zero-slack scheduling. However, to date there has been no quantitative comparison of system schedulability or run-time overhead for the different approaches. In this paper, we present what is to our knowledge the ﬁrst side-by-side evaluation of those approaches, for periodic mixed-criticality tasks on uniprocessor systems, under a mixed-criticality scheduling model that is common to all three approaches. To make a fair evaluation of zero-slack scheduling, we also address two previously open issues: how to accommodate execution of a task after its deadline, and how to account for previously unidentiﬁed forms of interference between mixed-criticality tasks. Our simulations show that while priority assignment and period transformation are most likely to be able to schedule a randomly selected task set, a small fraction of the task sets are schedulable only under the zero-slack approach. Our empirical evaluation demonstrates that user-space implementations of mechanisms to enforce period transformation and zero-slack scheduling can be achieved on Linux without kernel modiﬁcation, with suitably low overhead for mixed-criticality real-time task sets.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Huang, Huang-Ming and Gill, Christopher and Lu, Chenyang},
	month = apr,
	year = {2012},
	pages = {23--32},
}

@article{jeffrey_integration_2005,
	title = {The {Integration} of {On}-{Line} {Monitoring} and {Reconfiguration} {Functions} into a {Safety} {Critical} {Automotive} {Electronic} {Control} {Unit}},
	volume = {21},
	issn = {0923-8174, 1573-0727},
	url = {http://link.springer.com/10.1007/s10836-005-1272-3},
	doi = {10.1007/s10836-005-1272-3},
	abstract = {This paper presents an innovative application of IEEE1149.4 and the Integrated Diagnostic Reconﬁguration (IDR) method to an Automotive Electronic Control Unit implemented as a fully-integrated mixed-signal system. The IEEE1149.4 test structure has been embedded and used on-line for interconnect monitoring and signal analysis. This provides higher resolution failure diagnostics enabling localised fault compensation. A novel On-Line Monitoring architecture is presented, that supports real-time testing of the critical circuit nodes. The paper concludes that fault tolerance can be integrated into mixed-signal electronic systems to handle key failure modes.},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {Journal of Electronic Testing},
	author = {Jeffrey, C. and Cutajar, R. and Richardson, A. and Prosser, S. and Lickess, M. and Riches, S.},
	month = aug,
	year = {2005},
	pages = {405--416},
}

@inproceedings{kelly_partitioned_2011,
	title = {On {Partitioned} {Scheduling} of {Fixed}-{Priority} {Mixed}-{Criticality} {Task} {Sets}},
	isbn = {978-1-4577-2135-9},
	url = {http://ieeexplore.ieee.org/document/6120937/},
	doi = {10.1109/TrustCom.2011.144},
	abstract = {Mixed-criticality real-time systems, where tasks may be associated with different criticality and assurance levels, have attracted much attention in the recent past. In this paper, we consider partitioning-based multiprocessor scheduling of mixedcriticality real-time task sets. Guaranteeing feasibility in this setting is shown to be NP-Hard. With a focus on fixed-priority preemptive scheduling on each processor, we identify the two main aspects of the problem, namely the task allocation and priority assignment dimensions. For the task allocation dimension, we propose and compare bin-packing-inspired heuristics, based on offline task ordering according to utilization and criticality. For the priority assignment dimension, we compare the wellknown Rate Monotonic priority assignment policy with Audsley’s priority assignment algorithm. Through simulations, we also assess and discuss the relative importance of these two primary dimensions on the overall mixed-criticality feasibility problem for multiprocessor platforms.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Kelly, Owen R. and Aydin, Hakan and Zhao, Baoxian},
	month = nov,
	year = {2011},
	pages = {1051--1059},
}

@inproceedings{lakshmanan_resource_2010,
	title = {Resource {Allocation} in {Distributed} {Mixed}-{Criticality} {Cyber}-{Physical} {Systems}},
	isbn = {978-1-4244-7262-8 978-1-4244-7261-1 978-0-7695-4059-7},
	url = {http://ieeexplore.ieee.org/document/5541717/},
	doi = {10.1109/ICDCS.2010.91},
	abstract = {Large-scale distributed cyber-physical systems will have many sensors/actuators (each with local micro-controllers), and a distributed communication/computing backbone with multiple processors. Many cyber-physical applications will be safetycritical and in many cases unexpected workload spikes are likely to occur due to unpredictable changes in the physical environment. In the face of such overload scenarios, the desirable property in such systems is that the most critical applications continue to meet their deadlines. In this paper, we capture this mixedcriticality property by developing a formal overload-resilience metric called ductility. The generality of ductility enables it to evaluate any scheduling algorithm from the perspective of mixedcriticality cyber-physical systems. In distributed cyber-physical systems, this ductility is the result of both the task-to-processor packing (a.k.a bin packing) and the uniprocessor scheduling algorithms used. In this paper, we present a ductility-maximization packing algorithm to complement our previous work on mixedcriticality uniprocessor scheduling [6]. Our packing algorithm, known as Compress-on-Overload Packing (COP) is a criticalityaware greedy bin-packing algorithm that maximizes the tolerance of high-criticality tasks to overloads. We compare the ductility of COP against the Worst-Fit Decreasing (WFD) bin-packing heuristic used traditionally for load balancing in distributed systems, and show that the performance of COP dominates WFD in the average case and can reach close to ﬁve times better ductility when resources are limited. Finally, we illustrate the practical use of COP in distributed cyber-physical systems using a radar surveillance application, and provide an overview of the entire process from assigning task criticality levels to evaluating its performance.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Lakshmanan, K and de Niz, D and Rajkumar, R and Moreno, G},
	month = jun,
	year = {2010},
	pages = {169--178},
}

@inproceedings{lakshmanan_mixed-criticality_2011,
	title = {Mixed-{Criticality} {Task} {Synchronization} in {Zero}-{Slack} {Scheduling}},
	isbn = {978-1-61284-326-1},
	url = {http://ieeexplore.ieee.org/document/5767137/},
	doi = {10.1109/RTAS.2011.13},
	abstract = {Recent years have seen an increasing interest in the scheduling of mixed-criticality real-time systems. These systems are composed of groups of tasks with different levels of criticality deployed over the same processor(s). Such systems must be able to accommodate additional execution-time requirements that may occasionally be needed. When overload conditions develop, critical tasks must still meet their timing constraints at the expense of less critical tasks. Zero-slack scheduling algorithms are promising candidates for such systems. These algorithms guarantee that all tasks meet their deadlines when no overload occurs, and that criticality ordering is satisﬁed under overloads. Unfortunately, when mutually exclusive resources are shared across tasks, these guarantees are voided. Furthermore, the dualexecution modes of tasks in mixed-criticality systems violate the assumptions of traditional real-time synchronization protocols like PCP and hence the latter cannot be used directly. In this paper, we develop extensions to real-time synchronization protocols (Priority Inheritance and Priority Ceiling Protocol) that coordinate the mode changes of the zero-slack scheduler. We analyze the properties of these new protocols and the blocking terms they introduce. We maintain the deadlock avoidance property of our PCP extension, called the Priority and Criticality Ceiling Protocol (PCCP), and limit the blocking to only one critical section for each of the zero-slack scheduling execution modes. We also develop techniques to accommodate the blocking terms arising from synchronization, in calculating the zeroslack instants used by the scheduler. Finally, we conduct an experimental evaluation of PCCP. Our evaluation shows that PCCP is able to take advantage of the capacity of zero-slack schedulers to reclaim unused over-provisioning of resources that are only used in critical execution modes. This allows PCCP to accommodate larger blocking terms.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Lakshmanan, K and de Niz, Dionisio and Rajkumar, Ragunathan},
	month = apr,
	year = {2011},
	pages = {47--56},
}

@inproceedings{lemerre_method_2011,
	title = {Method and {Tools} for {Mixed}-{Criticality} {Real}-{Time} {Applications} within {PharOS}},
	isbn = {978-1-4577-0303-4},
	url = {http://ieeexplore.ieee.org/document/5753510/},
	doi = {10.1109/ISORCW.2011.15},
	abstract = {This paper provides an overview of some principles and mechanisms to securely operate mixed-criticality real-time systems on embedded platforms. Those principles are illustrated with PharOS, a complete set of tools to design, implement and execute real-time systems on automotive embedded platforms.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Lemerre, Matthieu and Ohayon, Emmanuel and Chabrol, Damien and Jan, Mathieu and Jacques, Marie-Benedicte},
	month = mar,
	year = {2011},
	pages = {41--48},
}

@inproceedings{li_modeling_2010,
	title = {Modeling and analysis of integrated avionics processing systems},
	isbn = {978-1-4244-6616-0},
	url = {http://ieeexplore.ieee.org/document/5655443/},
	doi = {10.1109/DASC.2010.5655443},
	abstract = {In the development of avionics systems, Integrated Modular Avionics is advocated for next generation architecture that needs integration of mixed criticality real-time applications. All real-time applications are processed by integrated avionics processing systems. To guarantee spatial and temporal isolation for these applications, the ARINC 653 standard which defines an interface for avionics real time operating systems provides hierarchy partitioning scheduling schemes.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Li, Xinying and Xiong, Huagang},
	month = oct,
	year = {2010},
	pages = {6.E.4--1--6.E.4--8},
}

@article{mangeruca_uniprocessor_2007,
	title = {Uniprocessor scheduling under precedence constraints for embedded systems design},
	volume = {7},
	issn = {15399087},
	url = {http://portal.acm.org/citation.cfm?doid=1324969.1324975},
	doi = {10.1145/1324969.1324975},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {ACM Transactions on Embedded Computing Systems},
	author = {Mangeruca, Leonardo and Baleani, Massimo and Ferrari, Alberto and Sangiovanni-Vincentelli, Alberto},
	month = dec,
	year = {2007},
	pages = {1--30},
}

@inproceedings{baruah_response-time_2011,
	title = {Response-{Time} {Analysis} for {Mixed} {Criticality} {Systems}},
	isbn = {978-1-4577-2000-0},
	url = {http://ieeexplore.ieee.org/document/6121424/},
	doi = {10.1109/RTSS.2011.12},
	abstract = {Many safety-critical embedded systems are subject to certiﬁcation requirements. However, only a subset of the functionality of the system may be safety-critical and hence subject to certiﬁcation; the rest of the functionality is non safetycritical and does not need to be certiﬁed, or is certiﬁed to a lower level. The resulting mixed criticality system offers challenges both for static schedulability analysis and run-time monitoring. This paper considers a novel implementation scheme for ﬁxed priority uniprocessor scheduling of mixed criticality systems. The scheme requires that jobs have their execution times monitored (as is usually the case in high integrity systems). An optimal priority assignment scheme is derived and sufﬁcient responsetime analysis is provided. The new scheme formally dominates those previously published. Evaluations illustrate the beneﬁts of the scheme.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, S.K. and Burns, A. and Davis, R.I.},
	month = nov,
	year = {2011},
	pages = {34--43},
}

@inproceedings{socci_mixed_2013,
	title = {Mixed {Critical} {Earliest} {Deadline} {First}},
	isbn = {978-0-7695-5054-1},
	url = {http://ieeexplore.ieee.org/document/6602091/},
	doi = {10.1109/ECRTS.2013.20},
	abstract = {Using the advances of the modern microelectronics technology, the safety-critical systems, such as avionics, can reduce their costs by integrating multiple tasks on one device. This makes such systems essentially mixed-critical, as this brings together different tasks whose safety assurance requirements may differ signiﬁcantly. In the context of mixed-critical scheduling theory, we studied the dual criticality problem of scheduling a ﬁnite set of hard real-time jobs. In this work we propose an algorithm which is proved to dominate OCBP, a state-of-theart algorithm for this problem that is optimal over ﬁxed job priority algorithms. We show through empirical studies that our algorithm can reduce the set of non-schedulable instances by a factor of two or, under certain assumptions, by a factor of four, when compared to OCBP.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Socci, Dario and Poplavko, Peter and Bensalem, Saddek and Bozga, Marius},
	month = jul,
	year = {2013},
	pages = {93--102},
}

@inproceedings{molnos_decoupled_2012,
	title = {Decoupled inter- and intra-application scheduling for composable and robust embedded {MPSoC} platforms},
	isbn = {978-1-4503-1336-0},
	url = {http://dl.acm.org/citation.cfm?doid=2236576.2236578},
	doi = {10.1145/2236576.2236578},
	abstract = {Systems-on-Chip (SoCs) typically implement complex applications, each consisting of multiple tasks. Several applications share the SoC cores, to reduce cost. Applications have mixed time-criticality, i.e., real-time or not, and are typically developed together with their schedulers, by diﬀerent parties. Composability, i.e., complete functional and temporal isolation between applications, is an SoC property required to enable fast integration and veriﬁcation of applications. To achieve composability, an Operating System (OS) allocates processor time in quanta of constant duration. The OS executes ﬁrst the application scheduler, then the corresponding task scheduler, to determine which task runs next. As the OS should be a trusted code base, both inter- and intra-application schedulers should be thoroughly analysed and veriﬁed. This is required anyway for real-time intraapplication schedulers. But for non-real-time applications, a costly eﬀort is required to achieve the desired conﬁdence level in their intra-application schedulers. In this paper we propose a light-weight, real-time OS implementation that overcomes these limitations. It separates the two arbitration levels, and requires only the inter-application scheduler to run in OS time. The intra-application scheduler runs in user time, and is therefore not trusted code. This approach allows each application to execute its own specialised task scheduler. We evaluated the practical implications of our proposal on an SoC modelled in FPGA, running an H264 and a JPEG decoder and we found that composability is preserved and performance is improved with up to 37\%.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Molnos, Anca and Nejad, Ashkan Beyranvand and Nguyen, Ba Thang and Cotofana, Sorin and Goossens, Kees},
	year = {2012},
	pages = {13--21},
}

@inproceedings{silly_optimal_1990,
	title = {An optimal algorithm for guaranteeing sporadic tasks in hard real-time systems},
	isbn = {978-0-8186-2087-4},
	url = {http://ieeexplore.ieee.org/document/143607/},
	doi = {10.1109/SPDP.1990.143607},
	abstract = {Guaranteeing that time critical tasks will meet their timing constraints is an important aspect of real-time systems research. Indeed, a real time system is dynamic and consequently requires on -line and adaptive scheduling strategies.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc. Press},
	author = {Silly, M. and Chetto, H. and Elyounsi, N.},
	year = {1990},
	pages = {578--585},
}

@article{jan_maximizing_nodate,
	title = {Maximizing the execution rate of low-criticality tasks in mixed criticality systems},
	abstract = {Industrial ﬁelds must build at the most competitive price real-time systems made of an increasing number of functionalities. This can be achieved by hosting high-criticality tasks as well as consumer real-time low-criticality tasks on a same chip. The design of such Mixed-Criticality (MC) systems requires the use of an appropriate task model and a speciﬁc scheduling strategy. In this work, inspired by the existing elastic task model, we introduce stretching factors as a way for the low-criticality tasks to reduce their utilization, as well as a level of importance in order to deﬁne an order for applying these stretching factors. At run-time, the slack time generated by both the over-provisioned high-criticality and the low-criticality tasks is used to maximize the execution rate of the low-criticality tasks. We also show how to integrate this approach in the Time-Triggered paradigm (TT), in particular its impact on the data visibility principle between the low-criticality tasks when they have been stretched.},
	language = {en},
	author = {Jan, Mathieu and Zaourar, Lilia and Pitel, Maurice},
	pages = {6},
}

@article{socci_time-triggered_nodate,
	title = {Time-{Triggered} {Mixed}-{Critical} {Scheduler}},
	abstract = {Modern safety-critical systems, such as avionics, tend to be mixed-critical, because integration of different tasks with different assurance requirements can effectively reduce their costs. Scheduling is one of the main challenges of such systems. In this work we show that a generalization of the Time Triggered (TT) scheduling paradigm, Single Time Table per Mode (STTM) dominates other approaches like Fixed Priority or Fixed Priority per Mode (FPM). We also propose an algorithm to transform any FPM priority assignment to an equivalent set of STTM tables.},
	language = {en},
	author = {Socci, Dario and Poplavko, Peter and Bensalem, Saddek and Bozga, Marius},
	pages = {6},
}

@article{rodriguez_multi-criteria_nodate,
	title = {Multi-{Criteria} {Evaluation} of {Partitioned} {EDF}-{VD} for {Mixed}-{Criticality} {Systems} {Upon} {Identical} {Processors}},
	abstract = {In this paper, we consider the partitioned EDF-VD scheduling problem of mixed critical systems with two criticality levels (LO and HI) on identical multiprocessors. Partitioned scheduling is an NP-hard problem that has been widely studied in the literature. The most common metaheuristic to solve partitioning problems consists in ordering tasks by a given criteria (such as task utilization) then assign tasks to processors in that order, choosing which processor using a heuristic rule such as First Fit or Best Fit. The current state of the art results show that First Fit Decreasing Density provides the best success ratio for single-criticality scheduling. In the context of mixedcriticality, we would like to investigate whether this is also true for assigning LO and HI critical tasks to processors. We consider two cases, one called “criticality aware” that ﬁrst tries to assign HI tasks to processors and then LO tasks separately and the other one called “criticality unaware” that assigns tasks without taking their criticality into account. We test the performance of all combinations of sorting/partitioning heuristics in both cases, which leads to 1024 different heuristics in the aware case and 32 in the unaware case. We deﬁne two search algorithms to efﬁciently ﬁnd which of these heuristics obtains the best success ratio. In addition, a new mixed-criticality multiprocessor random task set generation algorithm is proposed.},
	language = {en},
	author = {Rodriguez, Paul and George, Laurent and Abdeddaım, Yasmina and Goossens, Joel},
	pages = {6},
}

@article{ekberg_state-based_nodate,
	title = {State-{Based} {Mode} {Switching} with {Applications} to {Mixed}-{Criticality} {Systems}},
	abstract = {We present a new graph-based real-time task model that can specify complex job arrival patterns and global statebased mode switching. The mode switching is of a mixedcriticality style, enabling immediate changes to the parameters of active jobs upon mode switches. The resulting task model therefore generalizes previously proposed task graph models as well as mixed-criticality (sporadic) task models, and further allows for the modeling of timing properties not found in any of these models. We outline an EDF uniprocessor schedulability analysis procedure by combining ideas from prior analysis methods for graph-based and mixed-criticality task scheduling.},
	language = {en},
	author = {Ekberg, Pontus and Stigge, Martin and Guan, Nan and Yi, Wang},
	pages = {6},
}

@article{graydon_safety_nodate,
	title = {Safety {Assurance} {Driven} {Problem} {Formulation} for {Mixed}-{Criticality} {Scheduling}},
	abstract = {In 2007, Vestal proposed Mixed-Criticality Scheduling (MCS) to increase utilisation despite imperfect timing evidence. Others have since reﬁned the MCS problem formulation, proposed alternative scheduling approaches, and evaluated their performance. We assess existing MCS problem formulations from a safety assurance perspective and report problems found. Among these is the use of the word ‘criticality’ to mean several related but distinctly different things such as Safety Integrity Levels (SIL), importance, and conﬁdence. We conclude with suggestions for addressing the problems found.},
	language = {en},
	author = {Graydon, Patrick and Bate, Iain},
	pages = {6},
}

@inproceedings{pellizzoni_handling_2009,
	title = {Handling mixed-criticality in {SoC}-based real-time embedded systems},
	isbn = {978-1-60558-627-4},
	url = {http://portal.acm.org/citation.cfm?doid=1629335.1629367},
	doi = {10.1145/1629335.1629367},
	abstract = {System-on-Chip (SoC) is a promising paradigm to implement safety-critical embedded systems, but it poses signiﬁcant challenges from a design and veriﬁcation point of view. In particular, in a mixed-criticality system, low criticality applications must be prevented from interfering with high criticality ones. In this paper, we introduce a new design methodology for SoC that provides strong isolation guarantees to applications with diﬀerent criticalities. A set of certiﬁcates describing the assumed application behavior is extracted from a functional Architectural Analysis and Design Language (AADL) speciﬁcation. Our tools then automatically generate hardware wrappers that enforce at run-time the behavior described by the certiﬁcates. In particular, we employ run-time monitoring to formally check all data communication in the system, and we enforce timing reservations for both computation and communication resources. Veriﬁcation is greatly simpliﬁed because certiﬁcates are much simpler than the components used to implement low-criticality applications. The eﬀectiveness of our methodology is proven on a case study consisting of a medical pacemaker.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Pellizzoni, Rodolfo and Meredith, Patrick and Nam, Min-Young and Sun, Mu and Caccamo, Marco and Sha, Lui},
	year = {2009},
	pages = {235},
}

@article{sabeghi_runtime_nodate,
	title = {Runtime {Multitasking} {Support} on {Reconfigurable} {Accelerators}},
	abstract = {Serving several applications at runtime on a reconfigurable machine is a challenging problem in which the reconfigurable fabric has to be shared among competing tasks. Due to the inherent complexity of assigning tasks to the FPGA, a comprehensive runtime system is required to address all the conflicting issues between competing applications’ demands and to keep the system performance at the required level. In this paper, we present a runtime environment wherein a number of components introduced to handle the task assignment problem in a very low overhead fashion. We present the details of each component and evaluate the overhead imposed by each.},
	language = {en},
	author = {Sabeghi, Mojtaba and Mushtaq, Hamid and Bertels, Koen and Sabeghi, M and Mushtaq, H and Bertels, K L M},
	pages = {6},
}

@inproceedings{santy_relaxing_2012,
	title = {Relaxing {Mixed}-{Criticality} {Scheduling} {Strictness} for {Task} {Sets} {Scheduled} with {FP}},
	isbn = {978-1-4673-2032-0},
	url = {http://ieeexplore.ieee.org/document/6257568/},
	doi = {10.1109/ECRTS.2012.39},
	abstract = {Current trends in the embedded systems ﬁeld tend to collocate multiple functionalities upon a single computing platform, the aim being to reduce both the size and cost of embedded systems. Nevertheless, it is unlikely that all functionalities share the same level of criticality, and certiﬁcation of the system has to be achieved using varying degrees of rigorousness. Typically, a task τi is guaranteed to meet its temporal constraints up to a criticality level that is equal to its own criticality. When those conditions are no longer met, i.e. when another higher priority task τj has its execution time that exceeds its Worst Case Execution Time (WCET) w.r.t. the criticality level of τi, a common approach is to suspend τi. However, in some cases, it may not be necessary to suspend tasks with a lower criticality immediately as they could still be executed without compromising the deadlines of high criticality tasks. As a step towards this aim, we propose a method, denoted Latest Completion Time (LCT), that allows lower criticality tasks to proceed with their execution as long as they do not prevent higher criticality tasks from meeting their deadlines. Furthermore, we show that tasks suspension can only be temporary, and prove that a particular deﬁnition of idle times can be used to reset the system’s criticality level. Finally, we study the performances of our LCT mechanism w.r.t. the classical mechanism that suspends a task as soon as the system criticality level becomes higher than its own criticality.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Santy, Francois and George, Laurent and Thierry, Philippe and Goossens, Joel},
	month = jul,
	year = {2012},
	pages = {155--165},
}

@article{sarkar_push-assisted_nodate,
	title = {Push-assisted migration of real-time tasks in multi-core processors},
	abstract = {Multicores are becoming ubiquitous, not only in general-purpose but also embedded computing. This trend is a reﬂexion of contemporary embedded applications posing steadily increasing demands in processing power. On such platforms, prediction of timing behavior to ensure that deadlines of real-time tasks can be met is becoming increasingly difﬁcult. While real-time multicore scheduling approaches help to assure deadlines based on ﬁrm theoretical properties, their reliance on task migration poses a signiﬁcant challenge to timing predictability in practice. Task migration actually (a) reduces timing predictability for contemporary multicores due to cache warm-up overheads while (b) increasing trafﬁc on the network-on-chip (NoC) interconnect.},
	language = {en},
	author = {Sarkar, Abhik and Mueller, Frank and Ramaprasad, Harini and Mohan, Sibin},
	pages = {10},
}

@inproceedings{park_dynamic_2011,
	title = {Dynamic scheduling algorithm and its schedulability analysis for certifiable dual-criticality systems},
	isbn = {978-1-4503-0714-7},
	url = {http://dl.acm.org/citation.cfm?doid=2038642.2038681},
	doi = {10.1145/2038642.2038681},
	abstract = {Real-time embedded systems are becoming more complex to include multiple functionalities. Sharing a computing platform is a natural and eﬀective solution to reducing the cost of those systems. However, the sharing can cause serious problems in mixed-criticality systems where applications have diﬀerent levels of criticality. Certifying the mixed-criticality systems requires eﬃcient scheduling algorithms and schedulability tests diﬀerent from the ones used in single criticality systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Park, Taeju and Kim, Soontae},
	year = {2011},
	pages = {253},
}

@inproceedings{voss_deployment_2013,
	title = {Deployment and {Scheduling} {Synthesis} for {Mixed}-{Critical} {Shared}-{Memory} {Applications}},
	isbn = {978-0-7695-4991-0},
	url = {http://ieeexplore.ieee.org/document/6601578/},
	doi = {10.1109/ECBS.2013.23},
	abstract = {This paper presents an efﬁcient approach for generating suitable system architectures for embedded systems efﬁciently. Thereby, we focus on a joint generation of schedules and deployment for mixed-criticality multicore architectures using shared memory. The presented approach computes task and message schedules that are optimized with respect to a global discrete time base. As part of the solution, our approach generates an optimized assignment of tasks to computation resources (cores) concerning local memory constraints of cores and criticality constraints of tasks. This approach is integrated into the AUTOFOCUS 3 tool-chain, using a formally deﬁned model of computation with explicit data-ﬂow and discrete-time semantics to develop multi-criticality embedded systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Voss, Sebastian and Schatz, Bernhard},
	month = apr,
	year = {2013},
	pages = {100--109},
}

@inproceedings{li_algorithm_2010,
	title = {An {Algorithm} for {Scheduling} {Certifiable} {Mixed}-{Criticality} {Sporadic} {Task} {Systems}},
	isbn = {978-0-7695-4298-0},
	url = {http://ieeexplore.ieee.org/document/5702229/},
	doi = {10.1109/RTSS.2010.18},
	abstract = {Many safety-critical embedded systems are subject to certiﬁcation requirements. However, only a subset of the functionality of the system may be safety-critical and hence subject to certiﬁcation; the rest of the functionality is non safety-critical and does not need to be certiﬁed. Certiﬁcation requirements in such “mixedcriticality” systems give rise to some interesting scheduling problems, that cannot be satisfactorily addressed using techniques from conventional scheduling theory. In prior work, we have studied the scheduling and analysis of mixed criticality systems that are speciﬁed as ﬁnite collections of jobs executing on a single shared preemptive processor. In this paper, we consider mixed criticality systems that are comprised of ﬁnite collections of recurrent tasks, speciﬁed using a mixed-criticality generalization of the widelyused sporadic tasks model. We design a priority-based algorithm for scheduling such systems, derive an algorithm for computing priorities, and obtain a sufﬁcient schedulability condition for efﬁciently determining whether a given mixed-criticality system can be successfully scheduled by this algorithm.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Li, Haohan and Baruah, Sanjoy},
	month = nov,
	year = {2010},
	pages = {183--192},
}

@inproceedings{tamas-selicean_optimization_2011,
	title = {Optimization of {Time}-{Partitions} for {Mixed}-{Criticality} {Real}-{Time} {Distributed} {Embedded} {Systems}},
	isbn = {978-1-4577-0303-4},
	url = {http://ieeexplore.ieee.org/document/5753505/},
	doi = {10.1109/ISORCW.2011.11},
	abstract = {In this paper we are interested in mixed-criticality embedded real-time applications mapped on distributed heterogeneous architectures. The architecture provides both spatial and temporal partitioning, thus enforcing enough separation for the critical applications. With temporal partitioning, each application is allowed to run only within predeﬁned time slots, allocated on each processor. The sequence of time slots for all the applications on a processor are grouped within a Major Frame, which is repeated periodically. We assume that the safety-critical applications (on all criticality levels) are scheduled using static-cyclic scheduling and the noncritical applications are scheduled using ﬁxed-priority preemptive scheduling. We consider that each application runs in a separate partition, and each partition is allocated several time slots on the processors where the application is mapped. We are interested to determine the sequence and size of the time slots within the Major Frame on each processor such that both the safety-critical and non-critical applications are schedulable. We have proposed a Simulated Annealing-based approach to solve this optimization problem. The proposed algorithm has been evaluated using several synthetic and real-life benchmarks.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Tamas-Selicean, Domitian and Pop, Paul},
	month = mar,
	year = {2011},
	pages = {1--10},
}

@inproceedings{tamas-selicean_task_2011,
	title = {Task {Mapping} and {Partition} {Allocation} for {Mixed}-{Criticality} {Real}-{Time} {Systems}},
	isbn = {978-1-4577-2005-5 978-0-7695-4590-5},
	url = {http://ieeexplore.ieee.org/document/6133094/},
	doi = {10.1109/PRDC.2011.42},
	abstract = {In this paper we address the mapping of mixedcriticality hard real-time applications on distributed embedded architectures. We assume that the architecture provides both spatial and temporal partitioning, thus enforcing enough separation between applications. With temporal partitioning, each application runs in a separate partition, and each partition is allocated several time slots on the processors where the application is mapped. The sequence of time slots for all the applications on a processor are grouped within a Major Frame, which is repeated periodically. We assume that the applications are scheduled using static-cyclic scheduling. We are interested to determine the task mapping to processors, and the sequence and size of the time slots within the Major Frame on each processor, such that the applications are schedulable. We have proposed a Tabu Search-based approach to solve this optimization problem. The proposed algorithm has been evaluated using several synthetic and real-life benchmarks.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Tamas-Selicean, Domitian and Pop, Paul},
	month = dec,
	year = {2011},
	pages = {282--283},
}

@article{saraswat_task_2009,
	title = {Task migration for fault-tolerance in mixed-criticality embedded systems},
	volume = {6},
	issn = {15513688},
	url = {http://portal.acm.org/citation.cfm?doid=1851340.1851348},
	doi = {10.1145/1851340.1851348},
	abstract = {In this paper we are interested in mixed-criticality embedded applications implemented on distributed architectures. Depending on their time-criticality, tasks can be hard or soft real-time and regarding safety-criticality, tasks can be fault-tolerant to transient faults, permanent faults, or have no dependability requirements. We use Earliest Deadline First (EDF) scheduling for the hard tasks and the Constant Bandwidth Server (CBS) for the soft tasks. The CBS parameters determine the quality of service (QoS) of soft tasks. Transient faults are tolerated using checkpointing with rollback recovery. For tolerating permanent faults in processors, we use task migration, i.e., restarting the safety-critical tasks on other processors. We propose a Greedy-based online heuristic for the migration of safety-critical tasks, in response to permanent faults, and the adjustment of CBS parameters on the target processors, such that the faults are tolerated, the deadlines for the hard real-time tasks are satisﬁed and the QoS for soft tasks is maximized. The proposed online adaptive approach has been evaluated using several synthetic benchmarks and a real-life case study.},
	language = {en},
	number = {3},
	urldate = {2018-07-09},
	journal = {ACM SIGBED Review},
	author = {Saraswat, Prabhat Kumar and Pop, Paul and Madsen, Jan},
	month = oct,
	year = {2009},
	pages = {1},
}

@inproceedings{baruah_preemptive_2012,
	title = {The {Preemptive} {Uniprocessor} {Scheduling} of {Mixed}-{Criticality} {Implicit}-{Deadline} {Sporadic} {Task} {Systems}},
	isbn = {978-1-4673-2032-0},
	url = {http://ieeexplore.ieee.org/document/6257567/},
	doi = {10.1109/ECRTS.2012.42},
	abstract = {Systems in many safety-critical application domains are subject to certiﬁcation requirements. For any given system, however, it may be the case that only a subset of its functionality is safety-critical and hence subject to certiﬁcation; the rest of the functionality is non safety critical and does not need to be certiﬁed, or is certiﬁed to a lower level of assurance. An algorithm called EDF-VD (for Earliest Deadline First with Virtual Deadlines) is described for the scheduling of such mixed-criticality task systems. Analyses of EDF-VD signiﬁcantly superior to previously-known ones are presented, based on metrics such as processor speedup factor (EDF-VD is proved to be optimal with respect to this metric) and utilization bounds.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, S. and Bonifaci, V. and DAngelo, G. and Li, H. and Marchetti-Spaccamela, A. and van der Ster, S. and Stougie, L.},
	month = jul,
	year = {2012},
	pages = {145--154},
}

@inproceedings{vestal_preemptive_2007,
	title = {Preemptive {Scheduling} of {Multi}-criticality {Systems} with {Varying} {Degrees} of {Execution} {Time} {Assurance}},
	isbn = {978-0-7695-3062-8},
	url = {http://ieeexplore.ieee.org/document/4408308/},
	doi = {10.1109/RTSS.2007.47},
	abstract = {This paper is based on a conjecture that the more conﬁdence one needs in a task execution time bound (the less tolerant one is of missed deadlines), the larger and more conservative that bound tends to become in practice. We assume diﬀerent tasks perform functions having diﬀerent criticalities and requiring diﬀerent levels of assurance. We assume a task may have a set of alternative worst-case execution times, each assured to a diﬀerent level of conﬁdence. This paper presents ways to use this information to obtain more precise schedulability analysis and more eﬃcient preemptive ﬁxed priority scheduling. These methods are evaluated using workloads abstracted from production avionics systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Vestal, Steve},
	month = dec,
	year = {2007},
	pages = {239--243},
}

@inproceedings{yun_memory_2012,
	title = {Memory {Access} {Control} in {Multiprocessor} for {Real}-{Time} {Systems} with {Mixed} {Criticality}},
	isbn = {978-1-4673-2032-0},
	url = {http://ieeexplore.ieee.org/document/6257581/},
	doi = {10.1109/ECRTS.2012.32},
	abstract = {Shared resource access interference, particularly memory and system bus, is a big challenge in designing predictable real-time systems because its worst case behavior can signiﬁcantly differ. In this paper, we propose a software based memory throttling mechanism to explicitly control the memory interference. We developed analytic solutions to compute proper throttling parameters that satisfy schedulability of critical tasks while minimize performance impact caused by throttling. We implemented the mechanism in Linux kernel and evaluated isolation guarantee and overall performance impact using a set of synthetic and real applications.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Yun, Heechul and Yao, Gang and Pellizzoni, Rodolfo and Caccamo, Marco and Sha, Lui},
	month = jul,
	year = {2012},
	pages = {299--308},
}

@article{zhu_optimization_2012,
	title = {Optimization of task allocation and priority assignment in hard real-time distributed systems},
	volume = {11},
	issn = {15399087},
	url = {http://dl.acm.org/citation.cfm?doid=2362336.2362352},
	doi = {10.1145/2362336.2362352},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {ACM Transactions on Embedded Computing Systems},
	author = {Zhu, Qi and Zeng, Haibo and Zheng, Wei and Natale, Marco DI and Sangiovanni-Vincentelli, Alberto},
	month = dec,
	year = {2012},
	pages = {1--30},
}

@article{davis_survey_2011,
	title = {A survey of hard real-time scheduling for multiprocessor systems},
	volume = {43},
	issn = {03600300},
	url = {http://dl.acm.org/citation.cfm?doid=1978802.1978814},
	doi = {10.1145/1978802.1978814},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {ACM Computing Surveys},
	author = {Davis, Robert I. and Burns, Alan},
	month = oct,
	year = {2011},
	pages = {1--44},
}

@article{kwok_static_1999,
	title = {Static scheduling algorithms for allocating directed task graphs to multiprocessors},
	volume = {31},
	issn = {03600300},
	url = {http://portal.acm.org/citation.cfm?doid=344588.344618},
	doi = {10.1145/344588.344618},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {ACM Computing Surveys},
	author = {Kwok, Yu-Kwong and Ahmad, Ishfaq},
	month = dec,
	year = {1999},
	pages = {406--471},
}

@article{singh_mapping_nodate,
	title = {Mapping on multi/many-core systems: survey of current and emerging trends},
	abstract = {The reliance on multi/many-core systems to satisfy the high performance requirement of complex embedded software applications is increasing. This necessitates the need to realize eﬃcient mapping methodologies for such complex computing platforms. This paper provides an extensive survey and categorization of state-of-the-art mapping methodologies and highlights the emerging trends for multi/many-core systems. The methodologies aim at optimizing system’s resource usage, performance, power consumption, temperature distribution and reliability for varying application models. The methodologies perform design-time and run-time optimization for static and dynamic workload scenarios, respectively. These optimizations are necessary to fulﬁll the end-user demands. Comparison of the methodologies based on their optimization aim has been provided. The trend followed by the methodologies and open research challenges have also been discussed.},
	language = {en},
	author = {Singh, Amit Kumar and Shafique, Muhammad and Kumar, Akash},
	pages = {10},
}

@article{zhuravlev_survey_2012,
	title = {Survey of scheduling techniques for addressing shared resources in multicore processors},
	volume = {45},
	issn = {03600300},
	url = {http://dl.acm.org/citation.cfm?doid=2379776.2379780},
	doi = {10.1145/2379776.2379780},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {ACM Computing Surveys},
	author = {Zhuravlev, Sergey and Saez, Juan Carlos and Blagodurov, Sergey and Fedorova, Alexandra and Prieto, Manuel},
	month = nov,
	year = {2012},
	pages = {1--28},
}

@inproceedings{dolif_communication-aware_2007,
	title = {Communication-aware stochastic allocation and scheduling framework for conditional task graphs in multi-processor systems-on-chip},
	isbn = {978-1-59593-825-1},
	url = {http://portal.acm.org/citation.cfm?doid=1289927.1289940},
	doi = {10.1145/1289927.1289940},
	abstract = {The increasing levels of system integration in Multi-Processor System-on-Chips (MPSoCs) emphasize the need for new design ﬂows for eﬃcient mapping of multi-task applications onto hardware platforms. Even though data-ﬂow graphs are often used for pure data-streaming, many realistic applications can only be speciﬁed as conditional task graphs (CTG). The problem of allocating and scheduling conditional task graphs on processors in a distributed real-time system is NP-hard. The ﬁrst contribution of this paper is a complete stochastic allocation and scheduling framework, where an MPSoC virtual platform is used to accurately derive input parameters, validate abstract models of system components and assess constraint satisfaction and objective function optimization. The optimizer implements an eﬃcient and exact approach to allocation and scheduling based on problem decomposition. The original contributions of the approach appear both in the allocation and in the scheduling part of the optimizer. For the ﬁrst, we propose an exact analytic formulation of the stochastic objective function based on the task graph analysis, while for the scheduling part we extend the timetable constraint for conditional activities. The second contribution of this paper is the introduction of a software library and API for the deployment of conditional task graph applications onto Multi-Processor System-on-Chips. With our library support, programmers can quickly develop multi-task applications which will run on a multi-core architecture and can easily apply the optimal solution found by our optimizer. The proposed programming support manages OS-level issues, such as task allocation and scheduling, as well as task-level issues, like inter-task communication and synchronization.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Dolif, Emiliano and Lombardi, Michele and Ruggiero, Martino and Milano, Michela and Benini, Luca},
	year = {2007},
	pages = {47},
}

@inproceedings{guan_cache-aware_2009,
	title = {Cache-aware scheduling and analysis for multicores},
	isbn = {978-1-60558-627-4},
	url = {http://portal.acm.org/citation.cfm?doid=1629335.1629369},
	doi = {10.1145/1629335.1629369},
	abstract = {The major obstacle to use multicores for real-time applications is that we may not predict and provide any guarantee on real-time properties of embedded software on such platforms; the way of handling the on-chip shared resources such as L2 cache may have a signiﬁcant impact on the timing predictability. In this paper, we propose to use cache space isolation techniques to avoid cache contention for hard realtime tasks running on multicores with shared caches. We present a scheduling strategy for real-time tasks with both timing and cache space constraints, which allows each task to use a ﬁxed number of cache partitions, and makes sure that at any time a cache partition is occupied by at most one running task. In this way, the cache spaces of tasks are isolated at run-time.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Guan, Nan and Stigge, Martin and Yi, Wang and Yu, Ge},
	year = {2009},
	pages = {245},
}

@inproceedings{bernat_wcet_2002,
	title = {{WCET} analysis of probabilistic hard real-time systems},
	isbn = {978-0-7695-1851-0},
	url = {http://ieeexplore.ieee.org/document/1181582/},
	doi = {10.1109/REAL.2002.1181582},
	abstract = {Traditional approaches for worst case execution time (WCET) analysis produce values which are very pessimistic if applied to modern processors. In addition, end to end measurements as used in industry produce estimates of the execution time that potentially underestimate the real worst case execution time. We introduce the notion of probabilistic hard real-time system as a system which has to meet all the deadlines but for which a (high) probabilistic guarantee sufﬁces. We combine both measurement and analytical approaches into a model for computing probabilistically bounds on the execution time of the worst case path of sections of code. The idea of the technique presented is based on combining (probabilistically) the worst case effects seen in individual blocks to build the execution time model of the worst case path of the program (such case may have not been observed in the measurements). We provide three alternative operators for the combination based on whether the information of their dependency is known. Experimental evaluation of a two case study shows extremely low probabilities of the values obtained by traditional analysis.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Bernat, G. and Colin, A. and Petters, S.M.},
	year = {2002},
	pages = {279--288},
}

@inproceedings{baruah_certification-cognizant_2011,
	title = {Certification-{Cognizant} {Time}-{Triggered} {Scheduling} of {Mixed}-{Criticality} {Systems}},
	isbn = {978-1-4577-2000-0},
	url = {http://ieeexplore.ieee.org/document/6121421/},
	doi = {10.1109/RTSS.2011.9},
	abstract = {In many modern embedded platforms, safetycritical functionalities that must be certiﬁed correct to very high levels of assurance co-exist with less critical software that are not subject to certiﬁcation requirements. Recent research in realtime scheduling theory has yielded some promising techniques for meeting the dual goals of (i) being able to certify the safetycritical functionalities under very conservative assumptions, and (ii) ensuring high utilization of platform resources under less pessimistic assumptions . This research has centered on an event-triggered/ priority-driven approach to scheduling. However current practice in many safety-critical domains, including (the safety-critical components of) automotive and avionics systems and factory automation, favors a time-triggered approach. In such time-triggered systems, non-interference of safety-critical components by non-critical ones is ensured by strict isolation between components of different criticalities; although such isolation facilitates the certiﬁcation of the safety-critical functionalities, it can cause very low resource utilization.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Baruah, Sanjoy and Fohler, Gerhard},
	month = nov,
	year = {2011},
	pages = {3--12},
}

@article{theis_mixed_nodate,
	title = {Mixed {Criticality} {Scheduling} in {Time}-{Triggered} {Legacy} {Systems}},
	abstract = {Research on mixed criticality real-time scheduling has centered on an event-triggered (ET)/ priority-driven approach to scheduling. Regarding the time-triggered (TT) approach, which seems to have greater acceptability with certiﬁcation authorities for safety critical domains, only ﬁrst results have been presented, showing proof-of-concept of TT mixed criticality scheduling algorithms and comparing their resource utilization guarantees to those of ET ones. The algorithm is based on the ofﬂine construction of two coordinated schedule tables and an online mechanism. As a consequence, existing schedule tables for single criticality, possibly certiﬁed, have to be discarded.},
	language = {en},
	author = {Theis, Jens and Fohler, Gerhard},
	pages = {6},
}

@inproceedings{herrera_towards_2013,
	title = {Towards a {Modelling} and {Design} {Framework} for {Mixed}-{Criticality} {SoCs} and {Systems}-of-{Systems}},
	isbn = {978-1-4799-2978-8},
	url = {http://ieeexplore.ieee.org/document/6628385/},
	doi = {10.1109/DSD.2013.112},
	abstract = {Mixed-criticality system (MCS) design is an emerging discipline, which has been identiﬁed as a core foundational concept in ﬁelds such as cyber-physical systems. The hard realtime design community has pioneered the contributions to MCS design, extending scheduling theory to consider mixed-criticalities and the impact of on-chip and off-chip communication infrastructures. However, the development of MCS design methodologies capable to provide safe and efﬁcient solutions for complex applications and platforms in an acceptable design time demands a more interdisciplinary approach. This paper is a ﬁrst step towards such an approach in the development of MCS design methodologies . The paper ﬁrst identiﬁes main design disciplines to be involved in MCS design, both at SoC and system-ofsystems (SoS) scales. Then, the paper proposes a core ontology for modelling a mixed-criticality system at both SoC scale (MCSoC) and SoS scale (MCSoS). Finally, the paper introduces a set of aspects required for MCS design which have been identiﬁed as open and challenging attending the overviewed state-of-the-art.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Herrera, Fernando and Niaki, Seyed Hosein Attarzadeh and Sander, Ingo},
	month = sep,
	year = {2013},
	pages = {989--996},
}

@article{rushby_critical_1994,
	title = {Critical system properties: survey and taxonomy},
	volume = {43},
	issn = {09518320},
	shorttitle = {Critical system properties},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0951832094900655},
	doi = {10.1016/0951-8320(94)90065-5},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Rushby, John},
	month = jan,
	year = {1994},
	pages = {189--219},
}

@article{harchol-balter_task_nodate,
	title = {Task {Assignment} with {Unknown} {Duration}},
	abstract = {We consider a distributed server system and ask which policy should be used for assigning jobs (tasks) to hosts. In our server, jobs are not preemptible. Also, the job’s service demand is not known a priori. We are particularly concerned with the case where the workload is heavy-tailed, as is characteristic of many empirically measured computer workloads. We analyze several natural task assignment policies and propose a new one TAGS (Task Assignment based on Guessing Size). The TAGS algorithm is counterintuitive in many respects, including load unbalancing, non-workconserving, and fairness. We ﬁnd that under heavy-tailed workloads, TAGS can outperform all task assignment policies known to us by several orders of magnitude with respect to both mean response time and mean slowdown, provided the system load is not too high. We also introduce a new practical performance metric for distributed servers called server expansion. Under the server expansion metric, TAGS signiﬁcantly outperforms all other task assignment policies, regardless of system load.},
	language = {en},
	author = {HARCHOL-BALTER, MOR},
	pages = {29},
}

@incollection{hutchison_meeting_2012,
	address = {Berlin, Heidelberg},
	title = {Meeting {Real}-{Time} {Requirements} with {Multi}-core {Processors}},
	volume = {7613},
	isbn = {978-3-642-33674-4 978-3-642-33675-1},
	url = {http://link.springer.com/10.1007/978-3-642-33675-1_10},
	abstract = {Many multi-core processors exhibit characteristics that make it diﬃcult or even impossible to use them in safety-critical real-time systems. To prevent sporadic failures and late-stage integration problems, the hardware properties of the processor and its peripherals have to be checked for their real-time capability at an early project stage. Selecting a conﬁguration which enables predictable performance is an important requirement to achieve compliance with current safety standards, e.g., ISO-26262, IEC-61508, EN-50128, or DO-178B.},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {Computer {Safety}, {Reliability}, and {Security}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kästner, Daniel and Schlickling, Marc and Pister, Markus and Cullmann, Christoph and Gebhard, Gernot and Heckmann, Reinhold and Ferdinand, Christian},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Ortmeier, Frank and Daniel, Peter},
	year = {2012},
	doi = {10.1007/978-3-642-33675-1_10},
	pages = {117--131},
}

@inproceedings{neukirchner_multi-mode_2013,
	title = {Multi-mode monitoring for mixed-criticality real-time systems},
	isbn = {978-1-4799-1417-3},
	url = {http://ieeexplore.ieee.org/document/6659021/},
	doi = {10.1109/CODES-ISSS.2013.6659021},
	abstract = {We present a scheme for monitoring activation patterns of multiple tasks in mixed-criticality real-time systems. Unlike previous approaches, which enforce a single pre-deﬁned activation pattern bound per task, we propose a multi-mode approach, where monitors can dynamically switch between diﬀerent conﬁgurations, depending on the observed activation pattern at other tasks. The required conﬁgurations are based on real-time interfaces which we determine through sensitivity analysis. In an evaluation we show, that switching between monitor conﬁgurations allows to dynamically reassign timing slack between tasks and thereby achieve better resource utilization and still provide the same timing guarantees.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Neukirchner, Moritz and Lampka, Kai and Quinton, Sophie and Ernst, Rolf},
	month = sep,
	year = {2013},
	pages = {1--10},
}

@inproceedings{nowotsch_quality_2013,
	title = {Quality of service capabilities for hard real-time applications on multi-core processors},
	isbn = {978-1-4503-2058-0},
	url = {http://dl.acm.org/citation.cfm?doid=2516821.2516826},
	doi = {10.1145/2516821.2516826},
	abstract = {Computing Worst-Case Execution Times (WCETs) for applications executed on multi-core processors is a challenging topic since possible interferences on shared resources need to be considered. Some approaches are already proposed in literature, but the problem is still not suﬃciently solved. Diﬀerent approaches suﬀer diﬀerent shortcomings. For instance, the mutual analysis of multiple applications leads to great computational complexity, pessimistic assumptions on the interference between tasks causes highly overestimated WCETs and resource privatisation dissipates processor resources. In this paper we tackle the problems of overestimated WCETs due to pessimistic analysis and diﬀerences between average-case and worst-case execution timing. We introduce a new computing paradigm for safety-critical real-time systems, which enables Quality of Service (QoS) properties to increase the utilisation of multi-core processors while still guaranteeing bounds on the worst-case behavior. This paradigm is one approach to raise multi-core performance over single-core processors, even for hard real-time systems. For evaluation we use abstractions of real applications. The concepts are implemented on Freescale’s P4080 multi-core processor and AbsInt’s timing analysis framework aiT. The results show an increased processor core and system utilisation of up to 99.9\% and 59.3\% respectively, while still providing hard deadline guarantees for all applications.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Nowotsch, Jan and Paulitsch, Michael},
	year = {2013},
	pages = {151},
}

@article{kalyanasundaram_speed_2000,
	title = {Speed is as powerful as clairvoyance},
	volume = {47},
	issn = {00045411},
	url = {http://portal.acm.org/citation.cfm?doid=347476.347479},
	doi = {10.1145/347476.347479},
	abstract = {We introduce resource augmentation as a method for analyzing online scheduling problems. In resource augmentation analysis the on-line scheduler is given more resources, say faster processors or more processors, than the adversary. We apply this analysis to two well-known on-line scheduling problems, the classic uniprocessor CPU scheduling problem 1͉ri, pmtn͉͚ Fi, and the best-effort firm real-time scheduling problem 1͉ri, pmtn͉͚ wi(1 Ϫ Ui). It is known that there are no constant competitive nonclairvoyant on-line algorithms for these problems. We show that there are simple on-line scheduling algorithms for these problems that are constant competitive if the online scheduler is equipped with a slightly faster processor than the adversary. Thus, a moderate increase in processor speed effectively gives the on-line scheduler the power of clairvoyance. Furthermore, the on-line scheduler can be constant competitive on all inputs that are not closely correlated with processor speed. We also show that the performance of an on-line scheduler in best-effort real time scheduling can be significantly improved if the system is designed in such a way that the laxity of every job is proportional to its length.},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {Journal of the ACM},
	author = {Kalyanasundaram, Bala and Pruhs, Kirk},
	month = jul,
	year = {2000},
	pages = {617--643},
}

@article{radojkovic_evaluation_2012,
	title = {On the evaluation of the impact of shared resources in multithreaded {COTS} processors in time-critical environments},
	volume = {8},
	issn = {15443566},
	url = {http://dl.acm.org/citation.cfm?doid=2086696.2086713},
	doi = {10.1145/2086696.2086713},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {ACM Transactions on Architecture and Code Optimization},
	author = {Radojković, Petar and Girbal, Sylvain and Grasset, Arnaud and Quiñones, Eduardo and Yehia, Sami and Cazorla, Francisco J.},
	month = jan,
	year = {2012},
	pages = {1--25},
}

@inproceedings{colnaric_state_1999,
	title = {State of the art review paper: advances in embedded hard real-time systems design},
	volume = {1},
	isbn = {978-0-7803-5662-7},
	shorttitle = {State of the art review paper},
	url = {http://ieeexplore.ieee.org/document/801753/},
	doi = {10.1109/ISIE.1999.801753},
	abstract = {In the presentation, the most important and necessary properties of embedded real-time systems, and the ways t o achieve them, will be explored. The basic and most important domains of real-time systems design will be dealt with, starting with the processor and system hardware architectures, over operating systems, tasking and scheduling, high-level real-time programming languages, worst case execution time and schedulability analysis, t o application design engineering and safety critical applications. Common misconceptions which are still strongly present in the control systems design will be identified, guidelines for the consistent implementation will be proposed and sample solutions in certain areas will be presented.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Colnaric, M.},
	year = {1999},
	pages = {37--42},
}

@article{michalevsky_tight_nodate,
	title = {Tight {Schedule}: {Deadline} {Constrained} {Scheduling} of {OpenRadio} on a {Multi}-{Core} {Platform}},
	language = {en},
	author = {Michalevsky, C Copeland Y and Michelson, S},
	pages = {40},
}

@article{giannopoulou_timed_nodate,
	title = {Timed {Model} {Checking} with {Abstractions}: {Towards} {Worst}-{Case} {Response} {Time} {Analysis} in {Resource}-{Sharing} {Manycore} {Systems}},
	abstract = {Multicore architectures are increasingly used nowadays in embedded real-time systems. Parallel execution of tasks feigns the possibility of a massive increase in performance. However, this is usually not achieved because of contention on shared resources. Concurrently executing tasks mutually block their accesses to the shared resource, causing non-deterministic delays. Timing analysis of tasks in such systems is then far from trivial. Recently, several analytic methods have been proposed for this purpose, however, they cannot model complex arbitration schemes such as FlexRay which is a common bus arbitration protocol in the automotive industry. This paper considers real-time tasks composed of superblocks, i. e., sequences of computation and resource accessing phases. Resource accesses such as accesses to memories and caches are synchronous, i. e., they cause execution on the processing core to stall until the access is served. For such systems, the paper presents a state-based modeling and analysis approach based on Timed Automata which can model accurately arbitration schemes of any complexity. Based on it, we compute safe bounds on the worstcase response times of tasks. The scalability of the approach is increased signiﬁcantly by abstracting several cores and their tasks with one arrival curve, which represents their resource accesses and computation times. This curve is then incorporated into the Timed Automata model of the system. The accuracy and scalability of the approach are evaluated with a real-world application from the automotive industry and benchmark applications.},
	language = {en},
	author = {Giannopoulou, Georgia and Lampka, Kai and Stoimenov, Nikolay and Thiele, Lothar},
	pages = {10},
}

@phdthesis{pintard_safety_2015,
	type = {phdthesis},
	title = {From safety analysis to experimental validation by fault injection - {Case} of automotive embedded systems},
	url = {https://tel.archives-ouvertes.fr/tel-01216586/document},
	abstract = {Due to the rising complexity of automotive Electric/Electronic embedded systems, Functional Safety becomes a main issue in the automotive industry. This issue has been formalized by the introduction of the ISO 26262 standard for functional safety in 2011. The challenges are, on the one hand to design safe systems based on a systematic verification and validation approach, and on the other hand, the fulfilment of the requirements of the ISO 26262 standard. Following ISO 26262 recommendations, our approach, based on fault injection, aims at verifying fault tolerance mechanisms and non-functional requirements at all steps of the development cycle, from early design phases down to im-plementation. Fault injection is a verification technique that has been investigated for a long time. However, the role of fault injection during design phase and its complementarities with the experimental validation of the target have not been explored. In this work, we investigate a fault injection continuum, from system design validation to experiments on implemented targets. The proposed approach considers the safety analyses as a starting point, with the identification of safety mechanisms and safety requirements, and goes down to the validation of the implementation of safety mechanisms through fault injection ex-periments. The whole approach is based on a key fault injection framework, called FARM (Fault, Ac-tivation, Readouts and Measures). We show that this approach can be integrated in the development process of the automotive embedded systems described in the ISO 26262 standard. Our approach is illustrated on an automotive case study: a Front-Light system.},
	language = {en},
	urldate = {2018-07-09},
	school = {INP Toulouse},
	author = {Pintard, Ludovic},
	month = may,
	year = {2015},
}

@phdthesis{laarouchi_securites_2009,
	type = {phdthesis},
	title = {Sécurités (immunité et innocuité) des architectures ouvertes à niveaux de criticité multiples : application en avionique},
	shorttitle = {Sécurités (immunité et innocuité) des architectures ouvertes à niveaux de criticité multiples},
	url = {https://tel.archives-ouvertes.fr/tel-00468923/document},
	abstract = {La conception et le développement des applications critiques en avionique sont soumis à des contraintes strictes visant à assurer un niveau de confiance compatible avec les exigences de sécurité-innocuité (au sens safety) des tâches mises en Suvre. Ces contraintes induisent un accroissement considérable des coûts de production et de maintenance, ce qui rend le prix de revient de tels systèmes prohibitif. D'un autre côté, les composants sur étagère (Commercial Off-The-Shelf, COTS), matériels et logiciels, sont maintenant d'usage courant et offrent des services étendus pour un coût faible. Cependant, les COTS ne répondent pas aux contraintes d'innocuité exigées pour les tâches critiques ; de plus, ils présentent des vulnérabilités facilement exploitables par des attaques, les rendant incompatibles avec des exigences élevées de sécurité-immunité (au sens security). Il serait toutefois intéressant de profiter de tels composants dans un contexte avionique, mais en faisant en sorte qu'ils ne puissent affecter de façon préjudiciable les tâches critiques. Intégrer de tels composants dans les systèmes avioniques conduit donc à prendre en considération l'hétérogénéité des niveaux de confiance entre d'une part les applications critiques classiques, et d'autre part de nouvelles applications utilisant des composants sur étagère. Dans le cadre de cette thèse, nous proposons une architecture autorisant de telles interactions tout en préservant les propriétés de safety et security. La définition de cette architecture s'appuie sur le modèle Totel, et elle utilise la virtualisation afin de faciliter la mise en Suvre des mécanismes de tolérance aux fautes destinés à augmenter la crédibilité d'une application exécutée de façon répliquée sur des plateformes d'exécution COTS de niveau de confiance faible. Afin de valider notre approche, nous avons réalisé un prototype en nous appuyant sur deux cas d'étude identifiés avec Airbus et concernant tous deux des ordinateurs portables : un dédié à la maintenance et un au calcul du profil de décollage d'un avion.},
	language = {fr},
	urldate = {2018-07-09},
	school = {INSA de Toulouse},
	author = {Laarouchi, Youssef},
	month = nov,
	year = {2009},
}

@article{liu_scheduling_1973,
	title = {Scheduling {Algorithms} for {Multiprogramming} in a {Hard}-{Real}-{Time} {Environment}},
	volume = {20},
	issn = {0004-5411},
	url = {http://dl.acm.org/citation.cfm?id=321738.321743},
	doi = {10.1145/321738.321743},
	number = {1},
	urldate = {2018-07-09},
	journal = {Journal of the ACM (JACM)},
	author = {Liu, C. L. and Layland, James W.},
	month = jan,
	year = {1973},
	pages = {46--61},
}

@inproceedings{papazoglou_service-oriented_2003,
	title = {Service-oriented computing: concepts, characteristics and directions},
	isbn = {978-0-7695-1999-9},
	shorttitle = {Service-oriented computing},
	url = {http://ieeexplore.ieee.org/document/1254461/},
	doi = {10.1109/WISE.2003.1254461},
	abstract = {Service-Oriented Computing (SOC) is the computing paradigm that utilizes services as fundamental elements for developing applications/solutions. To build the service model, SOC relies on the Service Oriented Architecture (SOA), which is a way of reorganizing software applications and infrastructure into a set of interacting services. However, the basic SOA does not address overarching concerns such as management, service orchestration, service transaction management and coordination, security, and other concerns that apply to all components in a services architecture.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Papazoglou, M.P.},
	year = {2003},
	pages = {3--12},
}

@article{chen_partitioned_2015,
	title = {Partitioned {Multiprocessor} {Fixed}-{Priority} {Scheduling} of {Sporadic} {Real}-{Time} {Tasks}},
	url = {http://arxiv.org/abs/1505.04693},
	abstract = {Partitioned multiprocessor scheduling has been widely accepted in academia and industry to statically assign and partition real-time tasks onto identical multiprocessor systems. This paper studies fixed-priority partitioned multiprocessor scheduling for sporadic real-time systems, in which deadline-monotonic scheduling is applied on each processor. Prior to this paper, the best known results are by Fisher, Baruah, and Baker with speedup factors \$4-{\textbackslash}frac\{2\}\{M\}\$ and \$3-{\textbackslash}frac\{1\}\{M\}\$ for arbitrary-deadline and constrained-deadline sporadic real-time task systems, respectively, where \$M\$ is the number of processors. We show that a greedy mapping strategy has a speedup factor \$3-{\textbackslash}frac\{1\}\{M\}\$ when considering task systems with arbitrary deadlines. Such a factor holds for polynomial-time schedulability tests and exponential-time (exact) schedulability tests. Moreover, we also improve the speedup factor to \$2.84306\$ when considering constrained-deadline task systems. We also provide tight examples when the fitting strategy in the mapping stage is arbitrary and \$M\$ is sufficiently large. For both constrained- and arbitrary-deadline task systems, the analytical result surprisingly shows that using exact tests does not gain theoretical benefits (with respect to speedup factors) for an arbitrary fitting strategy.},
	language = {en},
	urldate = {2018-07-09},
	journal = {arXiv:1505.04693 [cs]},
	author = {Chen, Jian-Jia},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04693},
	keywords = {Computer Science - Data Structures and Algorithms},
}

@article{mok_multiframe_nodate,
	title = {A {Multiframe} {Model} for {Real}-{Time} {Tasks}},
	abstract = {The well-known periodic task model of Liu and Layland 1] assumes a worst-case execution time bound for every task and may be too pessimistic if the worst-case execution time of a task is much longer than the average. In this paper, we give a multiframe real-time task model which allows the execution time of a task to vary from one instance to another by specifying the execution time of a task in terms of a sequence of numbers. We investigate the schedulability problem for this model for the preemptive xed priority scheduling policy. We show that a signi cant improvement in the utilization bound can be established in our model.},
	language = {en},
	author = {Mok, Aloysius K and Chen, Deji},
	pages = {20},
}

@article{cucu_real-time_nodate,
	title = {Real-time scheduling for systems with precedence, periodicity and latency constraints},
	abstract = {First we present the main results concerning, in the one hand systems with periodicity constraints and deadlines, and in the other hand systems with precedence constraints and deadlines, in both cases for one computing resource. Then, we give a model in order to state clearly the problem for scheduling systems with precedence, periodicity and latency constraints. In order to solve this problem we give a nonpreemptive, off-line scheduling algorithm which uses in turn an algorithm of latency marking. We demonstrate the optimality of the scheduling algorithm, and after proving the equivalence of the notions of latency constraint and deadline, we extend this latter algorithm for scheduling realtime systems with precedence, periodicity constraints and deadlines for one computing resource.},
	language = {en},
	author = {Cucu, Liliana and Kocik, Remy and Sorel, Yves},
	pages = {15},
}

@inproceedings{mollison_mixed-criticality_2010,
	title = {Mixed-{Criticality} {Real}-{Time} {Scheduling} for {Multicore} {Systems}},
	isbn = {978-1-4244-7547-6},
	url = {http://ieeexplore.ieee.org/document/5578010/},
	doi = {10.1109/CIT.2010.320},
	abstract = {Current hard real-time scheduling and analysis techniques are unable to efﬁciently utilize the computational bandwidth provided by multicore platforms. This is due to the large gap between worst-case execution time predictions used in schedulability analysis and actual execution times seen in practice. In this paper, we view this gap as “slack” that can be accounted for during schedulability analysis and reclaimed for less critical work. We use this technique to develop an architecture for scheduling mixed-criticality real-time workloads on multiprocessor platforms. Our architecture provides temporal isolation among tasks of different criticalities while allowing slack to be redistributed across criticality levels.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Mollison, Malcolm S. and Erickson, Jeremy P. and Anderson, James H. and Baruah, Sanjoy K. and Scoredos, John A.},
	month = jun,
	year = {2010},
	pages = {1864--1871},
}

@inproceedings{kritikakou_run-time_2014,
	title = {Run-{Time} {Control} to {Increase} {Task} {Parallelism} {In} {Mixed}-{Critical} {Systems}},
	url = {http://ieeexplore.ieee.org/document/6932595/},
	doi = {10.1109/ECRTS.2014.14},
	abstract = {Although multi/many-core platforms enable the parallel execution of tasks, the sharing of resources may lead to long WCETs that fail to meet the real-time constraints of the system. Then, a safe solution is the execution of the most critical tasks in isolation followed by the execution of the remaining tasks. To improve the system performance, we propose an approach where a critical task can run in parallel with less critical tasks, as long as the real-time constraints are met. When no further interferences can be tolerated, the proposed run-time control suspends the low critical tasks until the termination of the critical task. In this paper, we describe the design and prove the correctness of our approach. To do so, a graph grammar is deﬁned to formally model the critical task as a set of control ﬂow graphs on which a safe partial WCET analysis is applied and used at run-time to control the safe execution of the critical task.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Kritikakou, Angeliki and Pagetti, Claire and Baldellon, Olivier and Roy, Matthieu and Rochange, Christine},
	month = jul,
	year = {2014},
	pages = {119--128},
}

@inproceedings{kritikakou_distributed_2014,
	title = {Distributed run-time {WCET} controller for concurrent critical tasks in mixed-critical systems},
	isbn = {978-1-4503-2727-5},
	url = {http://dl.acm.org/citation.cfm?doid=2659787.2659799},
	doi = {10.1145/2659787.2659799},
	abstract = {When integrating mixed critical systems on a multi/manycore, one challenge is to ensure predictability for high criticality tasks and an increased utilization for low criticality tasks. In this paper, we address this problem when several high criticality tasks with diﬀerent deadlines, periods and oﬀsets are concurrently executed on the system. We propose a distributed run-time WCET controller that works as follows: (1) locally, each critical task regularly checks if the interferences due to the low criticality tasks can be tolerated, otherwise it decides their suspension; (2) globally, a master suspends and restarts the low criticality tasks based on the received requests from the critical tasks. Our approach has been implemented as a software controller on a real multi-core COTS system with signiﬁcant gains 1.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Kritikakou, Angeliki and Rochange, Christine and Faugère, Madeleine and Pagetti, Claire and Roy, Matthieu and Girbal, Sylvain and Pérez, Daniel Gracia},
	year = {2014},
	pages = {139--148},
}

@inproceedings{oreizy_architecture-based_1998,
	title = {Architecture-based runtime software evolution},
	isbn = {978-0-8186-8368-8},
	url = {http://ieeexplore.ieee.org/document/671114/},
	doi = {10.1109/ICSE.1998.671114},
	abstract = {Continuous availability is a critical requirement for an important class of software systems. For these systems, runtime system evolution can mitigate the costs and risks associated with shutting down and restarting the system for an update. We present an architecture-based approach to runtime software evolution and highlight the role of software connectors in supporting runtime change. An initial implementation of a tool suite for supporting the runtime modification of software architectures, called ArchStudio, is presented.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE Comput. Soc},
	author = {Oreizy, P. and Medvidovic, N. and Taylor, R.N.},
	year = {1998},
	pages = {177--186},
}

@inproceedings{piper_instrumenting_2012,
	title = {Instrumenting {AUTOSAR} for dependability assessment: {A} guidance framework},
	isbn = {978-1-4673-1625-5 978-1-4673-1624-8 978-1-4673-1623-1},
	shorttitle = {Instrumenting {AUTOSAR} for dependability assessment},
	url = {http://ieeexplore.ieee.org/document/6263913/},
	doi = {10.1109/DSN.2012.6263913},
	abstract = {The AUTOSAR standard guides the development of component-based automotive software. As automotive software typically implements safety-critical functions, it needs to fulﬁll high dependability requirements, and the effort put into the quality assurance of these systems is correspondingly high. Testing, fault injection (FI), and other techniques are employed for the experimental dependability assessment of these increasingly software-intensive systems. Having ﬂexible and automated support for instrumentation is key in making these assessment techniques efﬁcient. However, providing a usable, customizable and performant instrumentation for AUTOSAR is non-trivial due to the varied abstractions and high complexity of these systems. This paper develops a dependability assessment guidance framework tailored towards AUTOSAR that helps identify the applicability and effectiveness of instrumentation techniques at (a) varied levels of software abstraction and granularity, (b) at varied software access levels - black-box, grey-box, white-box, and (c) the application of interface wrappers for conducting FI.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Piper, Thorsten and Winter, Stefan and Manns, Paul and Suri, Neeraj},
	month = jun,
	year = {2012},
	pages = {1--12},
}

@article{stoicescu_architecting_2017,
	title = {Architecting resilient computing systems: {A} component-based approach for adaptive fault tolerance},
	volume = {73},
	issn = {13837621},
	shorttitle = {Architecting resilient computing systems},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1383762116302715},
	doi = {10.1016/j.sysarc.2016.12.005},
	abstract = {Evolution of systems during their operational life is mandatory and both updates and upgrades should not impair their dependability properties. Dependable systems must evolve to accommodate changes, such as new threats and undesirable events, application updates or variations in available resources. A system that remains dependable when facing changes is called resilient. In this paper, we present an innovative approach taking advantage of component-based software engineering technologies for tackling the on-line adaptation of fault tolerance mechanisms. We propose a development process that relies on two key factors: designing fault tolerance mechanisms for adaptation and leveraging a reﬂective component-based middleware enabling ﬁne-grained control and modiﬁcation of the software architecture at runtime. We thoroughly describe the methodology, the development of adaptive fault tolerance mechanisms and evaluate the approach in terms of performance and agility.},
	language = {en},
	urldate = {2018-07-09},
	journal = {Journal of Systems Architecture},
	author = {Stoicescu, Miruna and Fabre, Jean-Charles and Roy, Matthieu},
	month = feb,
	year = {2017},
	pages = {6--16},
}

@inproceedings{lauer_engineering_2016,
	title = {Engineering {Adaptive} {Fault}-{Tolerance} {Mechanisms} for {Resilient} {Computing} on {ROS}},
	isbn = {978-1-4673-9913-5},
	url = {http://ieeexplore.ieee.org/document/7423139/},
	doi = {10.1109/HASE.2016.30},
	abstract = {Systems are expected to evolve during their service life in order to cope with changes of various natures, ranging from fluctuations in available resources to additional features requested by users. For dependable embedded systems, the challenge is even greater, as evolution must not impair dependability attributes. Resilient computing implies maintaining dependability properties when facing changes. Resilience encompasses several aspects, among which evolvability, i.e., the capacity of a system to evolve during its service life. In this paper, we discuss the evolution of systems with respect to their dependability mechanisms, and show how such mechanisms can evolve accordingly. From a component-based approach that enables to clarify the concepts, the process and the techniques to be used to address resilient computing, in particular regarding the adaptation of fault tolerance (or safety) mechanisms, we show how Adaptive Fault Tolerance (AFT) can be implemented with ROS. Beyond implementation, we draw the lessons learned from this work and discuss the limits of this runtime support to implement such resilient computing features in embedded systems.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Lauer, Michael and Amy, Matthieu and Fabre, Jean-Charles and Roy, Matthieu and Excoffon, William and Stoicescu, Miruna},
	month = jan,
	year = {2016},
	pages = {94--101},
}

@inproceedings{cherfi_securite-innocuite_2016,
	title = {Sécurité-innocuité des véhicules autonomes : enjeux et verrous},
	isbn = {978-2-35147-043-5},
	shorttitle = {Sécurité-innocuité des véhicules autonomes},
	url = {http://hdl.handle.net/2042/61697},
	doi = {10.4267/2042/61697},
	abstract = {These last months, autonomous cars are a trending topic. These vehicles are equipped with high end sensors which are in constant interaction with the environment. Before considering their mass production, automotive stakeholders must ensure the functional safety of critical systems embedded in these vehicles (intelligent sensors, fusion algorithms, command functions…). The SVA project aims at providing methods and tools that allow the characterization and study of those systems. To do this, it is necessary to identify the various stakes and locks that must be taken in to consideration and overcome. This article aims at describing some of those locks and offering shades of answers.},
	language = {fr},
	urldate = {2018-07-09},
	publisher = {IMdR},
	author = {Cherfi, Abraham and Arbaretier, Emmanuel and Zhao, Linda},
	month = dec,
	year = {2016},
}

@article{craveiro_adaptability_nodate,
	title = {Adaptability {Support} in {Time}- and {Space}-{Partitioned} {Aerospace} {Systems}},
	abstract = {The AIR (ARINC 653 in Space Real-Time Operating System) technology targets modern aerospace systems, where the concepts of time- and space-partitioning are applied. AIR features advanced timeliness control and adaptation mechanisms in its design, such as mode-based schedules, process deadline violation monitoring, and protection against event overload. The timing parameters of a space mission may vary throughout time, according to its mode/phase of operation, and the spacecraft may be exposed to unpredictable events and failures. In this paper we explore the adaptation potential of the advanced features included in AIR, analysing their code complexity (which inﬂuences software veriﬁcation, validation and certiﬁcation efforts) and computational complexity (which correlates to the temporal overhead impact on the system), and discussing how they can be applied to provide more adaptive, reconﬁgurable and self-adaptive AIR-based systems.},
	language = {en},
	author = {Craveiro, Joao and Ruﬁno, Jose},
	pages = {6},
}

@phdthesis{martorell_architecture_2014,
	title = {Architecture et processus de développement permettant la mise à jour dynamique de systèmes embarqués automobiles},
	url = {http://www.theses.fr/2014INPT0108},
	abstract = {Dans le contexte automobile actuel, le standard pour les calculateurs enfouis est AUTOSAR. L'un des inconvénients majeurs de cette architecture est son manque de flexibilité. Cependant, les mises à jour et la personnalisation des systèmes embarqués sont de plus en plus, non seulement plébiscités, mais également nécessaires. En effet, la complexité grandissante des systèmes exige à présent de déployer des moyens supplémentaires pour permettre leur maintenance et leur évolution de manière plus aisée. Ainsi, partant de ces constats, ce travail étudie les possibilités de faire des mises à jour dans le contexte d'AUTOSAR. Les modifications nécessaires se retrouvent non seulement dans l'architecture, mais également au sein du processus de développement et des considérations temps-réel. Tous ces aspects sont donc regardés en détails pour permettre les mises à jour partielles dans le cadre du standard AUTOSAR. Cette thèse décrit donc le processus de développement logiciel AUTOSAR et propose certaines améliorations mises en place au cours de ce travail. Un certain nombre de concepts sont également définis, afin d'aménager des espaces d'adaptation logiciels. Ces espaces sont ensuite utilisés pour intégrer des mises à jour partielles dans le calculateur embarqué. Le processus de développement est également modifié pour intégrer ces concepts ainsi que les mécanismes nécessaires à la mise à jour. Les aspects temps-réel concernant la mise à jour partielle dans les systèmes embarqués automobiles sont également traités ici. Un modèle de tâches approprié est mis en place dans le cadre d'AUTOSAR. De plus l'analyse de sensibilité est utilisée spécifiquement pour déterminer la flexibilité disponible dans un système donné. Les aspects d'implémentation sont également détaillés. En particulier, la création de mises à jour dans un contexte donné, la gestion des différentes versions possibles pour une application, l'utilisation et l'écriture dans la mémoire embarquée et enfin, les moyens nécessaires à la prise en compte des aspects de sûreté de fonctionnement. Pour terminer, tous les concepts développés dans ce travail sont appliqués à une preuve de concept reposant sur une application embarquée fournie par Renault. L'approche proposée est donc appliquée de manière pratique.},
	urldate = {2018-07-09},
	school = {Toulouse, INPT},
	author = {Martorell, Hélène},
	month = dec,
	year = {2014},
}

@inproceedings{bechennec_trampoline_2006,
	title = {Trampoline {An} {Open} {Source} {Implementation} of the {OSEK}/{VDX} {RTOS} {Specification}},
	isbn = {978-0-7803-9758-3},
	url = {http://ieeexplore.ieee.org/document/4178265/},
	doi = {10.1109/ETFA.2006.355432},
	abstract = {This paper introduces an OSEK/VDX1 Operating System implementation. OSEK/VDX is an industry standard for real-time operating system used in the ﬁeld of automotive embedded software. This implementation is proposed in the context of the open source software, which interest needs not to be demonstrated any more. The paper explains the main implementation choices as well as the technique proposed for the generation of a real-time application. This implementation is nowadays available for three targets: Inﬁneon C167, Darwin/PowerPC and Linux/x86.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Bechennec, Jean-Luc and Briday, Mikael and Faucou, Sebastien and Trinquet, Yvon},
	month = sep,
	year = {2006},
	pages = {62--69},
}

@inproceedings{schmidt_automotive_2010,
	title = {Automotive user interfaces: human computer interaction in the car},
	isbn = {978-1-60558-930-5},
	shorttitle = {Automotive user interfaces},
	url = {http://portal.acm.org/citation.cfm?doid=1753846.1753949},
	doi = {10.1145/1753846.1753949},
	abstract = {Cars have become complex interactive systems. Mechanical controls and electrical systems are transformed to the digital realm. It is common that drivers operate a vehicle and, at the same time, interact with a variety of devices and applications. Texting while driving, looking up an address for the navigation system, and taking a phone call are just some common examples that add value for the driver, but also increase the risk of driving. Novel interaction technologies create many opportunities for designing useful and attractive in-car user interfaces. With technologies that assist the user in driving, such as assistive cruise control and lane keeping, the user interface is essential to the way people perceive the driving experience. New means for user interface development and interaction design are required as the number of factors influencing the design space for automotive user interfaces is increasing. In comparison to other domains, a trial and error approach while the product is already in the market is not acceptable as the cost of failure may be fatal. User interface design in the automotive domain is relevant across many areas ranging from primary driving control, to assisted functions, to navigation, information services, entertainment and games.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {ACM Press},
	author = {Schmidt, Albrecht and Dey, Anind K. and Kun, Andrew L. and Spiessl, Wolfgang},
	year = {2010},
	pages = {3177},
}

@inproceedings{lei_feng_self_2008,
	title = {Self configuration of dependent tasks for dynamically reconfigurable automotive embedded systems},
	isbn = {978-1-4244-3123-6},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4739195},
	doi = {10.1109/CDC.2008.4739195},
	abstract = {The conﬁgurations of an automotive embedded system are normally ﬁxed in production and remain static over the vehicle lifetime. Future scenarios, however, call for more ﬂexible conﬁguration support. DySCAS (Dynamically Self-Conﬁguring Automotive Systems) project aims to introduce context-awareness and self-management features into automotive embedded systems via middleware technologies. Contributing to online conﬁguration decisions, this paper formalizes a fundamental self-conﬁguration problem. It forms a basis for managing the cross interdependencies of conﬁgurational items, assessing the system-wide impacts of changes, and making dynamic decisions about new conﬁgurations.},
	language = {en},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {{Lei Feng} and Chen, DeJiu and Torngren, Martin},
	year = {2008},
	pages = {3737--3742},
}

@article{studnia_security_nodate,
	title = {Security of embedded automotive networks: state of the art and a research proposal},
	abstract = {Embedded electronic components are nowadays a prominent part of a car’s architecture. Moreover, modern cars are now able to communicate with other devices through many wired or wireless interfaces. As a consequence, the security of embedded systems in cars has become a main concern for the manufacturers. This paper aims at 1) presenting a short overview of the current attacks already known and experimented against vehicles as well as the current state of the art of the protection mechanisms; 2) presenting an overview of our contribution to these protection mechanisms: the design and implementation of a stateful intrusion detection system for CAN-based automotive networks.},
	language = {en},
	author = {Studnia, Ivan and Nicomette, Vincent and Alata, Eric and Deswarte, Yves and Kaâniche, Mohamed and Laarouchi, Youssef},
	pages = {8},
}

@article{baufreton_multi-domain_nodate,
	title = {Multi-domain comparison of safety standards},
	abstract = {This paper presents an analysis of safety standards and their implementation in certification strategies from different domains such as aeronautics, automation, automotive, nuclear, railway and space. This work, performed in the context of the CG2E (“Club des Grandes Entreprises de l’Embarqué”), aims at identifying the main similarities and dissimilarities, for potential crossdomain harmonization. We strive to find the most comprehensive ‘trans-sectorial’ approach, within a large number of industrial domains. Exhibiting the ‘true goals’ of their numerous applicable standards, related to the safety of system and software, is a first important step towards harmonization, sharing common approaches, methods and tools whenever possible.},
	language = {en},
	author = {Baufreton, P and Blanquart, JP and Boulanger, JL and Delseny, H and Derrien, JC and Gassino, J and Ladier, G and Ledinot, E and Leeman, M and Quéré, P and Ricque, B},
	pages = {10},
}

@article{baruah_algorithms_1990,
	title = {Algorithms and complexity concerning the preemptive scheduling of periodic, real-time tasks on one processor},
	volume = {2},
	issn = {0922-6443, 1573-1383},
	url = {http://link.springer.com/10.1007/BF01995675},
	doi = {10.1007/BF01995675},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {Real-Time Systems},
	author = {Baruah, Sanjoy K. and Rosier, Louis E. and Howell, Rodney R.},
	month = nov,
	year = {1990},
	pages = {301--324},
}

@article{trapp_runtime_2007,
	title = {Runtime adaptation in safety-critical automotive systems},
	doi = {10.13140/2.1.1604.4480},
	abstract = {The cost-efficient development for dependable systems is one of the major future challenges of the automotive industry. Existing fault tolerance approaches are often not applicable and not sufficient. Therefore, innovative alternatives are required.},
	language = {en},
	author = {Trapp, Mario and Adler, Rasmus and Förster, Marc and {Janosch Junger}},
	year = {2007},
}

@inproceedings{pintard_using_2015,
	title = {Using {Fault} {Injection} to {Verify} an {AUTOSAR} {Application} {According} to the {ISO} 26262},
	url = {http://papers.sae.org/2015-01-0272/},
	doi = {10.4271/2015-01-0272},
	urldate = {2018-07-05},
	author = {Pintard, Ludovic and Leeman, Michel and Ymlahi-Ouazzani, Abdelillah and Fabre, Jean-Charles and Kanoun, Karama and Roy, Matthieu},
	month = apr,
	year = {2015},
}

@article{pellizzoni_feasibility_2005,
	title = {Feasibility {Analysis} of {Real}-{Time} {Periodic} {Tasks} with {Offsets}},
	volume = {30},
	issn = {0922-6443, 1573-1383},
	url = {http://link.springer.com/10.1007/s11241-005-0506-x},
	doi = {10.1007/s11241-005-0506-x},
	language = {en},
	number = {1-2},
	urldate = {2018-07-05},
	journal = {Real-Time Systems},
	author = {Pellizzoni, Rodolfo and Lipari, Giuseppe},
	month = may,
	year = {2005},
	pages = {105--128},
}

@article{pricopi_task_2014,
	title = {Task {Scheduling} on {Adaptive} {Multi}-{Core}},
	volume = {63},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/6517846/},
	doi = {10.1109/TC.2013.115},
	number = {10},
	urldate = {2018-07-05},
	journal = {IEEE Transactions on Computers},
	author = {Pricopi, Mihai and Mitra, Tulika},
	month = oct,
	year = {2014},
	pages = {2590--2603},
}

@inproceedings{hansson_saveccm_2004,
	title = {{SaveCCM} - a component model for safety-critical real-time systems},
	isbn = {978-0-7695-2199-2},
	url = {http://ieeexplore.ieee.org/document/1333431/},
	doi = {10.1109/EURMIC.2004.1333431},
	urldate = {2018-07-05},
	publisher = {IEEE},
	author = {Hansson, H. and AAkerholm, M. and Crnkovic, I. and Torngren, M.},
	year = {2004},
	pages = {627--635},
}

@inproceedings{burmester_fujaba_2005,
	title = {The fujaba real-time tool suite: model-driven development of safety-critical, real-time systems},
	shorttitle = {The fujaba real-time tool suite},
	url = {http://portal.acm.org/citation.cfm?doid=1062455.1062601},
	doi = {10.1145/1062455.1062601},
	language = {en},
	urldate = {2018-07-05},
	publisher = {ACM Press},
	author = {Burmester, Sven and Giese, Holger and Hirsch, Martin and Schilling, Daniela and Tichy, Matthias},
	year = {2005},
	pages = {670},
}

@inproceedings{bini_sensitivity_2006,
	title = {Sensitivity {Analysis} for {Fixed}-{Priority} {Real}-{Time} {Systems}},
	isbn = {978-0-7695-2619-5},
	url = {http://ieeexplore.ieee.org/document/1647721/},
	doi = {10.1109/ECRTS.2006.26},
	urldate = {2018-07-05},
	publisher = {IEEE},
	author = {Bini, E. and Di Natale, M. and Buttazzo, G.},
	year = {2006},
	pages = {13--22},
}

@inproceedings{furst_autosar_2016,
	title = {{AUTOSAR} for {Connected} and {Autonomous} {Vehicles}: {The} {AUTOSAR} {Adaptive} {Platform}},
	isbn = {978-1-5090-3688-2},
	shorttitle = {{AUTOSAR} for {Connected} and {Autonomous} {Vehicles}},
	url = {http://ieeexplore.ieee.org/document/7575379/},
	doi = {10.1109/DSN-W.2016.24},
	urldate = {2018-07-05},
	publisher = {IEEE},
	author = {Furst, Simon and Bechter, Markus},
	month = jun,
	year = {2016},
	pages = {215--217},
}

@inproceedings{wang_survey_2002,
	title = {Survey of weakly-hard real time schedule theory and its application},
	booktitle = {International {Symposium} on {Distributed} {Computing} and {Applications} to {Business}, {Engineering} and {Science}-{DCABES}'2002},
	author = {Wang, Zhi and Song, Ye-Qiong and Poggi, Enrico-Maria and Sun, Youxian},
	year = {2002},
	pages = {9--p},
}

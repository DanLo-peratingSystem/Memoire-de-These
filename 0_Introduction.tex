\ifdefined\included
\else
\documentclass[french, a4paper, 11pt, twoside, pdftex]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\fi


\chapter*{Introduction}\label{chap:Introduction}
\addstarredchapter{Introduction} %Sinon cela n'apparait pas dans la table des matières
\markboth{INTRODUCTION}{Introduction}

%%% GROLLEAU %%%
%%% Prévoit archis fédérées MCS, mais si on fait un // avec l'avionique IMA (mécanique -> fédéré -> IMA) => le choix fait d'aller vers un partitionnement. Pourquoi pas en automobile ?
La complexité des systèmes cyberphysiques s’est accrue dramatiquement  ces dernières décennies, tant par la multiplication des besoins applicatifs que par la sophistication des architectures matérielles qui les supportent.

C'est ainsi que le domaine de l'automobile est successivement passé du tout mécanique à des Architectures Électrique et Électronique (AEE) de plus en plus sophistiquées. Bien évidemment, cette tendance lourde a permis de rendre aux clients des services plus avancés et pertinents qui ont gagné en intelligence en s’appuyant sur les progrès des techniques numériques. Cela s'est fait tout particulièrement grâce à une approche logicielle prépondérante en délaissant les anciens systèmes mécaniques ou électro-mécaniques.

Ces évolutions progressives dans la voiture ont mené à des ajouts de calculateurs ayant chacun son lot de fonctionnalités avancées, potentiellement accompagnées des capteurs (température de l'habitacle, présence sur les sièges...) mais aussi des actionneurs (système d'air conditionné, vitres, verrouillage centralisé...) nécessaires.
C'est de cette façon que l'architecture distribuée dans l'automobile s'est étoffée pour atteindre de 50 jusqu'à 100 calculateurs pour les plus hauts de gamme. À terme, cette approche ne semble plus soutenable au vu de la demande en fonctionnalités supplémentaires liées aux technologies émergentes : le véhicule autonome et connecté.

C’est pour cette raison que la tendance d'ajout de calculateurs à une architecture distribuée toujours plus complexe est en train de s’inverser. L'architecture des systèmes embarqués a progressivement profité de l’émergence de calculateurs multicœurs puissants qui peuvent se substituer à nombre d’ECU (Unité de Commande Électronique) élémentaires. L’architecture actuelle s’oriente donc vers des architectures intégrées mettant en jeu des processeurs sur lesquels la coexistence d’applications critiques et non-critiques devient incontournable. 

Ces systèmes à criticité mixte sur calculateurs multicœurs induisent des problèmes d'\textit{interférence} d'exécution entre les tâches, de par le partage de ressources matérielles qui peuvent provoquer des latences d'exécution, quand plusieurs logiciels doivent exploiter une ressource commune. Cela a pour conséquence première d'ajouter des risques d'augmentation de temps d'exécution. Pour les tâches critiques ces augmentations peuvent aller jusqu'à un dépassement des échéances temporelles telles que définies par les spécifications. Ce risque de défaillances temporelles ne peut être pris à la légère et doit par conséquent être traité par des mécanismes de sûreté de fonctionnement dédiés. Ces derniers permettant de minimiser autant qu faire se peut l'occurrence de défaillances catastrophiques liées au dépassement d'échéance.

Il existe d'ores-et-déjà un certain nombre de solutions propres à la garantie d'exécution de tâches temps-réel. Ceci étant dit, un compromis est fait avec l'exploitation des ressources matérielles. De façon générale, plus les garanties de sûreté de fonctionnement logicielle sont fortes et plus les calculateurs multicœurs sont exploités de façon sous-optimale pour obtenir ces garanties. Ajouté à ce premier enjeu de garanties temporelles, vient donc un second enjeu complémentaire qui est d'avoir une approche conservatrice pour exploiter au maximum la puissance de calcul disponible. Cette approche conservatrice se définit comme une utilisation optimisée des ressources de calcul pour les tâches non-critiques autant que possible tout en garantissant les échéances temporelles propres aux tâches critiques.

C'est dans ce cadre que sont présentés ces travaux de thèse, focalisés sur l'étude de tâches logicielles critiques représentées sous forme de chaînes fonctionnelles. De fait chaque fonctionnalité exécutée correspond à une chaîne de différents composants logiciels exécutés séquentiellement. L'idée est d'avoir une vision plus macroscopique de l'exécution des tâches en tant que partie d'un ensemble de chaînes fonctionnelles plutôt que des instances isolées qui s'ordonnancent l'une après l'autre sur le processeur. Dans cette optique, on considère possible que les aléas de temps d'exécution puissent se compenser de façon naturelle pendant le fonctionnement. Que certains retards sur le temps d'exécution d'une tâche soient \textit{in fine} sans conséquence grâce au fait que des tâches précédentes faisant part de la même chaîne fonctionnelle aient bénéficié d'une avance sur leur temps d'exécution. Ou inversement, qu'un léger retard d'exécution d'une tâche à cause d'interférence soit bénin de part une compensation du retard dans la suite de la chaîne de tâches.

Avec ce concept, on souhaite mettre en place un mécanisme qui puisse prendre en compte l'état d'exécution d'une chaîne de tâches critiques de façon dynamique. Cette Surveillance doit vérifier qu'il est possible à chaque instant de garantir l'exécution bout-en-bout de la chaîne sous l'échéance temporelle propre à la fonction réalisée. Pour ce faire, un calcul d'anticipation de risque en pire cas doit s'opérer. L'objectif est d'anticiper le risque d'être dans une situation où un dépassement d'échéance deviendrait inévitable du fait d'un surplus d'interférences inter-tâches. Dans l'éventualité où ce cas de figure est anticipé, alors il faudra mobiliser un mécanisme de Contrôle. Son rôle sera de garantir en toute circonstance le respect de l'échéance et donc éviter toute faute temporelle par la prévention de toute interférence supplémentaire à la source~: par la suspension des tâches non-critiques.

Dit autrement, avec cette approche plus fonctionnelle de l'exécution du logiciel, le but est d'obtenir un mécanisme de Surveillance et de Contrôle qui offre des garanties minimales sur une chaîne de tâches critiques, par anticipation de risques d'interférences qui pourraient mener à une défaillance. Le principe fondamental de l'anticipation est de mettre en pause temporaire les tâches non critiques pour neutraliser les interférences associées. L'objectif est ainsi d'obtenir une garantie d'exécution bout-en-bout de la chaîne de tâche sans dépassement d'échéance, avec une limitation des interférences uniquement quand nécessaire. De cette façon, le reste du temps où cela n'est pas nécessaire, toutes les tâches du système peuvent exploiter au maximum la puissance de calcul et les ressources disponibles.

\smallbreak
\smallbreak
L’étude de cette problématique, l’approche que nous proposons, son développement et son
illustration expérimentale seront abordés en 5 chapitres.

Dans le~\autoref{chap:1_EnjeuxIntro}, nous nous attachons à expliciter la problématique de la thèse en débutant par un état des lieux du contexte industriel et de ses contraintes dans l'usage de systèmes à criticité mixte sur calculateurs multicœurs.

Dans le~\autoref{chap:2_StateofArt}, nous faisons référence aux travaux connexes étudiés. Les recherches sur la problématique du temps réel en général présentent un corpus foisonnant, voire gigantesque, de par la multiplicité des sous-branches du domaine. Nous positionnons notre proposition d'un point de vue plus macroscopique dans cet ensemble pour nous focaliser sur les travaux les plus pertinents relativement à notre approche.

Dans le~\autoref{chap:3_PrincipeArchi}, nous décrivons l'approche et la méthode propres à notre contribution pour répondre à la problématique soulevée~: allier optimisation des ressources de calcul et garanties temps-réel dans un environnement à criticité mixte complexe.

Dans le~\autoref{chap:4_ProtocolExpe}, nous développons et justifions notre approche expérimentale qui servira de squelette à la caractérisation et l'implémentation de notre approche.

Enfin, le~\autoref{chap:5_ImplementationCase} est dévolu à l’illustration de notre approche par la présentation d'un cas d'implémentation complet où l'on présente la plateforme matérielle et logicielle sélectionnée ainsi que les choix de développement qui ont été effectués. Ce cas d'étude se présente comme une première preuve de concept et nous permet d'analyser les résultats obtenus pour caractériser notre proposition aux travers de plusieurs expérimentations. 


\cmnt{
	The complexity of cyber-physical systems has increased drastically over the last decades. 
	
	Consequently, the automotive industry has successively gone from being entirely mechanical to increasingly sophisticated Electrical and Electronic Architectures (EEA). Of course, this major trend, supported by advances in digital technologies, has enabled us to provide customers with more advanced and relevant services that have become more intelligent. This has been done in a predominant way by relying on software aspects, leaving behind the old mechanical or electromechanical systems.
	
	These progressive evolution in the car led to the addition of computing units, each with its own set of advanced functionalities, potentially accompanied by sensors (cabin temperature, passenger's presence detection...) but also by the necessary actuators (air conditioning system, windows, central locking...).
	This is how the distributed architecture in the automobile has grown to up to 70 Electronic Computing Units (ECU) in a single vehicle. In the long run, this approach does not seem to be sustainable with the demand for additional functionalities linked to emerging technologies: the autonomous and connected vehicle.
	
	This is why the trend of adding ECUs to an increasingly complex distributed architecture is being reversed. It is substituted by the emergence of powerful multicore processors that can replace numerous elementary ECUs. The current trend is therefore moving towards federated architectures involving processors on which the coexistence of critical and non-critical applications is becoming essential. 
	
	These mixed-criticality systems lead to execution interference issues between tasks, due to the sharing of hardware resources which can cause execution latencies when several software applications have to exploit common resources. The first consequence is an increased risk of execution time overheads. For critical tasks, these overruns can go as far as compromising the temporal deadlines defined by the system specifications and consequently cause critical failures. This risk of temporal faults cannot be taken lightly and must therefore be dealt with by challenged operating safety mechanisms.
	
	There are already a certain number of solutions for guaranteeing the execution of real-time tasks. However, a trade-off is made with the exploitation of hardware resources. Generally speaking, the stronger the software real-time guarantees are, the more the multicore processors are exploited in a suboptimal way to obtain these guarantees. A second main issue is therefore to have a conservative approach to exploit the available computing power to the maximum.
	
	All-in-all,this thesis work focuses on the study of critical tasks modeled as functional task chains to guarantee their response times in a mixed-criticality hosting multicore. Each functionality of the system corresponds to a chain of different software components executed sequentially. With this more functional approach to software execution, we want to obtain a Monitoring and Control mechanism that offers guarantees on a critical task chain, by anticipating risks of interference that could lead to a failure. The anticipation consisting of pausing temporarily the noncritical tasks to control and mitigate interference. The objective is to obtain a guarantee of end-to-end response time of the task chain without missing deadlines, with a limitation of interference only when necessary, so that the rest of the time, all the tasks of the system can exploit the computing power and the available resources to the maximum. 
	
}

\ifdefined\included
\else
\bibliographystyle{StyleThese}
\bibliography{these}
\end{document}
\fi